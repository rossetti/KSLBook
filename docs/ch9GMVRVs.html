<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9.3 Generating Multi-Variate and Correlated Random Variates | Simulation Modeling using the Kotlin Simulation Library (KSL)</title>
  <meta name="description" content="A book that illustrates the basics of using the KSL. The output format for this book is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="9.3 Generating Multi-Variate and Correlated Random Variates | Simulation Modeling using the Kotlin Simulation Library (KSL)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A book that illustrates the basics of using the KSL. The output format for this book is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9.3 Generating Multi-Variate and Correlated Random Variates | Simulation Modeling using the Kotlin Simulation Library (KSL)" />
  
  <meta name="twitter:description" content="A book that illustrates the basics of using the KSL. The output format for this book is bookdown::gitbook." />
  

<meta name="author" content="Manuel D. Rossetti" />


<meta name="date" content="2025-07-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch9VRTs.html"/>
<link rel="next" href="summary-4.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Simulation Modeling using the Kotlin Simulation Library (KSL)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="release-history.html"><a href="release-history.html"><i class="fa fa-check"></i>Release History</a></li>
<li class="chapter" data-level="" data-path="ksl-project-page.html"><a href="ksl-project-page.html"><i class="fa fa-check"></i>KSL Project Page</a></li>
<li class="chapter" data-level="" data-path="book-support-files.html"><a href="book-support-files.html"><i class="fa fa-check"></i>Book Support Files</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="intended-audience.html"><a href="intended-audience.html"><i class="fa fa-check"></i>Intended Audience</a></li>
<li class="chapter" data-level="" data-path="organization-of-the-book.html"><a href="organization-of-the-book.html"><i class="fa fa-check"></i>Organization of the Book</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the Author</a></li>
<li class="chapter" data-level="1" data-path="ch1.html"><a href="ch1.html"><i class="fa fa-check"></i><b>1</b> Simulation Modeling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="simulation-modeling.html"><a href="simulation-modeling.html"><i class="fa fa-check"></i><b>1.1</b> Simulation Modeling</a></li>
<li class="chapter" data-level="1.2" data-path="why-simulate.html"><a href="why-simulate.html"><i class="fa fa-check"></i><b>1.2</b> Why Simulate?</a></li>
<li class="chapter" data-level="1.3" data-path="types-of-systems-and-simulation-models.html"><a href="types-of-systems-and-simulation-models.html"><i class="fa fa-check"></i><b>1.3</b> Types of Systems and Simulation Models</a></li>
<li class="chapter" data-level="1.4" data-path="simulation-descriptive-or-prescriptive-modeling.html"><a href="simulation-descriptive-or-prescriptive-modeling.html"><i class="fa fa-check"></i><b>1.4</b> Simulation: Descriptive or Prescriptive Modeling?</a></li>
<li class="chapter" data-level="1.5" data-path="randomness-in-simulation.html"><a href="randomness-in-simulation.html"><i class="fa fa-check"></i><b>1.5</b> Randomness in Simulation</a></li>
<li class="chapter" data-level="1.6" data-path="simulation-languages.html"><a href="simulation-languages.html"><i class="fa fa-check"></i><b>1.6</b> Simulation Languages</a></li>
<li class="chapter" data-level="1.7" data-path="ch1secsimMeth.html"><a href="ch1secsimMeth.html"><i class="fa fa-check"></i><b>1.7</b> Simulation Methodology</a></li>
<li class="chapter" data-level="1.8" data-path="overview-of-the-kotlin-simulation-library.html"><a href="overview-of-the-kotlin-simulation-library.html"><i class="fa fa-check"></i><b>1.8</b> Overview of the Kotlin Simulation Library</a></li>
<li class="chapter" data-level="1.9" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch2rng.html"><a href="ch2rng.html"><i class="fa fa-check"></i><b>2</b> Modeling Randomness</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch2generator.html"><a href="ch2generator.html"><i class="fa fa-check"></i><b>2.1</b> Random Number Generator</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ch2generator.html"><a href="ch2generator.html#ch2randompkg"><i class="fa fa-check"></i><b>2.1.1</b> Random Package</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch2generator.html"><a href="ch2generator.html#ch2creatingStreams"><i class="fa fa-check"></i><b>2.1.2</b> Creating and Using Streams</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch2generator.html"><a href="ch2generator.html#ch2crn"><i class="fa fa-check"></i><b>2.1.3</b> Common Random Numbers</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch2generator.html"><a href="ch2generator.html#ch2antitheticStreams"><i class="fa fa-check"></i><b>2.1.4</b> Creating and Using Antithetic Streams</a></li>
<li class="chapter" data-level="2.1.5" data-path="ch2generator.html"><a href="ch2generator.html#ch2rnFAQ"><i class="fa fa-check"></i><b>2.1.5</b> Frequently Asked Questions about Random Numbers</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="rvg.html"><a href="rvg.html"><i class="fa fa-check"></i><b>2.2</b> Random Variate Generation</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="rvg.html"><a href="rvg.html#basic-random-variate-generation"><i class="fa fa-check"></i><b>2.2.1</b> Basic Random Variate Generation</a></li>
<li class="chapter" data-level="2.2.2" data-path="rvg.html"><a href="rvg.html#rvg_dists"><i class="fa fa-check"></i><b>2.2.2</b> Continuous and Discrete Random Variables</a></li>
<li class="chapter" data-level="2.2.3" data-path="rvg.html"><a href="rvg.html#rvguse"><i class="fa fa-check"></i><b>2.2.3</b> Creating and Using Random Variables</a></li>
<li class="chapter" data-level="2.2.4" data-path="rvg.html"><a href="rvg.html#functions-of-random-variables"><i class="fa fa-check"></i><b>2.2.4</b> Functions of Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="probModels.html"><a href="probModels.html"><i class="fa fa-check"></i><b>2.3</b> Probability Distribution Models</a></li>
<li class="chapter" data-level="2.4" data-path="distFitting.html"><a href="distFitting.html"><i class="fa fa-check"></i><b>2.4</b> Distribution Fitting Using the KSL</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="distFitting.html"><a href="distFitting.html#estimating-distribution-parameters"><i class="fa fa-check"></i><b>2.4.1</b> Estimating Distribution Parameters</a></li>
<li class="chapter" data-level="2.4.2" data-path="distFitting.html"><a href="distFitting.html#continuous-distribution-recommendation-framework"><i class="fa fa-check"></i><b>2.4.2</b> Continuous Distribution Recommendation Framework</a></li>
<li class="chapter" data-level="2.4.3" data-path="distFitting.html"><a href="distFitting.html#discrete-distribution-framework"><i class="fa fa-check"></i><b>2.4.3</b> Discrete Distribution Framework</a></li>
<li class="chapter" data-level="2.4.4" data-path="distFitting.html"><a href="distFitting.html#pdfmexamples"><i class="fa fa-check"></i><b>2.4.4</b> Illustrative Examples from Appendix @ref(appidm)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>2.5</b> Summary</a></li>
<li class="chapter" data-level="2.6" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mcm.html"><a href="mcm.html"><i class="fa fa-check"></i><b>3</b> Monte Carlo Methods</a>
<ul>
<li class="chapter" data-level="3.1" data-path="kslStatistics.html"><a href="kslStatistics.html"><i class="fa fa-check"></i><b>3.1</b> Collecting Statistics</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="kslStatistics.html"><a href="kslStatistics.html#creating-and-using-a-statistic"><i class="fa fa-check"></i><b>3.1.1</b> Creating and Using a Statistic</a></li>
<li class="chapter" data-level="3.1.2" data-path="kslStatistics.html"><a href="kslStatistics.html#histFreq"><i class="fa fa-check"></i><b>3.1.2</b> Histograms and Frequencies</a></li>
<li class="chapter" data-level="3.1.3" data-path="kslStatistics.html"><a href="kslStatistics.html#ch3batchStats"><i class="fa fa-check"></i><b>3.1.3</b> Batch Statistics</a></li>
<li class="chapter" data-level="3.1.4" data-path="kslStatistics.html"><a href="kslStatistics.html#ch3StatSummary"><i class="fa fa-check"></i><b>3.1.4</b> Statistics Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ssMC.html"><a href="ssMC.html"><i class="fa fa-check"></i><b>3.2</b> Simple Monte Carlo Integration</a></li>
<li class="chapter" data-level="3.3" data-path="ch3StatReview.html"><a href="ch3StatReview.html"><i class="fa fa-check"></i><b>3.3</b> Review of Statistical Concepts</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="ch3StatReview.html"><a href="ch3StatReview.html#point-estimates-and-confidence-intervals"><i class="fa fa-check"></i><b>3.3.1</b> Point Estimates and Confidence Intervals</a></li>
<li class="chapter" data-level="3.3.2" data-path="ch3StatReview.html"><a href="ch3StatReview.html#ch3SampleSize"><i class="fa fa-check"></i><b>3.3.2</b> Sample Size Determination</a></li>
<li class="chapter" data-level="3.3.3" data-path="ch3StatReview.html"><a href="ch3StatReview.html#determining-the-sample-size-for-a-monte-carlo-simulation-experiment"><i class="fa fa-check"></i><b>3.3.3</b> Determining the Sample Size for a Monte Carlo Simulation Experiment</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="craps.html"><a href="craps.html"><i class="fa fa-check"></i><b>3.4</b> Simulating the Game of Craps</a></li>
<li class="chapter" data-level="3.5" data-path="the-news-vendor-problem.html"><a href="the-news-vendor-problem.html"><i class="fa fa-check"></i><b>3.5</b> The News Vendor Problem</a></li>
<li class="chapter" data-level="3.6" data-path="ch3InsProcess.html"><a href="ch3InsProcess.html"><i class="fa fa-check"></i><b>3.6</b> A Simple Inspection Process</a></li>
<li class="chapter" data-level="3.7" data-path="ch3SAN.html"><a href="ch3SAN.html"><i class="fa fa-check"></i><b>3.7</b> Stochastic Activity Networks</a></li>
<li class="chapter" data-level="3.8" data-path="mcmExperiments.html"><a href="mcmExperiments.html"><i class="fa fa-check"></i><b>3.8</b> Monte-Carlo Experiments</a></li>
<li class="chapter" data-level="3.9" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>3.9</b> Summary</a></li>
<li class="chapter" data-level="3.10" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>3.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introDEDS.html"><a href="introDEDS.html"><i class="fa fa-check"></i><b>4</b> Introduction to Discrete Event Modeling</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introDEDSdeds.html"><a href="introDEDSdeds.html"><i class="fa fa-check"></i><b>4.1</b> Discrete-Event Dynamic Systems</a></li>
<li class="chapter" data-level="4.2" data-path="HowDEDSClockWorks.html"><a href="HowDEDSClockWorks.html"><i class="fa fa-check"></i><b>4.2</b> How the Discrete-Event Clock Works</a></li>
<li class="chapter" data-level="4.3" data-path="QHandExample.html"><a href="QHandExample.html"><i class="fa fa-check"></i><b>4.3</b> Simulating a Queueing System By Hand</a></li>
<li class="chapter" data-level="4.4" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html"><i class="fa fa-check"></i><b>4.4</b> Modeling DEDS in the KSL</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#event-scheduling"><i class="fa fa-check"></i><b>4.4.1</b> Event Scheduling</a></li>
<li class="chapter" data-level="4.4.2" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#introDEDSschedExamples"><i class="fa fa-check"></i><b>4.4.2</b> Simple Event Scheduling Examples</a></li>
<li class="chapter" data-level="4.4.3" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#introDEDSUpDown"><i class="fa fa-check"></i><b>4.4.3</b> Up and Down Component Example</a></li>
<li class="chapter" data-level="4.4.4" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#introDEDSPharmacy"><i class="fa fa-check"></i><b>4.4.4</b> Modeling a Simple Queueing System</a></li>
<li class="chapter" data-level="4.4.5" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#more-details-about-the-pharmacy-model-implementation"><i class="fa fa-check"></i><b>4.4.5</b> More Details About the Pharmacy Model Implementation</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="enhancing-the-drive-through-pharmacy-model.html"><a href="enhancing-the-drive-through-pharmacy-model.html"><i class="fa fa-check"></i><b>4.5</b> Enhancing the Drive Through Pharmacy Model</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="enhancing-the-drive-through-pharmacy-model.html"><a href="enhancing-the-drive-through-pharmacy-model.html#modeling-a-simple-resource"><i class="fa fa-check"></i><b>4.5.1</b> Modeling a Simple Resource</a></li>
<li class="chapter" data-level="4.5.2" data-path="enhancing-the-drive-through-pharmacy-model.html"><a href="enhancing-the-drive-through-pharmacy-model.html#modeling-a-queue-with-statistical-collection"><i class="fa fa-check"></i><b>4.5.2</b> Modeling a Queue with Statistical Collection</a></li>
<li class="chapter" data-level="4.5.3" data-path="enhancing-the-drive-through-pharmacy-model.html"><a href="enhancing-the-drive-through-pharmacy-model.html#modeling-a-repeating-event-pattern"><i class="fa fa-check"></i><b>4.5.3</b> Modeling a Repeating Event Pattern</a></li>
<li class="chapter" data-level="4.5.4" data-path="enhancing-the-drive-through-pharmacy-model.html"><a href="enhancing-the-drive-through-pharmacy-model.html#collecting-more-detailed-statistics"><i class="fa fa-check"></i><b>4.5.4</b> Collecting More Detailed Statistics</a></li>
<li class="chapter" data-level="4.5.5" data-path="enhancing-the-drive-through-pharmacy-model.html"><a href="enhancing-the-drive-through-pharmacy-model.html#implementing-the-enhanced-pharmacy-model"><i class="fa fa-check"></i><b>4.5.5</b> Implementing the Enhanced Pharmacy Model</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="DTPExpanded.html"><a href="DTPExpanded.html"><i class="fa fa-check"></i><b>4.6</b> More Drive Through Fun</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="DTPExpanded.html"><a href="DTPExpanded.html#modeling-a-resource-with-a-waiting-line"><i class="fa fa-check"></i><b>4.6.1</b> Modeling a Resource with a Waiting Line</a></li>
<li class="chapter" data-level="4.6.2" data-path="DTPExpanded.html"><a href="DTPExpanded.html#modeling-the-tandem-queue-of-example-refexmexch4tandemq"><i class="fa fa-check"></i><b>4.6.2</b> Modeling the Tandem Queue of Example @ref(exm:exCh4TandemQ)</a></li>
<li class="chapter" data-level="4.6.3" data-path="DTPExpanded.html"><a href="DTPExpanded.html#modeling-with-the-station-package"><i class="fa fa-check"></i><b>4.6.3</b> Modeling with the Station Package</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="introDEDSSummary.html"><a href="introDEDSSummary.html"><i class="fa fa-check"></i><b>4.7</b> Summary</a></li>
<li class="chapter" data-level="4.8" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>4.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simoa.html"><a href="simoa.html"><i class="fa fa-check"></i><b>5</b> Analyzing and Accessing Simulation Output</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simoadatatypes.html"><a href="simoadatatypes.html"><i class="fa fa-check"></i><b>5.1</b> Types of Statistical Variables</a></li>
<li class="chapter" data-level="5.2" data-path="simoasimtypes.html"><a href="simoasimtypes.html"><i class="fa fa-check"></i><b>5.2</b> Types of Simulation With Respect To Output Analysis</a></li>
<li class="chapter" data-level="5.3" data-path="simoafinhorizon.html"><a href="simoafinhorizon.html"><i class="fa fa-check"></i><b>5.3</b> Analysis of Finite Horizon Simulations</a></li>
<li class="chapter" data-level="5.4" data-path="simoafinhorizonex.html"><a href="simoafinhorizonex.html"><i class="fa fa-check"></i><b>5.4</b> Capturing Output for a Simple Finite Horizon Simulation</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="simoafinhorizonex.html"><a href="simoafinhorizonex.html#simoaCapture"><i class="fa fa-check"></i><b>5.4.1</b> KSL Functionality for Capturing Statistical Results</a></li>
<li class="chapter" data-level="5.4.2" data-path="simoafinhorizonex.html"><a href="simoafinhorizonex.html#additional-remarks"><i class="fa fa-check"></i><b>5.4.2</b> Additional Remarks</a></li>
<li class="chapter" data-level="5.4.3" data-path="simoafinhorizonex.html"><a href="simoafinhorizonex.html#querying-the-ksl-database"><i class="fa fa-check"></i><b>5.4.3</b> Querying the KSL Database</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="simoaseqsampling.html"><a href="simoaseqsampling.html"><i class="fa fa-check"></i><b>5.5</b> Sequential Sampling for Finite Horizon Simulations</a></li>
<li class="chapter" data-level="5.6" data-path="simoainfhorizon.html"><a href="simoainfhorizon.html"><i class="fa fa-check"></i><b>5.6</b> Analysis of Infinite Horizon Simulations</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="simoainfhorizon.html"><a href="simoainfhorizon.html#simoainfhorizoninitialbias"><i class="fa fa-check"></i><b>5.6.1</b> Assessing the Effect of Initial Conditions</a></li>
<li class="chapter" data-level="5.6.2" data-path="simoainfhorizon.html"><a href="simoainfhorizon.html#simoainfhorizonrepDeletion"><i class="fa fa-check"></i><b>5.6.2</b> Performing the Method of Replication-Deletion</a></li>
<li class="chapter" data-level="5.6.3" data-path="simoainfhorizon.html"><a href="simoainfhorizon.html#simoainfhorizonbatchmeans"><i class="fa fa-check"></i><b>5.6.3</b> The Method of Batch Means</a></li>
<li class="chapter" data-level="5.6.4" data-path="simoainfhorizon.html"><a href="simoainfhorizon.html#simoainfhorizonjslbatching"><i class="fa fa-check"></i><b>5.6.4</b> Performing the Method of Batch Means</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="simoacomparingSystems.html"><a href="simoacomparingSystems.html"><i class="fa fa-check"></i><b>5.7</b> Comparing System Configurations</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="simoacomparingSystems.html"><a href="simoacomparingSystems.html#simoacomparingSystems:two"><i class="fa fa-check"></i><b>5.7.1</b> Comparing Two Systems</a></li>
<li class="chapter" data-level="5.7.2" data-path="simoacomparingSystems.html"><a href="simoacomparingSystems.html#simoacomparingSystemsMCB"><i class="fa fa-check"></i><b>5.7.2</b> Concepts for Comparing Systems</a></li>
<li class="chapter" data-level="5.7.3" data-path="simoacomparingSystems.html"><a href="simoacomparingSystems.html#multiple-comparison-with-the-best-procedures-mcb"><i class="fa fa-check"></i><b>5.7.3</b> Multiple Comparison with the Best Procedures (MCB)</a></li>
<li class="chapter" data-level="5.7.4" data-path="simoacomparingSystems.html"><a href="simoacomparingSystems.html#ch5Screening"><i class="fa fa-check"></i><b>5.7.4</b> Screening Procedures</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="ch5Scenarios.html"><a href="ch5Scenarios.html"><i class="fa fa-check"></i><b>5.8</b> Simulating Many Scenarios</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="ch5Scenarios.html"><a href="ch5Scenarios.html#controlAntns"><i class="fa fa-check"></i><b>5.8.1</b> Control Annotations</a></li>
<li class="chapter" data-level="5.8.2" data-path="ch5Scenarios.html"><a href="ch5Scenarios.html#rvParameters"><i class="fa fa-check"></i><b>5.8.2</b> Random Variable Parameters</a></li>
<li class="chapter" data-level="5.8.3" data-path="ch5Scenarios.html"><a href="ch5Scenarios.html#kslScenarios"><i class="fa fa-check"></i><b>5.8.3</b> Setting Up and Running Multiple Scenarios</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="simoasummary.html"><a href="simoasummary.html"><i class="fa fa-check"></i><b>5.9</b> Summary</a></li>
<li class="chapter" data-level="5.10" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>5.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="processview.html"><a href="processview.html"><i class="fa fa-check"></i><b>6</b> Process View Modeling Using the KSL</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ch6Entities.html"><a href="ch6Entities.html"><i class="fa fa-check"></i><b>6.1</b> What are Entities?</a></li>
<li class="chapter" data-level="6.2" data-path="pvIntro.html"><a href="pvIntro.html"><i class="fa fa-check"></i><b>6.2</b> The Process View</a></li>
<li class="chapter" data-level="6.3" data-path="understanding-ksl-processes-and-entities.html"><a href="understanding-ksl-processes-and-entities.html"><i class="fa fa-check"></i><b>6.3</b> Understanding KSL Processes and Entities</a></li>
<li class="chapter" data-level="6.4" data-path="examples-of-process-modeling.html"><a href="examples-of-process-modeling.html"><i class="fa fa-check"></i><b>6.4</b> Examples of Process Modeling</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="examples-of-process-modeling.html"><a href="examples-of-process-modeling.html#holding-entities-in-a-queue-holdqueue-class"><i class="fa fa-check"></i><b>6.4.1</b> Holding Entities in a Queue: <code>HoldQueue</code> Class</a></li>
<li class="chapter" data-level="6.4.2" data-path="examples-of-process-modeling.html"><a href="examples-of-process-modeling.html#signaling-entities"><i class="fa fa-check"></i><b>6.4.2</b> Signaling Entities</a></li>
<li class="chapter" data-level="6.4.3" data-path="examples-of-process-modeling.html"><a href="examples-of-process-modeling.html#understanding-blocking-queues"><i class="fa fa-check"></i><b>6.4.3</b> Understanding Blocking Queues</a></li>
<li class="chapter" data-level="6.4.4" data-path="examples-of-process-modeling.html"><a href="examples-of-process-modeling.html#allowing-entities-to-wait-for-a-process"><i class="fa fa-check"></i><b>6.4.4</b> Allowing Entities to Wait for a Process</a></li>
<li class="chapter" data-level="6.4.5" data-path="examples-of-process-modeling.html"><a href="examples-of-process-modeling.html#processinteraction"><i class="fa fa-check"></i><b>6.4.5</b> Process Interaction</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="modeling-a-stem-career-mixer.html"><a href="modeling-a-stem-career-mixer.html"><i class="fa fa-check"></i><b>6.5</b> Modeling a STEM Career Mixer</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="modeling-a-stem-career-mixer.html"><a href="modeling-a-stem-career-mixer.html#conceptualizing-the-system"><i class="fa fa-check"></i><b>6.5.1</b> Conceptualizing the System</a></li>
<li class="chapter" data-level="6.5.2" data-path="modeling-a-stem-career-mixer.html"><a href="modeling-a-stem-career-mixer.html#implementing-the-stem-mixer-model"><i class="fa fa-check"></i><b>6.5.2</b> Implementing the STEM Mixer Model</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="the-tie-dye-t-shirt-model.html"><a href="the-tie-dye-t-shirt-model.html"><i class="fa fa-check"></i><b>6.6</b> The Tie-Dye T-Shirt Model</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="the-tie-dye-t-shirt-model.html"><a href="the-tie-dye-t-shirt-model.html#ch4:TieDyeTShirtsSub1"><i class="fa fa-check"></i><b>6.6.1</b> Implementing the Tie-Dye T-Shirt Model</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="summary-2.html"><a href="summary-2.html"><i class="fa fa-check"></i><b>6.7</b> Summary</a></li>
<li class="chapter" data-level="6.8" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch7AdvModeling.html"><a href="ch7AdvModeling.html"><i class="fa fa-check"></i><b>7</b> Advanced Event and Process View Modeling</a>
<ul>
<li class="chapter" data-level="7.1" data-path="modeling-with-processes-and-resources.html"><a href="modeling-with-processes-and-resources.html"><i class="fa fa-check"></i><b>7.1</b> Modeling with Processes and Resources</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="modeling-with-processes-and-resources.html"><a href="modeling-with-processes-and-resources.html#modeling-space-with-resources"><i class="fa fa-check"></i><b>7.1.1</b> Modeling Space with Resources</a></li>
<li class="chapter" data-level="7.1.2" data-path="modeling-with-processes-and-resources.html"><a href="modeling-with-processes-and-resources.html#secResourcePools"><i class="fa fa-check"></i><b>7.1.2</b> Resource Pools</a></li>
<li class="chapter" data-level="7.1.3" data-path="modeling-with-processes-and-resources.html"><a href="modeling-with-processes-and-resources.html#secTestAndRepair"><i class="fa fa-check"></i><b>7.1.3</b> Computer Test and Repair Shop Example</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="modeling-non-stationary-systems.html"><a href="modeling-non-stationary-systems.html"><i class="fa fa-check"></i><b>7.2</b> Modeling Non-Stationary Systems</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="modeling-non-stationary-systems.html"><a href="modeling-non-stationary-systems.html#ch7secNSPP"><i class="fa fa-check"></i><b>7.2.1</b> Non-Stationary Arrival Processes</a></li>
<li class="chapter" data-level="7.2.2" data-path="modeling-non-stationary-systems.html"><a href="modeling-non-stationary-systems.html#modeling-resources-under-non-stationary-conditions"><i class="fa fa-check"></i><b>7.2.2</b> Modeling Resources Under Non-Stationary Conditions</a></li>
<li class="chapter" data-level="7.2.3" data-path="modeling-non-stationary-systems.html"><a href="modeling-non-stationary-systems.html#enhancing-the-stem-career-mixer-model"><i class="fa fa-check"></i><b>7.2.3</b> Enhancing the STEM Career Mixer Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="examples-of-advanced-event-models.html"><a href="examples-of-advanced-event-models.html"><i class="fa fa-check"></i><b>7.3</b> Examples of Advanced Event Models</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="examples-of-advanced-event-models.html"><a href="examples-of-advanced-event-models.html#ch6s1sb4sub3"><i class="fa fa-check"></i><b>7.3.1</b> Modeling Balking and Reneging</a></li>
<li class="chapter" data-level="7.3.2" data-path="examples-of-advanced-event-models.html"><a href="examples-of-advanced-event-models.html#rqModel"><i class="fa fa-check"></i><b>7.3.2</b> Modeling a Reorder Point, Reorder Quantity Inventory Policy</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ch7VandV.html"><a href="ch7VandV.html"><i class="fa fa-check"></i><b>7.4</b> Applying Queueing Theory Results to Verify and Validate a Simulation</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="ch7VandV.html"><a href="ch7VandV.html#analyzing-the-preparation-station"><i class="fa fa-check"></i><b>7.4.1</b> Analyzing the Preparation Station</a></li>
<li class="chapter" data-level="7.4.2" data-path="ch7VandV.html"><a href="ch7VandV.html#analyzing-the-build-lines"><i class="fa fa-check"></i><b>7.4.2</b> Analyzing the Build Lines</a></li>
<li class="chapter" data-level="7.4.3" data-path="ch7VandV.html"><a href="ch7VandV.html#analyzing-the-packaging-station"><i class="fa fa-check"></i><b>7.4.3</b> Analyzing the Packaging Station</a></li>
<li class="chapter" data-level="7.4.4" data-path="ch7VandV.html"><a href="ch7VandV.html#analyzing-the-palletizing-station"><i class="fa fa-check"></i><b>7.4.4</b> Analyzing the Palletizing Station</a></li>
<li class="chapter" data-level="7.4.5" data-path="ch7VandV.html"><a href="ch7VandV.html#analyzing-the-total-system-time"><i class="fa fa-check"></i><b>7.4.5</b> Analyzing the Total System Time</a></li>
<li class="chapter" data-level="7.4.6" data-path="ch7VandV.html"><a href="ch7VandV.html#other-issues-for-verification-and-validation"><i class="fa fa-check"></i><b>7.4.6</b> Other Issues for Verification and Validation</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="summary-3.html"><a href="summary-3.html"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="exercises-6.html"><a href="exercises-6.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chEntityMovement.html"><a href="chEntityMovement.html"><i class="fa fa-check"></i><b>8</b> Modeling Entity Movement</a>
<ul>
<li class="chapter" data-level="8.1" data-path="secRCT.html"><a href="secRCT.html"><i class="fa fa-check"></i><b>8.1</b> Resource Constrained Transfer</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="secRCT.html"><a href="secRCT.html#secTestRepairRCT"><i class="fa fa-check"></i><b>8.1.1</b> Test and Repair with Resource Constrained Transfer</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="movableResources.html"><a href="movableResources.html"><i class="fa fa-check"></i><b>8.2</b> Constrained Transfer with Movable Resources</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="movableResources.html"><a href="movableResources.html#spatial-models"><i class="fa fa-check"></i><b>8.2.1</b> Spatial Models</a></li>
<li class="chapter" data-level="8.2.2" data-path="movableResources.html"><a href="movableResources.html#secMovableResources"><i class="fa fa-check"></i><b>8.2.2</b> Movable Resources</a></li>
<li class="chapter" data-level="8.2.3" data-path="movableResources.html"><a href="movableResources.html#secTQMWM"><i class="fa fa-check"></i><b>8.2.3</b> Tandem Queue Model With Movement</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="secTestAndRepairMovableResources.html"><a href="secTestAndRepairMovableResources.html"><i class="fa fa-check"></i><b>8.3</b> Modeling the Test and Repair System with Movable Resources</a></li>
<li class="chapter" data-level="8.4" data-path="secConveyors.html"><a href="secConveyors.html"><i class="fa fa-check"></i><b>8.4</b> Modeling Systems with Conveyors</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="secConveyors.html"><a href="secConveyors.html#ksl-conveyor-constructs"><i class="fa fa-check"></i><b>8.4.1</b> KSL Conveyor Constructs</a></li>
<li class="chapter" data-level="8.4.2" data-path="secConveyors.html"><a href="secConveyors.html#tandem-queue-system-with-conveyors"><i class="fa fa-check"></i><b>8.4.2</b> Tandem Queue System with Conveyors</a></li>
<li class="chapter" data-level="8.4.3" data-path="secConveyors.html"><a href="secConveyors.html#secTestAndRepairConveyors"><i class="fa fa-check"></i><b>8.4.3</b> Test and Repair via Conveyors</a></li>
<li class="chapter" data-level="8.4.4" data-path="secConveyors.html"><a href="secConveyors.html#secMiscConveyor"><i class="fa fa-check"></i><b>8.4.4</b> Miscellaneous Concepts in Conveyor Modeling</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="summary-of-new-concepts.html"><a href="summary-of-new-concepts.html"><i class="fa fa-check"></i><b>8.5</b> Summary of New Concepts</a></li>
<li class="chapter" data-level="8.6" data-path="exercises-7.html"><a href="exercises-7.html"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch9AdvMC.html"><a href="ch9AdvMC.html"><i class="fa fa-check"></i><b>9</b> Advanced Monte Carlo Methods</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ch9BootStrapping.html"><a href="ch9BootStrapping.html"><i class="fa fa-check"></i><b>9.1</b> Bootstrap Methods</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ch9BootStrapping.html"><a href="ch9BootStrapping.html#bootstrapping-using-the-ksl"><i class="fa fa-check"></i><b>9.1.1</b> Bootstrapping Using the KSL</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch9VRTs.html"><a href="ch9VRTs.html"><i class="fa fa-check"></i><b>9.2</b> Variance Reduction Techniques</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ch9VRTs.html"><a href="ch9VRTs.html#common-random-numbers-crn"><i class="fa fa-check"></i><b>9.2.1</b> Common Random Numbers (CRN)</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch9VRTs.html"><a href="ch9VRTs.html#antithetic-variates-av"><i class="fa fa-check"></i><b>9.2.2</b> Antithetic Variates (AV)</a></li>
<li class="chapter" data-level="9.2.3" data-path="ch9VRTs.html"><a href="ch9VRTs.html#indirect-estimation"><i class="fa fa-check"></i><b>9.2.3</b> Indirect Estimation</a></li>
<li class="chapter" data-level="9.2.4" data-path="ch9VRTs.html"><a href="ch9VRTs.html#control-variates-cv"><i class="fa fa-check"></i><b>9.2.4</b> Control Variates (CV)</a></li>
<li class="chapter" data-level="9.2.5" data-path="ch9VRTs.html"><a href="ch9VRTs.html#stratified-and-post-stratified-sampling"><i class="fa fa-check"></i><b>9.2.5</b> Stratified and Post Stratified Sampling</a></li>
<li class="chapter" data-level="9.2.6" data-path="ch9VRTs.html"><a href="ch9VRTs.html#conditional-expectation-ce"><i class="fa fa-check"></i><b>9.2.6</b> Conditional Expectation (CE)</a></li>
<li class="chapter" data-level="9.2.7" data-path="ch9VRTs.html"><a href="ch9VRTs.html#importance-sampling-is"><i class="fa fa-check"></i><b>9.2.7</b> Importance Sampling (IS)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ch9GMVRVs.html"><a href="ch9GMVRVs.html"><i class="fa fa-check"></i><b>9.3</b> Generating Multi-Variate and Correlated Random Variates</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="ch9GMVRVs.html"><a href="ch9GMVRVs.html#generating-from-a-bivariate-normal-distribution"><i class="fa fa-check"></i><b>9.3.1</b> Generating from a Bivariate Normal Distribution</a></li>
<li class="chapter" data-level="9.3.2" data-path="ch9GMVRVs.html"><a href="ch9GMVRVs.html#copulas-and-multi-variate-generation-methods"><i class="fa fa-check"></i><b>9.3.2</b> Copulas and Multi-variate Generation Methods</a></li>
<li class="chapter" data-level="9.3.3" data-path="ch9GMVRVs.html"><a href="ch9GMVRVs.html#autocorrelated-generation"><i class="fa fa-check"></i><b>9.3.3</b> Autocorrelated Generation</a></li>
<li class="chapter" data-level="9.3.4" data-path="ch9GMVRVs.html"><a href="ch9GMVRVs.html#ch9MCMC"><i class="fa fa-check"></i><b>9.3.4</b> Introduction to Markov Chain Monte Carlo Methods</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="summary-4.html"><a href="summary-4.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="exercises-8.html"><a href="exercises-8.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appRNRV.html"><a href="appRNRV.html"><i class="fa fa-check"></i><b>A</b> Generating Pseudo-Random Numbers and Random Variates</a>
<ul>
<li class="chapter" data-level="A.1" data-path="appRNRVPRN.html"><a href="appRNRVPRN.html"><i class="fa fa-check"></i><b>A.1</b> Pseudo Random Numbers</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="appRNRVPRN.html"><a href="appRNRVPRN.html#appRNRVRNGs"><i class="fa fa-check"></i><b>A.1.1</b> Random Number Generators</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="appRNRVs.html"><a href="appRNRVs.html"><i class="fa fa-check"></i><b>A.2</b> Generating Random Variates from Distributions</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="appRNRVs.html"><a href="appRNRVs.html#inverse-transform-method"><i class="fa fa-check"></i><b>A.2.1</b> Inverse Transform Method</a></li>
<li class="chapter" data-level="A.2.2" data-path="appRNRVs.html"><a href="appRNRVs.html#convolution"><i class="fa fa-check"></i><b>A.2.2</b> Convolution</a></li>
<li class="chapter" data-level="A.2.3" data-path="appRNRVs.html"><a href="appRNRVs.html#acceptancerejection"><i class="fa fa-check"></i><b>A.2.3</b> Acceptance/Rejection</a></li>
<li class="chapter" data-level="A.2.4" data-path="appRNRVs.html"><a href="appRNRVs.html#AppRNRVsubsecMTSRV"><i class="fa fa-check"></i><b>A.2.4</b> Mixture Distributions, Truncated Distributions, and Shifted Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="summary-5.html"><a href="summary-5.html"><i class="fa fa-check"></i><b>A.3</b> Summary</a></li>
<li class="chapter" data-level="A.4" data-path="exercises-9.html"><a href="exercises-9.html"><i class="fa fa-check"></i><b>A.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appidm.html"><a href="appidm.html"><i class="fa fa-check"></i><b>B</b> Probability Distribution Modeling</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appidmsecrvPD.html"><a href="appidmsecrvPD.html"><i class="fa fa-check"></i><b>B.1</b> Random Variables and Probability Distributions</a></li>
<li class="chapter" data-level="B.2" data-path="appidmsecMDD.html"><a href="appidmsecMDD.html"><i class="fa fa-check"></i><b>B.2</b> Modeling with Discrete Distributions</a></li>
<li class="chapter" data-level="B.3" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html"><i class="fa fa-check"></i><b>B.3</b> Fitting Discrete Distributions</a>
<ul>
<li class="chapter" data-level="B.3.1" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#AppDisFitPoissonFit"><i class="fa fa-check"></i><b>B.3.1</b> Fitting a Poisson Distribution</a></li>
<li class="chapter" data-level="B.3.2" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#visualizing-the-data"><i class="fa fa-check"></i><b>B.3.2</b> Visualizing the Data</a></li>
<li class="chapter" data-level="B.3.3" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#estimating-the-rate-parameter-for-the-poisson-distribution"><i class="fa fa-check"></i><b>B.3.3</b> Estimating the Rate Parameter for the Poisson Distribution</a></li>
<li class="chapter" data-level="B.3.4" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#chi-squared-goodness-of-fit-test-for-poisson-distribution"><i class="fa fa-check"></i><b>B.3.4</b> Chi-Squared Goodness of Fit Test for Poisson Distribution</a></li>
<li class="chapter" data-level="B.3.5" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#subsubchisqGOF"><i class="fa fa-check"></i><b>B.3.5</b> Chi-Squared Goodness of Fit Test</a></li>
<li class="chapter" data-level="B.3.6" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#using-the-fitdistrplus-r-package-on-discrete-data"><i class="fa fa-check"></i><b>B.3.6</b> Using the fitdistrplus R Package on Discrete Data</a></li>
<li class="chapter" data-level="B.3.7" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#fitting-a-discrete-empirical-distribution"><i class="fa fa-check"></i><b>B.3.7</b> Fitting a Discrete Empirical Distribution</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="appidmsecMCD.html"><a href="appidmsecMCD.html"><i class="fa fa-check"></i><b>B.4</b> Modeling with Continuous Distributions</a></li>
<li class="chapter" data-level="B.5" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html"><i class="fa fa-check"></i><b>B.5</b> Fitting Continuous Distributions</a>
<ul>
<li class="chapter" data-level="B.5.1" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsecvisualizedata"><i class="fa fa-check"></i><b>B.5.1</b> Visualizing the Data</a></li>
<li class="chapter" data-level="B.5.2" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsecstatsdata"><i class="fa fa-check"></i><b>B.5.2</b> Statistically Summarize the Data</a></li>
<li class="chapter" data-level="B.5.3" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsechypothDist"><i class="fa fa-check"></i><b>B.5.3</b> Hypothesizing and Testing a Distribution</a></li>
<li class="chapter" data-level="B.5.4" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#kolmogorov-smirnov-test"><i class="fa fa-check"></i><b>B.5.4</b> Kolmogorov-Smirnov Test</a></li>
<li class="chapter" data-level="B.5.5" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsecvisFit"><i class="fa fa-check"></i><b>B.5.5</b> Visualizing the Fit</a></li>
<li class="chapter" data-level="B.5.6" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidms2sb3"><i class="fa fa-check"></i><b>B.5.6</b> Using the Input Analyzer</a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html"><i class="fa fa-check"></i><b>B.6</b> Testing Uniform (0,1) Pseudo-Random Numbers</a>
<ul>
<li class="chapter" data-level="B.6.1" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#chi-squared-goodness-of-fit-tests-for-pseudo-random-numbers"><i class="fa fa-check"></i><b>B.6.1</b> Chi-Squared Goodness of Fit Tests for Pseudo-Random Numbers</a></li>
<li class="chapter" data-level="B.6.2" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#higher-dimensional-chi-squared-test"><i class="fa fa-check"></i><b>B.6.2</b> Higher Dimensional Chi-Squared Test</a></li>
<li class="chapter" data-level="B.6.3" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#kolmogorov-smirnov-test-for-pseudo-random-numbers"><i class="fa fa-check"></i><b>B.6.3</b> Kolmogorov-Smirnov Test for Pseudo-Random Numbers</a></li>
<li class="chapter" data-level="B.6.4" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#testing-for-independence-and-patterns-in-pseudo-random-numbers"><i class="fa fa-check"></i><b>B.6.4</b> Testing for Independence and Patterns in Pseudo-Random Numbers</a></li>
</ul></li>
<li class="chapter" data-level="B.7" data-path="appdistfitidms2sb4.html"><a href="appdistfitidms2sb4.html"><i class="fa fa-check"></i><b>B.7</b> Additional Distribution Modeling Concepts</a></li>
<li class="chapter" data-level="B.8" data-path="appidmSummary.html"><a href="appidmSummary.html"><i class="fa fa-check"></i><b>B.8</b> Summary</a></li>
<li class="chapter" data-level="B.9" data-path="exercises-10.html"><a href="exercises-10.html"><i class="fa fa-check"></i><b>B.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="appqtAndInvT.html"><a href="appqtAndInvT.html"><i class="fa fa-check"></i><b>C</b> Queueing Theory</a>
<ul>
<li class="chapter" data-level="C.1" data-path="appqts1.html"><a href="appqts1.html"><i class="fa fa-check"></i><b>C.1</b> Single Line Queueing Stations</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="appqts1.html"><a href="appqts1.html#queueing-notation"><i class="fa fa-check"></i><b>C.1.1</b> Queueing Notation</a></li>
<li class="chapter" data-level="C.1.2" data-path="appqts1.html"><a href="appqts1.html#littles-formula"><i class="fa fa-check"></i><b>C.1.2</b> Littleâ€™s Formula</a></li>
<li class="chapter" data-level="C.1.3" data-path="appqts1.html"><a href="appqts1.html#appqts1sb1"><i class="fa fa-check"></i><b>C.1.3</b> Deriving Formulas for Markovian Single Queue Systems</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="appqts1sb2.html"><a href="appqts1sb2.html"><i class="fa fa-check"></i><b>C.2</b> Examples and Applications of Queueing Analysis</a>
<ul>
<li class="chapter" data-level="C.2.1" data-path="appqts1sb2.html"><a href="appqts1sb2.html#infinite-queue-examples"><i class="fa fa-check"></i><b>C.2.1</b> Infinite Queue Examples</a></li>
<li class="chapter" data-level="C.2.2" data-path="appqts1sb2.html"><a href="appqts1sb2.html#finite-queue-examples"><i class="fa fa-check"></i><b>C.2.2</b> Finite Queue Examples</a></li>
</ul></li>
<li class="chapter" data-level="C.3" data-path="appqts1sb3.html"><a href="appqts1sb3.html"><i class="fa fa-check"></i><b>C.3</b> Non-Markovian Queues and Approximations</a></li>
<li class="chapter" data-level="C.4" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html"><i class="fa fa-check"></i><b>C.4</b> Summary of Queueing Formulas</a>
<ul>
<li class="chapter" data-level="C.4.1" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mm1-queue"><i class="fa fa-check"></i><b>C.4.1</b> M/M/1 Queue</a></li>
<li class="chapter" data-level="C.4.2" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmc-queue"><i class="fa fa-check"></i><b>C.4.2</b> M/M/c Queue</a></li>
<li class="chapter" data-level="C.4.3" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmck-queue"><i class="fa fa-check"></i><b>C.4.3</b> M/M/c/k Queue</a></li>
<li class="chapter" data-level="C.4.4" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mgcc-queue"><i class="fa fa-check"></i><b>C.4.4</b> M/G/c/c Queue</a></li>
<li class="chapter" data-level="C.4.5" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mm1k-queue"><i class="fa fa-check"></i><b>C.4.5</b> M/M/1/k Queue</a></li>
<li class="chapter" data-level="C.4.6" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmck-queue-1"><i class="fa fa-check"></i><b>C.4.6</b> M/M/c/k Queue</a></li>
<li class="chapter" data-level="C.4.7" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mm1kk-queue"><i class="fa fa-check"></i><b>C.4.7</b> M/M/1/k/k Queue</a></li>
<li class="chapter" data-level="C.4.8" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmckk-queue"><i class="fa fa-check"></i><b>C.4.8</b> M/M/c/k/k Queue</a></li>
</ul></li>
<li class="chapter" data-level="C.5" data-path="exercises-11.html"><a href="exercises-11.html"><i class="fa fa-check"></i><b>C.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="appUtilities.html"><a href="appUtilities.html"><i class="fa fa-check"></i><b>D</b> KSL Utility Packages</a>
<ul>
<li class="chapter" data-level="D.1" data-path="the-outputdirectory-class-and-ksl-object.html"><a href="the-outputdirectory-class-and-ksl-object.html"><i class="fa fa-check"></i><b>D.1</b> The <code>OutputDirectory</code> Class and <code>KSL</code> Object</a></li>
<li class="chapter" data-level="D.2" data-path="logging-options.html"><a href="logging-options.html"><i class="fa fa-check"></i><b>D.2</b> Logging Options</a></li>
<li class="chapter" data-level="D.3" data-path="the-kslfileutil-object.html"><a href="the-kslfileutil-object.html"><i class="fa fa-check"></i><b>D.3</b> The <code>KSLFileUtil</code> Object</a></li>
<li class="chapter" data-level="D.4" data-path="appDCSVEtc.html"><a href="appDCSVEtc.html"><i class="fa fa-check"></i><b>D.4</b> CSV, Excel, and Tabular Data Files</a></li>
<li class="chapter" data-level="D.5" data-path="dfUtil.html"><a href="dfUtil.html"><i class="fa fa-check"></i><b>D.5</b> The <code>DataFrameUtil</code> Object</a></li>
<li class="chapter" data-level="D.6" data-path="ksl-database-utilities.html"><a href="ksl-database-utilities.html"><i class="fa fa-check"></i><b>D.6</b> KSL Database Utilities</a></li>
<li class="chapter" data-level="D.7" data-path="appUtilitiesArrays.html"><a href="appUtilitiesArrays.html"><i class="fa fa-check"></i><b>D.7</b> Array Utilities</a></li>
<li class="chapter" data-level="D.8" data-path="appPlotting.html"><a href="appPlotting.html"><i class="fa fa-check"></i><b>D.8</b> KSL Plotting Utilities</a></li>
<li class="chapter" data-level="D.9" data-path="appExpDesign.html"><a href="appExpDesign.html"><i class="fa fa-check"></i><b>D.9</b> Experimental Design Utilities</a></li>
<li class="chapter" data-level="D.10" data-path="appUtilitiesMisc.html"><a href="appUtilitiesMisc.html"><i class="fa fa-check"></i><b>D.10</b> Miscellaneous Utilities</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>E</b> Distributions</a>
<ul>
<li class="chapter" data-level="E.1" data-path="appDiscreteDistributions.html"><a href="appDiscreteDistributions.html"><i class="fa fa-check"></i><b>E.1</b> Discrete Distrbutions</a></li>
<li class="chapter" data-level="E.2" data-path="appContinuousDistributions.html"><a href="appContinuousDistributions.html"><i class="fa fa-check"></i><b>E.2</b> Continuous Distrbutions</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="appStatTables.html"><a href="appStatTables.html"><i class="fa fa-check"></i><b>F</b> Statistical Tables</a></li>
<li class="chapter" data-level="G" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>G</b> References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Simulation Modeling using the Kotlin Simulation Library (KSL)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch9GMVRVs" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Generating Multi-Variate and Correlated Random Variates<a href="ch9GMVRVs.html#ch9GMVRVs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The purpose of this section is to present the KSL constructs that facilitate the sampling from multi-variate distributions. In order to do this, we will discuss some of the common methods for generating correlated random variables. We will focus on those techniques that have implementations within the KSL. The presentation will be focused on the practical application of the methods rather than the theory. Because it will be instructive, we will start with generating from bi-variate distributions, specifically the bi-variate normal distribution.</p>
<div id="generating-from-a-bivariate-normal-distribution" class="section level3 hasAnchor" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Generating from a Bivariate Normal Distribution<a href="ch9GMVRVs.html#generating-from-a-bivariate-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A bivariate normal distribution is specified by the expected values, variances, and correlation between the random variables. For an excellent refresher on the mathematical basis for bivariate normal random variables, we refer the reader to <span class="citation">(<a href="#ref-pishro-nik">Pishro-Nik 2014</a>)</span> and specifically <a href="https://www.probabilitycourse.com/chapter5/5_3_2_bivariate_normal_dist.php">Section 5.3.2</a>.</p>
<p>We specify a bivariate normal random variables as <span class="math inline">\((X_1, X_2) \sim BVN(\mu_1, \sigma^2_1,\mu_2, \sigma^2_2,\rho)\)</span>. The key result necessary for generating BVN random variables is the following procedure:</p>
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(Z_1\)</span> and <span class="math inline">\(Z_2\)</span> be independent <span class="math inline">\(N(0,1)\)</span> random variables.</li>
<li>Define <span class="math inline">\(X_1 = \sigma_1 Z_1 + \mu_1\)</span> and <span class="math inline">\(X_2 = \sigma_2(\rho Z_1 + \sqrt{(1-\rho^2)} Z_2) + \mu_2\)</span>, where <span class="math inline">\(-1&lt;\rho&lt;1\)</span>.</li>
<li>Then, <span class="math inline">\((X_1, X_2) \sim BVN(\mu_1, \sigma^2_1,\mu_12, \sigma^2_2,\rho)\)</span></li>
</ol>
<p>An outline for the proof of this result can be found in <span class="citation">(<a href="#ref-pishro-nik">Pishro-Nik 2014</a>)</span>, <a href="https://www.probabilitycourse.com/chapter5/5_3_2_bivariate_normal_dist.php">Section 5.3.2</a>. Thus, if we can generate independent standard normal random variables, we can generate bivariate normal random variables via simple algebra. As can be seen in the following code, the KSL <code>BivariateNormalRV</code> class uses this procedure to generate an array that contains the bivariate normal sample.</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb381-1"><a href="ch9GMVRVs.html#cb381-1" tabindex="-1"></a><span class="kw">class</span> BivariateNormalRV<span class="op">(</span></span>
<span id="cb381-2"><a href="ch9GMVRVs.html#cb381-2" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">mean1</span><span class="op">:</span> <span class="dt">Double</span> <span class="op">=</span> <span class="fl">0.0</span><span class="op">,</span></span>
<span id="cb381-3"><a href="ch9GMVRVs.html#cb381-3" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">v1</span><span class="op">:</span> <span class="dt">Double</span> <span class="op">=</span> <span class="fl">1.0</span><span class="op">,</span></span>
<span id="cb381-4"><a href="ch9GMVRVs.html#cb381-4" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">mean2</span><span class="op">:</span> <span class="dt">Double</span> <span class="op">=</span> <span class="fl">0.0</span><span class="op">,</span></span>
<span id="cb381-5"><a href="ch9GMVRVs.html#cb381-5" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">v2</span><span class="op">:</span> <span class="dt">Double</span> <span class="op">=</span> <span class="fl">1.0</span><span class="op">,</span></span>
<span id="cb381-6"><a href="ch9GMVRVs.html#cb381-6" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">corr</span><span class="op">:</span> <span class="dt">Double</span> <span class="op">=</span> <span class="fl">0.0</span><span class="op">,</span></span>
<span id="cb381-7"><a href="ch9GMVRVs.html#cb381-7" tabindex="-1"></a>    <span class="va">stream</span><span class="op">:</span> <span class="dt">RNStreamIfc</span> <span class="op">=</span> KSLRandom<span class="op">.</span>nextRNStream<span class="op">(),</span></span>
<span id="cb381-8"><a href="ch9GMVRVs.html#cb381-8" tabindex="-1"></a>    <span class="va">name</span><span class="op">:</span> <span class="dt">String</span><span class="op">?</span> <span class="op">=</span> null</span>
<span id="cb381-9"><a href="ch9GMVRVs.html#cb381-9" tabindex="-1"></a><span class="op">)</span> <span class="op">:</span> <span class="dt">MVRVariable</span><span class="op">(</span><span class="va">stream</span><span class="op">,</span> <span class="va">name</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb381-10"><a href="ch9GMVRVs.html#cb381-10" tabindex="-1"></a><span class="op">.</span></span>
<span id="cb381-11"><a href="ch9GMVRVs.html#cb381-11" tabindex="-1"></a><span class="op">.</span></span>
<span id="cb381-12"><a href="ch9GMVRVs.html#cb381-12" tabindex="-1"></a><span class="op">.</span></span>
<span id="cb381-13"><a href="ch9GMVRVs.html#cb381-13" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">fun</span> <span class="fu">generate</span><span class="op">(</span><span class="va">array</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb381-14"><a href="ch9GMVRVs.html#cb381-14" tabindex="-1"></a>        require<span class="op">(</span>array<span class="op">.</span>size <span class="op">==</span> dimension<span class="op">)</span> <span class="op">{</span> <span class="st">&quot;The size of the array to fill does not match the sampling dimension!&quot;</span> <span class="op">}</span></span>
<span id="cb381-15"><a href="ch9GMVRVs.html#cb381-15" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">z0</span> <span class="op">=</span> Normal<span class="op">.</span>stdNormalInvCDF<span class="op">(</span>rnStream<span class="op">.</span>randU01<span class="op">())</span></span>
<span id="cb381-16"><a href="ch9GMVRVs.html#cb381-16" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">z1</span> <span class="op">=</span> Normal<span class="op">.</span>stdNormalInvCDF<span class="op">(</span>rnStream<span class="op">.</span>randU01<span class="op">())</span></span>
<span id="cb381-17"><a href="ch9GMVRVs.html#cb381-17" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">s1</span> <span class="op">=</span> sqrt<span class="op">(</span>v1<span class="op">)</span></span>
<span id="cb381-18"><a href="ch9GMVRVs.html#cb381-18" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">s2</span> <span class="op">=</span> sqrt<span class="op">(</span>v2<span class="op">)</span></span>
<span id="cb381-19"><a href="ch9GMVRVs.html#cb381-19" tabindex="-1"></a>        array<span class="op">[</span><span class="dv">0</span><span class="op">]</span> <span class="op">=</span> mean1 <span class="op">+</span> s1 <span class="op">*</span> z0</span>
<span id="cb381-20"><a href="ch9GMVRVs.html#cb381-20" tabindex="-1"></a>        array<span class="op">[</span><span class="dv">1</span><span class="op">]</span> <span class="op">=</span> mean2 <span class="op">+</span> s2 <span class="op">*</span> <span class="op">(</span>corr <span class="op">*</span> z0 <span class="op">+</span> sqrt<span class="op">(</span><span class="fl">1.0</span> <span class="op">-</span> corr <span class="op">*</span> corr<span class="op">)</span> <span class="op">*</span> z1<span class="op">)</span></span>
<span id="cb381-21"><a href="ch9GMVRVs.html#cb381-21" tabindex="-1"></a>    <span class="op">}</span></span></code></pre></div>
<p>Figure <a href="ch9GMVRVs.html#fig:BVNRV">9.7</a> presents the key classes and interfaces involved in the generation of a BVN sample. Notice that the <code>BivariateNormalRV</code> class sub-classes from the <code>MVRVariable</code> class, which in turn implements the <code>MVRVariableIfc</code> and the <code>MVSampleIfc</code> interfaces. The key is the <code>generate(array: DoubleArray)</code> method, in which the generation algorithm must be implemented.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:BVNRV"></span>
<img src="figures2/ch9/BivariateNormalRV.png" alt="Key Classes for BVN Generation" width="80%" height="80%" />
<p class="caption">
Figure 9.7: Key Classes for BVN Generation
</p>
</div>
<p>The functionality of the <code>MVSampleIfc</code> interface is especially noteworthy, with the following methods:</p>
<ul>
<li><code>sample(): DoubleArray</code> - generates an array that holds the sample</li>
<li><code>sample(array: DoubleArray)</code> - fills the supplied array with the generated values</li>
<li><code>sample(sampleSize: Int): List&lt;DoubleArray&gt;</code> - generates a list holding the randomly generated arrays. This can easily be converted to a 2-dimensional array that contains the samples as its rows.</li>
<li><code>sampleByColumn(sampleSize: Int): Array&lt;DoubleArray&gt;</code> - generates a 2-dimensional array (matrix) where the columns
contain the samples.</li>
<li><code>sample(values: Array&lt;DoubleArray&gt;)</code> - fills the supplied array of arrays with randomly generated samples by rows.</li>
</ul>
<p>The key property is the <code>dimension</code> property, which specifies the size of the array from the <code>sample()</code> method. In the case of the BVN random variable, the dimension is equal to 2. As you can see from Figure <a href="ch9GMVRVs.html#fig:BVNRV">9.7</a> the analogies with the one dimensional <code>SampleIfc</code> and <code>RVariableIfc</code> interfaces described in Section <a href="rvg.html#rvg">2.2</a> should be clear. In addition, the <code>MVRVariableIfc</code>interface implements the <code>RNStreamControlIfc</code> and <code>RNStreamChangeIfc</code> interfaces. As you may recall, the <code>RNStreamControlIfc</code> interface allows you to control the underlying stream of random numbers. The multi-dimensional case works the same as in the single variate case. Thus, sampling multi-variate distributions should be a straightforward step as long as you realize that you are generating arrays of data.</p>
<p>There are only two directly implemented bi-variate distributions the bivariate normal and the bivariate lognormal distribution. The implementation of the bivariate lognormal is conceptually similar to that of the bivariate normal. Since it can be shown that for the previously discussed bivariate normal procedure that the generated <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are individually normally distributed then the algorithm for the generating from the bivariate lognormal distribution is straightforward because of the relationship between the two random variables. That is, if <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span> then the random variable <span class="math inline">\(Y=e^X\)</span> will be lognormally distributed <span class="math inline">\(LN(\mu_l,\sigma_{l}^{2})\)</span>, where</p>
<p><span class="math display">\[
E[Y] = \mu_l = e^{\mu + \sigma^{2}/2}
\]</span></p>
<p><span class="math display">\[
\text{Var}[Y] = \sigma_{l}^{2}  = e^{2\mu + \sigma^{2}}\left(e^{\sigma^{2}} - 1\right)
\]</span>
Thus, in implemented the bivariate lognormal distribution, we just need to generate BVN random variable and apply <span class="math inline">\(Y=e^X\)</span>. This is shown in the <code>generate()</code> method of the <code>BivariateLogNormalRV</code> class.</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb382-1"><a href="ch9GMVRVs.html#cb382-1" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">fun</span> <span class="fu">generate</span><span class="op">(</span><span class="va">array</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb382-2"><a href="ch9GMVRVs.html#cb382-2" tabindex="-1"></a>        require<span class="op">(</span>array<span class="op">.</span>size <span class="op">==</span> dimension<span class="op">)</span> <span class="op">{</span> <span class="st">&quot;The size of the array to fill does not match the sampling dimension!&quot;</span> <span class="op">}</span></span>
<span id="cb382-3"><a href="ch9GMVRVs.html#cb382-3" tabindex="-1"></a>        myBVN<span class="op">.</span>sample<span class="op">(</span>array<span class="op">)</span></span>
<span id="cb382-4"><a href="ch9GMVRVs.html#cb382-4" tabindex="-1"></a>        <span class="co">// transform them to bi-variate lognormal</span></span>
<span id="cb382-5"><a href="ch9GMVRVs.html#cb382-5" tabindex="-1"></a>        array<span class="op">[</span><span class="dv">0</span><span class="op">]</span> <span class="op">=</span> exp<span class="op">(</span>array<span class="op">[</span><span class="dv">0</span><span class="op">])</span></span>
<span id="cb382-6"><a href="ch9GMVRVs.html#cb382-6" tabindex="-1"></a>        array<span class="op">[</span><span class="dv">1</span><span class="op">]</span> <span class="op">=</span> exp<span class="op">(</span>array<span class="op">[</span><span class="dv">1</span><span class="op">])</span></span>
<span id="cb382-7"><a href="ch9GMVRVs.html#cb382-7" tabindex="-1"></a>    <span class="op">}</span></span></code></pre></div>
<p>Developing your own bivariate generation classes can readily be accomplished by following the pattern presented by the <code>BivariateNormalRV</code> and <code>BivariateLogNormalRV</code> classes and sub-classing from the <code>MVRVariable</code> abstract base class. In this section, we discussed the generation of bivariate normal random variables. The key concept to remember moving into the next section is that now we have a procedure for generating correlated random variables. While the generation of bivariate lognormal random variables used the fact that we can generate bivariate normal random variables, we will see that these ideas can be generalized.</p>
</div>
<div id="copulas-and-multi-variate-generation-methods" class="section level3 hasAnchor" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Copulas and Multi-variate Generation Methods<a href="ch9GMVRVs.html#copulas-and-multi-variate-generation-methods" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section, we will discuss general approaches for generating multi-variate random variables. To reduce the burden of excessive notation, the presentation will focus on the 2-dimensional case. This should not limit the ideas because the concepts can be readily generalized to higher dimensions. One of the most useful concepts used in the generation of multi-variate random variates is that of a copula.</p>
<hr />
<div class="definition">
<p><span id="def:Copula" class="definition"><strong>Definition 9.1  (Copula) </strong></span>A d-dimensional <em>copula</em>, <span class="math inline">\(C : [0,1]^d : \rightarrow [0,1]\)</span> is a cumulative distribution function (CDF) with uniform marginals. That is, if we have a joint distribution of random variables, <span class="math inline">\((U_1, U_2,\cdots, U_d)\)</span> where each <span class="math inline">\(U_i \sim U(0,1)\)</span>, then the copula is the joint CDF:
<span class="math display">\[
C(u_1, u_2, \cdots, u_d) = P\{U_1 \leq u_1, U_2 \leq u_2, \cdots, U_d \leq u_d\}
\]</span></p>
</div>
<hr />
<p>Note that in the definition of a copula, the <span class="math inline">\((U_1, U_2,\cdots, U_d)\)</span> are not assumed to be independent. In fact, the whole point is for them to have a dependence structure. A definitive reference text on copulas, their properties and their uses can be found in <span class="citation">(<a href="#ref-rbNelson1999">R. B. Nelson 1999</a>)</span>. The main theorem concerning copulas that is relevant to our discussion is due to <span class="citation">(<a href="#ref-sklar1959">Sklar 1959</a>)</span>, see <span class="citation">(<a href="#ref-rbNelson1999">R. B. Nelson 1999</a>)</span> for a proof and further discussion.</p>
<hr />
<div class="theorem">
<p><span id="thm:Sklar" class="theorem"><strong>Theorem 9.1  (Sklar's Theorem) </strong></span>For any random variables, <span class="math inline">\((X_1, X_2, \cdots, X_d)\)</span> with joint CDF:
<span class="math display">\[
F(x_1, x_2, \cdots, x_d) = P\{X_1 \leq x_1, X_2 \leq x_2, \cdots, X_d \leq x_d\}
\]</span>
and marginals <span class="math inline">\(F_j(x) = P(X_j \leq x_j)\)</span> for <span class="math inline">\(j=1, 2, \cdots, d\)</span>, there exists a copula, such that:
<span class="math display">\[
F(x_1, x_2, \cdots, x_d) = C(F_1(x_1),F_2(x_2), \cdots, F_d(x_d) )
\]</span>
If each <span class="math inline">\(F_j(x)\)</span> is continuous, then the copula, <span class="math inline">\(C(\cdot)\)</span> will be unique.</p>
</div>
<hr />
<p>Because of Theorem <a href="ch9GMVRVs.html#thm:Sklar">9.1</a>, we can express the joint CDF, <span class="math inline">\(F(\cdot)\)</span> in terms of a copula, <span class="math inline">\(C(\cdot)\)</span> and a set of marginal distribution functions, <span class="math inline">\(F_j(x_j)\)</span>. This fact allows us to separate the marginals, <span class="math inline">\(F_j(x_j)\)</span> from the dependence structure implied by the copula, <span class="math inline">\(C(\cdot)\)</span>. This is extremely useful because it allows us to generate dependent <span class="math inline">\((U_1, U_2,\cdots, U_d)\)</span> and then use the inverse transform technique to generate from each marginal, <span class="math inline">\(F_j(x_j)\)</span> so that the resulting <span class="math inline">\(X_j\)</span> have a dependence structure implied by the specified copula.</p>
<p>There are many possible choices for specifying copulas. One way to specify a copula is to extract it from a known joint distribution <span class="math inline">\(F(\cdot)\)</span> via an inverse transform operation:</p>
<p><span class="math display">\[
C(u_1, u_2, \cdots, u_d) = F(F_1^{-1}(u_1),F_2^{-1}(u_2), \cdots, F_d^{-1}(u_d) )
\]</span>
The resulting copula will then take on its name from the joint distribution, <span class="math inline">\(F\)</span>, assuming that the marginals are continuous.</p>
<p>An example of this is the so called Gaussian copula. Let <span class="math inline">\(\mathbf{X} \sim \text{MVN}_d(\vec{0}, \mathbf{P})\)</span> be a multi-variate normal random variable, where <span class="math inline">\(\mathbf{P}\)</span> is the correlation matrix of <span class="math inline">\(\mathbf{X}\)</span>. Then, the Gaussian copula is as follows:</p>
<p><span class="math display">\[
C^G_{\mathbf{P}}(u_1, u_2, \cdots, u_d) = \Phi_{\mathbf{P}}(\Phi_1^{-1}(u_1),\Phi_2^{-1}(u_2), \cdots, \Phi_d^{-1}(u_d) )
\]</span>
where <span class="math inline">\(\Phi(\cdot)\)</span> is the standard normal CDF and <span class="math inline">\(\Phi_{\mathbf{P}}(\cdot)\)</span> is the joint CDF of <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>To make this concrete, letâ€™s consider the bivariate normal copula. Let <span class="math inline">\((X_1, X_2)\)</span> be from a bivariate normal distribution such that <span class="math inline">\(\text{BVN}(\mu_1=0, \sigma^2_1=1,\mu_2 =0, \sigma^2_2 = 1,\rho)\)</span>. Now to generate from the Gaussian copula, we have the following algorithm:</p>
<ol style="list-style-type: decimal">
<li>Generate <span class="math inline">\(Z_1 \sim N(0,1)\)</span> and <span class="math inline">\(Z_2 \sim N(0,1)\)</span>
<ol style="list-style-type: lower-alpha">
<li>Generate <span class="math inline">\(V_1 \sim U(0,1)\)</span> and <span class="math inline">\(V_2 \sim U(0,1)\)</span></li>
<li>Let <span class="math inline">\(z_1 = \Phi^{-1}(v_1)\)</span> and <span class="math inline">\(z_2 = \Phi^{-1}(v_2)\)</span></li>
</ol></li>
<li>Let <span class="math inline">\(x_1 = z_1\)</span> and <span class="math inline">\(x_2 = \rho z_1 + z_2\sqrt{(1-\rho^2)}\)</span>.</li>
<li>Let <span class="math inline">\(u_1 = \Phi(x_1)\)</span> and <span class="math inline">\(u_2 = \Phi(x_2)\)</span></li>
<li>Return <span class="math inline">\((u_1, u_2)\)</span></li>
</ol>
<p>The bivariate random variate <span class="math inline">\((u_1, u_2)\)</span> returned from this algorithm will be from a bivariate Gaussian copula. The random variables from this copula, <span class="math inline">\((U_1, U_2)\)</span> will be correlated because the generated <span class="math inline">\((x_1, x_2)\)</span> will have correlation <span class="math inline">\(\rho\)</span>. Thus, we can use the correlated random variables <span class="math inline">\((U_1, U_2)\)</span> to generate other random variables that have a dependence structure that is implied by the correlation between <span class="math inline">\((U_1, U_2)\)</span>.</p>
<p>For example let <span class="math inline">\(\vec{Y} = (Y_1, Y_2)\)</span> be a random vector and let <span class="math inline">\(F_{Y_1}(\cdot)\)</span> and <span class="math inline">\(F_{Y_2}(\cdot)\)</span> be the marginal distributions associated with <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span>. Then, we can generate <span class="math inline">\(\vec{Y}\)</span> as follows:</p>
<p><span class="math display">\[
Y_1 = F^{-1}_{Y_1}(u_1) = F^{-1}_{Y_1}(\Phi(x_1))\\
Y_2 = F^{-1}_{Y_2}(u_1) = F^{-1}_{Y_2}(\Phi(x_2))\\
\]</span>
where <span class="math inline">\(x_1 = z_1\)</span> with <span class="math inline">\(Z_1 \sim N(0,1)\)</span> and <span class="math inline">\(x_2 = \rho z_1 + z_2\sqrt{(1-\rho^2)}\)</span> with <span class="math inline">\(Z_2 \sim N(0,1)\)</span>. This will cause the vector, <span class="math inline">\(\vec{Y}\)</span> to have the corresponding Gaussian BVN copula. The KSL <code>BVGaussianCopulaRV</code> class implements these ideas to generate bivariate correlated random variables. The user is required to supply the inverse CDF functions for the two marginals. Note that, in general, the two distributions, <span class="math inline">\(F_{Y_1}(\cdot)\)</span> and <span class="math inline">\(F_{Y_2}(\cdot)\)</span> do not have to be from the same family. In addition, as long as the inverse CDF function is available the distribution could be discrete or continuous.</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb383-1"><a href="ch9GMVRVs.html#cb383-1" tabindex="-1"></a><span class="kw">class</span> BVGaussianCopulaRV<span class="op">(</span></span>
<span id="cb383-2"><a href="ch9GMVRVs.html#cb383-2" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">marginal1</span><span class="op">:</span> <span class="dt">InverseCDFIfc</span><span class="op">,</span></span>
<span id="cb383-3"><a href="ch9GMVRVs.html#cb383-3" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">marginal2</span><span class="op">:</span> <span class="dt">InverseCDFIfc</span><span class="op">,</span></span>
<span id="cb383-4"><a href="ch9GMVRVs.html#cb383-4" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">bvnCorrelation</span><span class="op">:</span> <span class="dt">Double</span><span class="op">,</span></span>
<span id="cb383-5"><a href="ch9GMVRVs.html#cb383-5" tabindex="-1"></a>    <span class="va">stream</span><span class="op">:</span> <span class="dt">RNStreamIfc</span> <span class="op">=</span> KSLRandom<span class="op">.</span>nextRNStream<span class="op">()</span></span>
<span id="cb383-6"><a href="ch9GMVRVs.html#cb383-6" tabindex="-1"></a><span class="op">)</span> <span class="op">:</span> <span class="dt">MVRVariable</span><span class="op">(</span><span class="va">stream</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb383-7"><a href="ch9GMVRVs.html#cb383-7" tabindex="-1"></a></span>
<span id="cb383-8"><a href="ch9GMVRVs.html#cb383-8" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">bvGaussianCopula</span> <span class="op">=</span> BVGaussianCopula<span class="op">(</span>bvnCorrelation<span class="op">,</span> stream<span class="op">)</span></span>
<span id="cb383-9"><a href="ch9GMVRVs.html#cb383-9" tabindex="-1"></a></span>
<span id="cb383-10"><a href="ch9GMVRVs.html#cb383-10" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">val</span> <span class="va">dimension</span><span class="op">:</span> <span class="kw">Int</span></span>
<span id="cb383-11"><a href="ch9GMVRVs.html#cb383-11" tabindex="-1"></a>        <span class="kw">get</span><span class="op">()</span> <span class="op">=</span> bvGaussianCopula<span class="op">.</span>dimension</span>
<span id="cb383-12"><a href="ch9GMVRVs.html#cb383-12" tabindex="-1"></a></span>
<span id="cb383-13"><a href="ch9GMVRVs.html#cb383-13" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">fun</span> <span class="fu">generate</span><span class="op">(</span><span class="va">array</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb383-14"><a href="ch9GMVRVs.html#cb383-14" tabindex="-1"></a>        require<span class="op">(</span>array<span class="op">.</span>size <span class="op">==</span> dimension<span class="op">)</span> <span class="op">{</span> <span class="st">&quot;The length of the array was not the proper dimension&quot;</span> <span class="op">}</span></span>
<span id="cb383-15"><a href="ch9GMVRVs.html#cb383-15" tabindex="-1"></a>        <span class="co">// generate the uniforms</span></span>
<span id="cb383-16"><a href="ch9GMVRVs.html#cb383-16" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">u</span> <span class="op">=</span> bvGaussianCopula<span class="op">.</span>sample<span class="op">()</span></span>
<span id="cb383-17"><a href="ch9GMVRVs.html#cb383-17" tabindex="-1"></a>        <span class="co">// apply the inverse transform for each of the marginals</span></span>
<span id="cb383-18"><a href="ch9GMVRVs.html#cb383-18" tabindex="-1"></a>        array<span class="op">[</span><span class="dv">0</span><span class="op">]</span> <span class="op">=</span> marginal1<span class="op">.</span>invCDF<span class="op">(</span>u<span class="op">[</span><span class="dv">0</span><span class="op">])</span></span>
<span id="cb383-19"><a href="ch9GMVRVs.html#cb383-19" tabindex="-1"></a>        array<span class="op">[</span><span class="dv">1</span><span class="op">]</span> <span class="op">=</span> marginal2<span class="op">.</span>invCDF<span class="op">(</span>u<span class="op">[</span><span class="dv">1</span><span class="op">])</span></span>
<span id="cb383-20"><a href="ch9GMVRVs.html#cb383-20" tabindex="-1"></a>    <span class="op">}</span></span></code></pre></div>
<p>This idea generalizes to the generation of random vectors of dimension, <span class="math inline">\(d\)</span>, if we use the <span class="math inline">\(d\)</span>-dimensional Gaussian copula, <span class="math inline">\(C^G_{\mathbf{P}}(\cdot)\)</span>. Thus, because of Sklarâ€™s Theorem the joint distribution of <span class="math inline">\(\vec{Y}\)</span> can be written using the specified Gaussian copula. This is due to the invariance of copulas to monotonic transformations, which is discussed in <span class="citation">(<a href="#ref-rbNelson1999">R. B. Nelson 1999</a>)</span>.</p>
<p>There are many different kinds of copulas that have been developed which can be used to generate correlated random variables. The general procedure is as follows:</p>
<ol style="list-style-type: decimal">
<li>Specify a copula and its parameters</li>
<li>Generate <span class="math inline">\(\vec{U} = (u_1, u_2,\cdots, u_d)\)</span> from the copula</li>
<li>Generate <span class="math inline">\(\vec{Y} = (Y_1, Y_2, \cdots, Y_d)\)</span>, where <span class="math inline">\(Y_i = F^{-1}_i(u_i)\)</span></li>
</ol>
<p>The generated vector <span class="math inline">\(\vec{Y}\)</span> will have a dependence structure that is determined by the dependence structure of the vector <span class="math inline">\(\vec{U}\)</span>. It is important to realize that the dependence structures of these two random vectors will be related, but not necessarily the same. The key is to specify a copula that is easy to generate from and to understand how its dependence structure translates to the desired dependence structure. <span class="citation">(<a href="#ref-Nelsen2004PropertiesAA">Nelsen 2004</a>)</span> presents a survey of the properties of various copulas. In addition, a comprehensive compendium of copulas is available in <span class="citation">(<a href="#ref-Nadarajah_Afuecheta_Chan_2017">Nadarajah, Afuecheta, and Chan 2017</a>)</span>.</p>
<p>The KSL supports the generation of random vectors due to its implementation of the multi-variate normal distribution. Thus, the Gaussian copula is available to KSL users. In addition, the formulas in <span class="citation">(<a href="#ref-Nadarajah_Afuecheta_Chan_2017">Nadarajah, Afuecheta, and Chan 2017</a>)</span> can be readily implemented for other copulas.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:KSLMVClasses"></span>
<img src="figures2/ch9/MVSampling.png" alt="Key Classes for Multi-Variate Generation" width="80%" height="80%" />
<p class="caption">
Figure 9.8: Key Classes for Multi-Variate Generation
</p>
</div>
<p>A d-dimensional multi-variate normal distribution is specified by a vector of means <span class="math inline">\(\vec{\mu} = (\mu_1, \mu_2, \cdots ,\mu_d)^{T}\)</span> and a <span class="math inline">\(d \times d\)</span> covariance matrix, <span class="math inline">\(\mathbf{\Sigma}\)</span>. The entries of <span class="math inline">\(\mathbf{\Sigma}\)</span> are <span class="math inline">\(\text{COV}(X_i, X_j)\)</span> and <span class="math inline">\(\mathbf{\Sigma}\)</span> is symmetric and positive definite. Define <span class="math inline">\(\mathbf{C}\)</span> a <span class="math inline">\(d \times d\)</span> matrix representing the Cholesky decomposition of <span class="math inline">\(\mathbf{\Sigma}\)</span>, where <span class="math inline">\(\mathbf{\Sigma} =\mathbf{C}\mathbf{C}^{T}\)</span>. Then the algorithm for generating MVN random variables is just an extension to the method for generating BVN random variables:</p>
<ol style="list-style-type: decimal">
<li>Generate <span class="math inline">\((Z_1, Z_2, \cdots, Z_d)\)</span> as IID <span class="math inline">\(N(0,1)\)</span> random variables</li>
<li>For <span class="math inline">\(i=1,2,\cdots,d\)</span>, let <span class="math inline">\(X_i = \mu_i + \sum_{j=1}^{i}c_{ij}Z_j\)</span>, where <span class="math inline">\(c_ij\)</span> is the <span class="math inline">\((i,j)\)</span>th element of <span class="math inline">\(\mathbf{C}\)</span>, Return <span class="math inline">\((X_1, X_2, \cdots, X_d)\)</span></li>
</ol>
<p>The KSL <code>MVNormalRV</code> implements this algorithm.</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb384-1"><a href="ch9GMVRVs.html#cb384-1" tabindex="-1"></a><span class="kw">class</span> MVNormalRV <span class="kw">constructor</span><span class="op">(</span></span>
<span id="cb384-2"><a href="ch9GMVRVs.html#cb384-2" tabindex="-1"></a>    <span class="va">means</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">,</span></span>
<span id="cb384-3"><a href="ch9GMVRVs.html#cb384-3" tabindex="-1"></a>    <span class="va">covariances</span><span class="op">:</span> <span class="dt">Array</span>&lt;<span class="va">DoubleArray</span>&gt;<span class="op">,</span></span>
<span id="cb384-4"><a href="ch9GMVRVs.html#cb384-4" tabindex="-1"></a>    <span class="va">stream</span><span class="op">:</span> <span class="dt">RNStreamIfc</span> <span class="op">=</span> KSLRandom<span class="op">.</span>nextRNStream<span class="op">()</span></span>
<span id="cb384-5"><a href="ch9GMVRVs.html#cb384-5" tabindex="-1"></a><span class="op">)</span> <span class="op">:</span> <span class="dt">MVRVariableIfc</span></span></code></pre></div>
<p>An example for generating from a MVN is shown in the following code.</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb385-1"><a href="ch9GMVRVs.html#cb385-1" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">cov</span> <span class="op">=</span> arrayOf<span class="op">(</span></span>
<span id="cb385-2"><a href="ch9GMVRVs.html#cb385-2" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">1.0</span><span class="op">,</span> <span class="fl">1.0</span><span class="op">,</span> <span class="fl">1.0</span><span class="op">,</span> <span class="fl">1.0</span><span class="op">),</span></span>
<span id="cb385-3"><a href="ch9GMVRVs.html#cb385-3" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">),</span></span>
<span id="cb385-4"><a href="ch9GMVRVs.html#cb385-4" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">3.0</span><span class="op">,</span> <span class="fl">3.0</span><span class="op">,</span> <span class="fl">3.0</span><span class="op">),</span></span>
<span id="cb385-5"><a href="ch9GMVRVs.html#cb385-5" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">3.0</span><span class="op">,</span> <span class="fl">4.0</span><span class="op">,</span> <span class="fl">4.0</span><span class="op">),</span></span>
<span id="cb385-6"><a href="ch9GMVRVs.html#cb385-6" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">3.0</span><span class="op">,</span> <span class="fl">4.0</span><span class="op">,</span> <span class="fl">5.0</span><span class="op">)</span></span>
<span id="cb385-7"><a href="ch9GMVRVs.html#cb385-7" tabindex="-1"></a>    <span class="op">)</span></span>
<span id="cb385-8"><a href="ch9GMVRVs.html#cb385-8" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">means</span> <span class="op">=</span> doubleArrayOf<span class="op">(</span><span class="fl">10.0</span><span class="op">,</span> <span class="fl">10.0</span><span class="op">,</span> <span class="fl">10.0</span><span class="op">,</span> <span class="fl">10.0</span><span class="op">,</span> <span class="fl">10.0</span><span class="op">)</span></span>
<span id="cb385-9"><a href="ch9GMVRVs.html#cb385-9" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">rv</span> <span class="op">=</span> MVNormalRV<span class="op">(</span>means<span class="op">,</span> cov<span class="op">)</span></span>
<span id="cb385-10"><a href="ch9GMVRVs.html#cb385-10" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span>i <span class="kw">in</span> <span class="fl">1..5</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb385-11"><a href="ch9GMVRVs.html#cb385-11" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">sample</span><span class="op">:</span> DoubleArray <span class="op">=</span> rv<span class="op">.</span>sample<span class="op">()</span></span>
<span id="cb385-12"><a href="ch9GMVRVs.html#cb385-12" tabindex="-1"></a>        println<span class="op">(</span>KSLArrays<span class="op">.</span>toCSVString<span class="op">(</span>sample<span class="op">))</span></span>
<span id="cb385-13"><a href="ch9GMVRVs.html#cb385-13" tabindex="-1"></a>    <span class="op">}</span></span></code></pre></div>
<p>This code produces the following output.</p>
<pre><code>10.608312205708812, 12.427876158938025, 15.095818342789086, 13.895399804504395, 15.82457463544744
12.357092448543806, 12.093733136888977, 12.89119464537901, 12.45554505056937, 13.885758234303694
9.351088769471737, 9.08925546297716, 8.826393183582276, 9.972369809797016, 10.15999988875732
9.094163074400619, 8.983286878421879, 10.986502362541005, 10.212432226337382, 11.371691780443308
9.837869522611827, 9.038466912761681, 9.124068606401634, 9.590808967808215, 11.561395573689001</code></pre>
<p>To generate <span class="math inline">\((U_1, U_2,\cdots, U_d)\)</span> using a Gaussian copula, you can use the <code>MVGaussianCopula</code> class. This class requires the specification of the correlation matrix.</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb387-1"><a href="ch9GMVRVs.html#cb387-1" tabindex="-1"></a><span class="kw">class</span> MVGaussianCopula<span class="op">(</span></span>
<span id="cb387-2"><a href="ch9GMVRVs.html#cb387-2" tabindex="-1"></a>    <span class="va">correlation</span><span class="op">:</span> <span class="dt">Array</span>&lt;<span class="va">DoubleArray</span>&gt;<span class="op">,</span></span>
<span id="cb387-3"><a href="ch9GMVRVs.html#cb387-3" tabindex="-1"></a>    <span class="va">stream</span><span class="op">:</span> <span class="dt">RNStreamIfc</span> <span class="op">=</span> KSLRandom<span class="op">.</span>nextRNStream<span class="op">()</span></span>
<span id="cb387-4"><a href="ch9GMVRVs.html#cb387-4" tabindex="-1"></a><span class="op">)</span> <span class="op">:</span> <span class="dt">MVRVariable</span><span class="op">(</span><span class="va">stream</span><span class="op">){</span></span></code></pre></div>
<p>The following examples illustrates how to use the class.</p>
<div class="sourceCode" id="cb388"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb388-1"><a href="ch9GMVRVs.html#cb388-1" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">cov</span> <span class="op">=</span> arrayOf<span class="op">(</span></span>
<span id="cb388-2"><a href="ch9GMVRVs.html#cb388-2" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">1.0</span><span class="op">,</span> <span class="fl">1.0</span><span class="op">,</span> <span class="fl">1.0</span><span class="op">,</span> <span class="fl">1.0</span><span class="op">),</span></span>
<span id="cb388-3"><a href="ch9GMVRVs.html#cb388-3" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">),</span></span>
<span id="cb388-4"><a href="ch9GMVRVs.html#cb388-4" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">3.0</span><span class="op">,</span> <span class="fl">3.0</span><span class="op">,</span> <span class="fl">3.0</span><span class="op">),</span></span>
<span id="cb388-5"><a href="ch9GMVRVs.html#cb388-5" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">3.0</span><span class="op">,</span> <span class="fl">4.0</span><span class="op">,</span> <span class="fl">4.0</span><span class="op">),</span></span>
<span id="cb388-6"><a href="ch9GMVRVs.html#cb388-6" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">,</span> <span class="fl">3.0</span><span class="op">,</span> <span class="fl">4.0</span><span class="op">,</span> <span class="fl">5.0</span><span class="op">)</span></span>
<span id="cb388-7"><a href="ch9GMVRVs.html#cb388-7" tabindex="-1"></a>    <span class="op">)</span></span>
<span id="cb388-8"><a href="ch9GMVRVs.html#cb388-8" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">rho</span> <span class="op">=</span> MVNormalRV<span class="op">.</span>convertToCorrelation<span class="op">(</span>cov<span class="op">)</span></span>
<span id="cb388-9"><a href="ch9GMVRVs.html#cb388-9" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">rv</span> <span class="op">=</span> MVGaussianCopula<span class="op">(</span>rho<span class="op">)</span></span>
<span id="cb388-10"><a href="ch9GMVRVs.html#cb388-10" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span>i <span class="kw">in</span> <span class="fl">1..5</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb388-11"><a href="ch9GMVRVs.html#cb388-11" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">sample</span><span class="op">:</span> DoubleArray <span class="op">=</span> rv<span class="op">.</span>sample<span class="op">()</span></span>
<span id="cb388-12"><a href="ch9GMVRVs.html#cb388-12" tabindex="-1"></a>        println<span class="op">(</span>KSLArrays<span class="op">.</span>toCSVString<span class="op">(</span>sample<span class="op">))</span></span>
<span id="cb388-13"><a href="ch9GMVRVs.html#cb388-13" tabindex="-1"></a>    <span class="op">}</span></span></code></pre></div>
<p>This produces the following output, which are all marginal uniform random variables.</p>
<pre><code>0.7285097863655003, 0.9569891872203626, 0.9983698799092053, 0.9742745590896011, 0.9954039933624037
0.9907906696144968, 0.9306291228202694, 0.9524642953735563, 0.8902338139058006, 0.9588737889598452
0.2581978776398398, 0.2597897797244717, 0.24901831402144003, 0.49448874976678453, 0.5285216255173468
0.18251108664042276, 0.2360936451712804, 0.715511037152583, 0.542294556596819, 0.7302070177714262
0.4356015531081042, 0.24828181183321235, 0.3065268847809944, 0.4189440794684452, 0.757498112637931</code></pre>
<p>The <code>MVGaussianCopulaRV</code> class puts all these components together to generate random vectors using the d-dimensional Gaussian copula by allowing the user to specify the inverse CDF functions for the marginal distributions.</p>
<div class="sourceCode" id="cb390"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb390-1"><a href="ch9GMVRVs.html#cb390-1" tabindex="-1"></a><span class="kw">class</span> MVGaussianCopulaRV<span class="op">(</span></span>
<span id="cb390-2"><a href="ch9GMVRVs.html#cb390-2" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">marginals</span><span class="op">:</span> <span class="dt">List</span>&lt;<span class="va">InverseCDFIfc</span>&gt;<span class="op">,</span></span>
<span id="cb390-3"><a href="ch9GMVRVs.html#cb390-3" tabindex="-1"></a>    <span class="va">correlation</span><span class="op">:</span> <span class="dt">Array</span>&lt;<span class="va">DoubleArray</span>&gt;<span class="op">,</span></span>
<span id="cb390-4"><a href="ch9GMVRVs.html#cb390-4" tabindex="-1"></a>    <span class="va">stream</span><span class="op">:</span> <span class="dt">RNStreamIfc</span> <span class="op">=</span> KSLRandom<span class="op">.</span>nextRNStream<span class="op">()</span></span>
<span id="cb390-5"><a href="ch9GMVRVs.html#cb390-5" tabindex="-1"></a><span class="op">)</span> <span class="op">:</span> <span class="dt">MVRVariable</span><span class="op">(</span><span class="va">stream</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb390-6"><a href="ch9GMVRVs.html#cb390-6" tabindex="-1"></a></span>
<span id="cb390-7"><a href="ch9GMVRVs.html#cb390-7" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">myCopula</span> <span class="op">=</span> MVGaussianCopula<span class="op">(</span>correlation<span class="op">,</span> stream<span class="op">)</span></span>
<span id="cb390-8"><a href="ch9GMVRVs.html#cb390-8" tabindex="-1"></a><span class="op">.</span></span>
<span id="cb390-9"><a href="ch9GMVRVs.html#cb390-9" tabindex="-1"></a><span class="op">.</span></span>
<span id="cb390-10"><a href="ch9GMVRVs.html#cb390-10" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">fun</span> <span class="fu">generate</span><span class="op">(</span><span class="va">array</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb390-11"><a href="ch9GMVRVs.html#cb390-11" tabindex="-1"></a>        require<span class="op">(</span>array<span class="op">.</span>size <span class="op">==</span> dimension<span class="op">)</span> <span class="op">{</span> <span class="st">&quot;The length of the array was not the proper dimension&quot;</span> <span class="op">}</span></span>
<span id="cb390-12"><a href="ch9GMVRVs.html#cb390-12" tabindex="-1"></a>        <span class="co">// generate the uniforms</span></span>
<span id="cb390-13"><a href="ch9GMVRVs.html#cb390-13" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">u</span> <span class="op">=</span> myCopula<span class="op">.</span>sample<span class="op">()</span></span>
<span id="cb390-14"><a href="ch9GMVRVs.html#cb390-14" tabindex="-1"></a>        <span class="co">// apply the inverse transform for each of the marginals</span></span>
<span id="cb390-15"><a href="ch9GMVRVs.html#cb390-15" tabindex="-1"></a>        <span class="cf">for</span> <span class="op">(</span>i <span class="kw">in</span> u<span class="op">.</span>indices<span class="op">)</span> <span class="op">{</span></span>
<span id="cb390-16"><a href="ch9GMVRVs.html#cb390-16" tabindex="-1"></a>            array<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> marginals<span class="op">[</span>i<span class="op">].</span>invCDF<span class="op">(</span>u<span class="op">[</span>i<span class="op">])</span></span>
<span id="cb390-17"><a href="ch9GMVRVs.html#cb390-17" tabindex="-1"></a>        <span class="op">}</span></span>
<span id="cb390-18"><a href="ch9GMVRVs.html#cb390-18" tabindex="-1"></a>    <span class="op">}</span></span></code></pre></div>
<p>Similar strategies can be implemented for other copula specifications.</p>
</div>
<div id="autocorrelated-generation" class="section level3 hasAnchor" number="9.3.3">
<h3><span class="header-section-number">9.3.3</span> Autocorrelated Generation<a href="ch9GMVRVs.html#autocorrelated-generation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This section involves how to explicitly model dependence (autocorrelation) within random samples. An important application is to generate correlated values from simulation input models. In the fitting of input models, it was assumed and tested that the sample observations did not have correlation. But, what do you do if the data does have correlation? For example, let <span class="math inline">\(X_i\)</span> be the service time of the <span class="math inline">\(i^{th}\)</span> customer. What if the <span class="math inline">\(X_i\)</span> have significant correlation? That is, the service times are correlated. Input processes might also correlated. That is, the time between arrivals might be correlated. Research has shown, see see
<span class="citation">(<a href="#ref-patuwo1993the">Patuwo, Disney, and Mcnickle 1993</a>)</span> and <span class="citation">(<a href="#ref-livny1993the">Livny, Melamed, and Tsiolis 1993</a>)</span>, that ignoring the correlation when it is in fact present can lead to gross underestimation of the actual performance estimates for the system.</p>
<p>The discussion here is based on the Normal-to-Anything Transformation as discussed in <span class="citation">Banks et al. (<a href="#ref-banks2005discreteevent">2005</a>)</span>, <span class="citation">(<a href="#ref-cario1998numerical">Cario and Nelson 1998</a>)</span>, <span class="citation">(<a href="#ref-cario1996autoregressive">Cario and Nelson 1996</a>)</span>, and <span class="citation">(<a href="#ref-biller2003modeling">Biller and Nelson 2003</a>)</span>. Suppose you have a <span class="math inline">\(N(0,1)\)</span> random variable, <span class="math inline">\(Z_i\)</span>, and a way to compute the CDF, <span class="math inline">\(\Phi(z)\)</span>, of the normal distribution. Then, from the discussion of the inverse transform technique, the random variable, <span class="math inline">\(\Phi(Z_i)\)</span> will have a U(0,1) distribution. Suppose that you wanted to generate a random variable <span class="math inline">\(X_i\)</span> with CDF <span class="math inline">\(F(x)\)</span>, then you can use <span class="math inline">\(\Phi(Z_i)\)</span> as the source of uniform random numbers in an inverse transform technique.</p>
<p><span class="math display">\[
X_i = F^{-1}(U_i) = F^{-1}((\Phi(Z_i)))
\]</span>
This transform is called the normal-to-anything (NORTA) transformation. It can be shown that even if the <span class="math inline">\(Z_i\)</span> are correlated (and thus so are the <span class="math inline">\(\Phi(Z_i)\)</span> then the <span class="math inline">\(X_i\)</span> will have the correct CDF and will also be correlated. Unfortunately, the correlation is not directly preserved in the transformation so that if the <span class="math inline">\(Z_i\)</span> has correlation <span class="math inline">\(\rho_z\)</span> the <span class="math inline">\(X_i\)</span> will have <span class="math inline">\(\rho_x\)</span> (not necessarily the same). Thus, in order to induce correlation in the <span class="math inline">\(X_i\)</span> you must have a method to induce correlation in the <span class="math inline">\(Z_i\)</span>.</p>
<p>One method to induce correlation in the <span class="math inline">\(Z_i\)</span> is to generate the <span class="math inline">\(Z_i\)</span> from an stationary autoregressive time-series model of order 1, i.e.Â <span class="math inline">\(AR(1)\)</span>. A stationary <span class="math inline">\(AR(1)\)</span> model with <span class="math inline">\(N(0,1)\)</span> marginal distributions has the following form:</p>
<p><span class="math display">\[
Z_i = \phi(Z_{i-1}) + \varepsilon_i
\]</span></p>
<p>where <span class="math inline">\(i = 1,2,3,\ldots\)</span> and <span class="math inline">\(\varepsilon_i\)</span> are IID <span class="math inline">\(N(0,1-\phi^2)\)</span>, <span class="math inline">\(i = 1,2,3,\ldots\)</span>, <span class="math inline">\(-1&lt;\phi&lt;1\)</span>, and <span class="math inline">\(Z_1 \sim N(0,1)\)</span>. Thus, it is relatively straightforward to generate this process by first generating <span class="math inline">\(Z_1\)</span>, then generating <span class="math inline">\(\varepsilon_i \sim N(0,1-\phi^2)\)</span> and using <span class="math inline">\(Z_i = \phi(Z_{i-1}) + \varepsilon_i\)</span> to compute the next <span class="math inline">\(Z_i\)</span>. It can be shown that this <span class="math inline">\(AR(1)\)</span> process will have lag-1 correlation:</p>
<p><span class="math display">\[
\phi = \rho^1 = corr(Z_i, Z_{i+1})
\]</span>
Therefore, you can generate a random variable <span class="math inline">\(Z_i\)</span> that has a desired correlation and through the NORTA transformation produce <span class="math inline">\(X_i\)</span> that are correlated with the correlation being functionally related to <span class="math inline">\(\rho_z\)</span>. By changing <span class="math inline">\(\phi\)</span> through trial and error one can get the correlation for the <span class="math inline">\(X_i\)</span> that is desired. Procedures for accomplishing this are given in the previously mentioned references.</p>
<p>The implementation of this technique can be readily achieved in a general way within the KSL through the use of the <code>AR1NormalRV</code> class and already available constructs. The <code>AR1CorrelatedRNStream</code> class implements these ideas in the form of a stream that can be supplied to random variables and other constructs that require a stream.</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb391-1"><a href="ch9GMVRVs.html#cb391-1" tabindex="-1"></a><span class="kw">class</span> AR1CorrelatedRNStream<span class="op">(</span></span>
<span id="cb391-2"><a href="ch9GMVRVs.html#cb391-2" tabindex="-1"></a>    <span class="va">lag1Corr</span><span class="op">:</span> <span class="dt">Double</span><span class="op">,</span></span>
<span id="cb391-3"><a href="ch9GMVRVs.html#cb391-3" tabindex="-1"></a>    <span class="va">stream</span><span class="op">:</span> <span class="dt">RNStreamIfc</span> <span class="op">=</span> KSLRandom<span class="op">.</span>nextRNStream<span class="op">(),</span></span>
<span id="cb391-4"><a href="ch9GMVRVs.html#cb391-4" tabindex="-1"></a><span class="op">)</span> <span class="op">:</span> <span class="dt">RNStreamIfc</span> <span class="kw">by</span> stream <span class="op">{</span></span>
<span id="cb391-5"><a href="ch9GMVRVs.html#cb391-5" tabindex="-1"></a></span>
<span id="cb391-6"><a href="ch9GMVRVs.html#cb391-6" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">myAR1NormalRV</span> <span class="op">=</span> AR1NormalRV<span class="op">(</span>lag1Corr <span class="op">=</span> lag1Corr<span class="op">,</span> stream <span class="op">=</span> stream<span class="op">)</span></span>
<span id="cb391-7"><a href="ch9GMVRVs.html#cb391-7" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">var</span> <span class="va">myPrevU</span> <span class="op">:</span> <span class="kw">Double</span> <span class="op">=</span> <span class="kw">Double</span><span class="op">.</span>NaN</span>
<span id="cb391-8"><a href="ch9GMVRVs.html#cb391-8" tabindex="-1"></a></span>
<span id="cb391-9"><a href="ch9GMVRVs.html#cb391-9" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">ar1LagCorr</span></span>
<span id="cb391-10"><a href="ch9GMVRVs.html#cb391-10" tabindex="-1"></a>        <span class="kw">get</span><span class="op">()</span> <span class="op">=</span> myAR1NormalRV<span class="op">.</span>lag1Corr</span>
<span id="cb391-11"><a href="ch9GMVRVs.html#cb391-11" tabindex="-1"></a></span>
<span id="cb391-12"><a href="ch9GMVRVs.html#cb391-12" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">val</span> <span class="va">previousU</span><span class="op">:</span> <span class="kw">Double</span></span>
<span id="cb391-13"><a href="ch9GMVRVs.html#cb391-13" tabindex="-1"></a>        <span class="kw">get</span><span class="op">()</span> <span class="op">=</span> myPrevU</span>
<span id="cb391-14"><a href="ch9GMVRVs.html#cb391-14" tabindex="-1"></a></span>
<span id="cb391-15"><a href="ch9GMVRVs.html#cb391-15" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">fun</span> <span class="fu">randU01</span><span class="op">():</span> <span class="dt">Double</span> <span class="op">{</span></span>
<span id="cb391-16"><a href="ch9GMVRVs.html#cb391-16" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">z</span> <span class="op">=</span> myAR1NormalRV<span class="op">.</span>value</span>
<span id="cb391-17"><a href="ch9GMVRVs.html#cb391-17" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">u</span> <span class="op">=</span> Normal<span class="op">.</span>stdNormalCDF<span class="op">(</span>z<span class="op">)</span></span>
<span id="cb391-18"><a href="ch9GMVRVs.html#cb391-18" tabindex="-1"></a>        myPrevU <span class="op">=</span> u</span>
<span id="cb391-19"><a href="ch9GMVRVs.html#cb391-19" tabindex="-1"></a>        <span class="kw">return</span> u</span>
<span id="cb391-20"><a href="ch9GMVRVs.html#cb391-20" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb391-21"><a href="ch9GMVRVs.html#cb391-21" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>The <code>AR1CorrelatedRNStream</code> class overrides the <code>randU01()</code> method to implement the ARTA concept. To use this class just supply it as the stream for the random variable.</p>
<div class="sourceCode" id="cb392"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb392-1"><a href="ch9GMVRVs.html#cb392-1" tabindex="-1"></a><span class="kw">val</span> <span class="va">e</span> <span class="op">=</span> ExponentialRV<span class="op">(</span>mean<span class="op">=</span><span class="fl">10.0</span><span class="op">,</span> stream <span class="op">=</span> AR1CorrelatedRNStream<span class="op">(</span>lag1Corr <span class="op">=</span> <span class="fl">0.85</span><span class="op">))</span></span></code></pre></div>
<p>In the next section, we explore a general method for generating multi-variate samples using Markov Chain Monte Carlo methods.</p>
</div>
<div id="ch9MCMC" class="section level3 hasAnchor" number="9.3.4">
<h3><span class="header-section-number">9.3.4</span> Introduction to Markov Chain Monte Carlo Methods<a href="ch9GMVRVs.html#ch9MCMC" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section, we present the a brief overview of Markov Chain Monte Carlo (MCMC) methods, especially as they relate to the constructs available within the KSL. MCMC has a deep and important history of both theoretical and practical applications. This overview provides a minimal amount of theory and then presents the related KSL classes. For tutorials on MCMC the reader should consult the following references, <span class="citation">(<a href="#ref-brooks1998">Brooks 1998</a>)</span>, <span class="citation">(<a href="#ref-Christian2020">Robert and Changye, n.d.</a>)</span>, <span class="citation">(<a href="#ref-geyer2011">Geyer 2011</a>)</span>, <span class="citation">(<a href="#ref-Ravenzwaaij2018">Van Ravenzwaaij and Brown 2018</a>)</span>, and <span class="citation">(<a href="#ref-speagle2020">Speagle 2020</a>)</span>. For textbook treatments within the context of simulation, the reader might consult <span class="citation">(<a href="#ref-ross2023">S. M. Ross 2023</a>)</span>, <span class="citation">(<a href="#ref-fishman2006first">G. Fishman 2006</a>)</span>, or <span class="citation">(<a href="#ref-rubenstein-kroese">Rubinstein and Kroese. 2017</a>)</span>.</p>
<p>MCMC is a numerical simulation technique that facilitates the approximate generation of random variates from arbitrary distributions. The distributions need only be specified up to a multiplicative constant, which is very useful in Bayesian applications. In addition, the theory works for multi-variate distributions, which allows for the generation of random vectors from arbitrary joint probability distributions. Because MCMC facilitates the generation of samples from multi-variate distributions it often has applications in estimating complex multi-dimensional integrals and has applications in the optimization of multi-variate functions.</p>
<p>Recall that the application of the Monte Carlo method, basically comes down to solving problems of the form for <span class="math inline">\(\vec{x} \in \mathbb{R}^d\)</span> and integration limit set, <span class="math inline">\(S\)</span>, such that <span class="math inline">\(S \subseteq \mathbb{R}^d\)</span>:</p>
<p><span class="math display">\[
\theta = \int\limits_S g(\vec{x}) \mathrm{d}\vec{x}
\]</span></p>
<p>We estimated <span class="math inline">\(\theta\)</span> by generating random samples of <span class="math inline">\(\vec{X}_i\)</span> according to some probability distribution <span class="math inline">\(w(\vec{x})\)</span> over the limiting set, <span class="math inline">\(S\)</span>, and averaging over the <span class="math inline">\(Y_i\)</span>, where</p>
<p><span class="math display">\[
Y_i = \frac{g(\vec{X}_i)}{w(\vec{X}_i)}
\]</span></p>
<p>which is justified because</p>
<p><span class="math display">\[
E[Y] = E_{\vec{X}}\bigg[\frac{g(\vec{X})}{w(\vec{X})}\bigg]=\int\limits_{S} g(\vec{x}) \mathrm{d}\vec{x} =\theta
\]</span></p>
<p>When we discussed importance sampling, we noted that <span class="math inline">\(g(\vec{x})\)</span> can be factorized as follows <span class="math inline">\(g(\vec{x}) = h(\vec{x})w(\vec{x})\)</span> where <span class="math inline">\(w(\vec{x})\)</span> is a probability distribution with <span class="math inline">\(\vec{x} \in S \subseteq \mathbb{R}^d\)</span>. Thus, an estimate of <span class="math inline">\(\theta\)</span> is</p>
<p><span class="math display">\[
\hat{\theta} = \bar{Y}(n) = \frac{1}{n}\sum_{i=1}^{n}Y_i=\frac{1}{n}\sum_{i=1}^{n}\frac{g(\vec{X}_i)}{w(\vec{X}_i)}=\frac{1}{n}\sum_{i=1}^{n}h(\vec{X}_i)
\]</span></p>
<p>We know that independent <span class="math inline">\(\vec{X}_i\)</span> ensures that the law of large numbers has, <span class="math inline">\(\hat{\theta} \rightarrow \theta\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> with probability 1. But what happens if the <span class="math inline">\(\vec{X}_i\)</span> are dependent? Under some technical conditions, it can still be shown that <span class="math inline">\(\hat{\theta} \rightarrow \theta\)</span>. Thus, sequences of dependent <span class="math inline">\(\vec{X}_i\)</span> could be used. One method for generating depended <span class="math inline">\(\vec{X}_i\)</span> would be from a Markov chain that has <span class="math inline">\(w(\vec{X})\)</span> as its stationary limiting distribution. In the Markov Chain literature, <span class="math inline">\(w(\vec{X})\)</span> is often denoted as <span class="math inline">\(\pi(\vec{X})\)</span>.</p>
<p>For simplicity in what follows, we will focus on the univariate case, with the understanding that the presentation can be extended to a multi-dimensional setting. Because it should make it easier to conceptualize the approach, we will first present some basic concepts using discrete Markov Chains.</p>
<p>A Markov Chain is a collection of random variables <span class="math inline">\(\{X_1,X_2,\cdots\}\)</span> where we interpret the <span class="math inline">\(X_n\)</span> as the state of the process at time step <span class="math inline">\(n\)</span>. For simplicity, suppose the state space is finite and labeled <span class="math inline">\(\{1,2,\cdots,N\}\)</span>. Let <span class="math inline">\(P\{X_{n+1} =j | X_n =i, X_{n-1} =k, \cdots,X_0 = l \}\)</span> be the probability that the process transitions to state <span class="math inline">\(j\)</span> at time <span class="math inline">\(n+1\)</span> given all previous state visits. If this probability only depends on the previous state, then we have a Markov Chain. Thus, if the following is true</p>
<p><span class="math display">\[
P\{X_{n+1} =j | X_n =i, X_{n-1} =k, \cdots,X_0 = l \} = P\{X_{n+1} =j | X_n =i\}
\]</span>
We call <span class="math inline">\(P\{X_{n+1} =j | X_n =i\}\)</span> the single step transition probabilities, <span class="math inline">\(p_{ij}\)</span>, and the process <span class="math inline">\(\{X_n\}\)</span> is a Markov Chain. Notice that the <span class="math inline">\(p_{ij}\)</span> form a conditional probability distribution across the states <span class="math inline">\(j=1, 2,\cdots, N\)</span> for a given state <span class="math inline">\(i\)</span>. Thus, we have that</p>
<p><span class="math display">\[
\sum_{j=1}^N p_{ij}= \sum_{j=1}^NP\{X_{n+1} =j | X_n =i\}=1
\]</span>
Therefore the process must be in some state <span class="math inline">\(j \in \{1,2,\cdots,N\}\)</span> after it transitions from state <span class="math inline">\(i\)</span>. To simulate <span class="math inline">\(k\)</span> transitions of a discrete state Markov Chain, we can perform the following algorithm:</p>
<ol start="0" style="list-style-type: decimal">
<li>initialize <span class="math inline">\(X_0=i\)</span> and <span class="math inline">\(n=0\)</span></li>
</ol>
<p>for n = 1 to k;</p>
<ol style="list-style-type: decimal">
<li>generate <span class="math inline">\(j \sim P\{X_{n+1}| X_n =i\}\)</span></li>
<li>let <span class="math inline">\(X_n = j\)</span> and <span class="math inline">\(i=j\)</span></li>
</ol>
<p>end for;</p>
<p>The KSL <code>DMarkovChain</code> class in the <code>ksl.utilities.random.markovchain</code> package facilitates the simulation of simple discrete state Markov Chains.</p>
<div class="example">
<p><span id="exm:exMC1" class="example"><strong>Example 9.7  (Simulating a Markov Chain) </strong></span>An ergodic Markov Chain is setup and simulated with statistics collected on the probability of being within the states.</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb393-1"><a href="ch9GMVRVs.html#cb393-1" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">p</span> <span class="op">=</span> arrayOf<span class="op">(</span></span>
<span id="cb393-2"><a href="ch9GMVRVs.html#cb393-2" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">0.3</span><span class="op">,</span> <span class="fl">0.1</span><span class="op">,</span> <span class="fl">0.6</span><span class="op">),</span></span>
<span id="cb393-3"><a href="ch9GMVRVs.html#cb393-3" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">0.4</span><span class="op">,</span> <span class="fl">0.4</span><span class="op">,</span> <span class="fl">0.2</span><span class="op">),</span></span>
<span id="cb393-4"><a href="ch9GMVRVs.html#cb393-4" tabindex="-1"></a>        doubleArrayOf<span class="op">(</span><span class="fl">0.1</span><span class="op">,</span> <span class="fl">0.7</span><span class="op">,</span> <span class="fl">0.2</span><span class="op">)</span></span>
<span id="cb393-5"><a href="ch9GMVRVs.html#cb393-5" tabindex="-1"></a>    <span class="op">)</span></span>
<span id="cb393-6"><a href="ch9GMVRVs.html#cb393-6" tabindex="-1"></a></span>
<span id="cb393-7"><a href="ch9GMVRVs.html#cb393-7" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">mc</span> <span class="op">=</span> DMarkovChain<span class="op">(</span><span class="dv">1</span><span class="op">,</span> p<span class="op">)</span></span>
<span id="cb393-8"><a href="ch9GMVRVs.html#cb393-8" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">f</span> <span class="op">=</span> IntegerFrequency<span class="op">()</span></span>
<span id="cb393-9"><a href="ch9GMVRVs.html#cb393-9" tabindex="-1"></a></span>
<span id="cb393-10"><a href="ch9GMVRVs.html#cb393-10" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span>i <span class="kw">in</span> <span class="fl">1..100000</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb393-11"><a href="ch9GMVRVs.html#cb393-11" tabindex="-1"></a>        f<span class="op">.</span>collect<span class="op">(</span>mc<span class="op">.</span>nextState<span class="op">())</span></span>
<span id="cb393-12"><a href="ch9GMVRVs.html#cb393-12" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb393-13"><a href="ch9GMVRVs.html#cb393-13" tabindex="-1"></a>    println<span class="op">(</span><span class="st">&quot;True Steady State Distribution&quot;</span><span class="op">)</span></span>
<span id="cb393-14"><a href="ch9GMVRVs.html#cb393-14" tabindex="-1"></a>    println<span class="op">(</span><span class="st">&quot;P{X=1} = &quot;</span> <span class="op">+</span> <span class="fl">238.0</span> <span class="op">/</span> <span class="fl">854.0</span><span class="op">)</span></span>
<span id="cb393-15"><a href="ch9GMVRVs.html#cb393-15" tabindex="-1"></a>    println<span class="op">(</span><span class="st">&quot;P{X=2} = &quot;</span> <span class="op">+</span> <span class="fl">350.0</span> <span class="op">/</span> <span class="fl">854.0</span><span class="op">)</span></span>
<span id="cb393-16"><a href="ch9GMVRVs.html#cb393-16" tabindex="-1"></a>    println<span class="op">(</span><span class="st">&quot;P{X=3} = &quot;</span> <span class="op">+</span> <span class="fl">266.0</span> <span class="op">/</span> <span class="fl">854.0</span><span class="op">)</span></span>
<span id="cb393-17"><a href="ch9GMVRVs.html#cb393-17" tabindex="-1"></a>    println<span class="op">()</span></span>
<span id="cb393-18"><a href="ch9GMVRVs.html#cb393-18" tabindex="-1"></a>    println<span class="op">(</span><span class="st">&quot;Observed Steady State Distribution&quot;</span><span class="op">)</span></span>
<span id="cb393-19"><a href="ch9GMVRVs.html#cb393-19" tabindex="-1"></a>    println<span class="op">(</span>f<span class="op">)</span></span></code></pre></div>
</div>
<p>This code results in the following output.</p>
<pre><code>True Steady State Distribution
P{X=1} = 0.2786885245901639
P{X=2} = 0.4098360655737705
P{X=3} = 0.3114754098360656

Observed Steady State Distribution
Frequency Tabulation ID_2
----------------------------------------
Number of cells = 3
Lower limit = -2147483648
Upper limit = 2147483647
Under flow count = 0
Over flow count = 0
Total count = 100000.0
Minimum value observed = 1
Maximum value observed = 3
----------------------------------------
Value    Count   Proportion
1    27812.0     0.27812
2    41138.0     0.41138
3    31050.0     0.3105
----------------------------------------</code></pre>
<p>As we can see from the output, the distribution of the observations from the chain are converging to the steady state limiting distribution.</p>
<p>There are many issues related to the analysis of Markov Chains that are discussed in some of the aforementioned textbooks. The main property of concern here is that a Markov Chain is said to be <em>irreducible</em> if for each pair of states <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, there exists a probability of starting in state <span class="math inline">\(i\)</span> that eventually allows state <span class="math inline">\(j\)</span> to be visited. For an irreducible Markov Chain that is also aperiodic, there will exist a limiting distribution across the states, <span class="math inline">\(\pi_j = \underset{n \rightarrow \infty}{\text{lim}}P\{X_n = j\}\)</span>, which represents the steady state probability that the process is in state <span class="math inline">\(j\)</span> or sometimes called the long run proportion of time that the process is in state <span class="math inline">\(j\)</span>. Suppose now that we have a Markov Chain such that <span class="math inline">\(\pi_j\)</span> exists, then it can be shown that for any function <span class="math inline">\(h(\cdot)\)</span> on <span class="math inline">\(X_n\)</span>, that:</p>
<p><span class="math display">\[
\underset{n \rightarrow \infty}{\text{lim}}\frac{1}{n}\sum_{i=1}^{n}h(X_i)=\sum_{j=1}^{N}h(j)\pi_j \quad \text{w.p.} \, 1
\]</span>
This result is the motivation for MCMC.</p>
<p>In MCMC, we want to generate random variables, <span class="math inline">\(X \sim P(X=j)\)</span>, for <span class="math inline">\(j=1,2,\cdots,N\)</span> and estimate <span class="math inline">\(E[h(X)]= \sum_{j=1}^{N}h(j)p_j\)</span>. Thus, why not set up a Markov Chain with limiting probability <span class="math inline">\(\pi_j = p_j\)</span>, then <span class="math inline">\(X_n\)</span> will have approximately the distribution of <span class="math inline">\(X\)</span> after a sufficiently large number of steps <span class="math inline">\(n\)</span> of the Markov Chain. Thus, we can estimate <span class="math inline">\(E[h(X)]\)</span> by <span class="math inline">\(\frac{1}{n}\sum_{i=1}^{n}h(X_i)\)</span> for large <span class="math inline">\(n\)</span>. The key requirement is to be able to set up a Markov Chain such that <span class="math inline">\(\pi_j = p_j\)</span> is true. You might ask, if we have <span class="math inline">\(p_j\)</span>, why not just use:</p>
<p><span class="math display">\[
E[h(X)] =\sum_{j=1}^{N}h(j)p_j
\]</span>
In many cases, especially in the continuous case, <span class="math inline">\(p_j\)</span> is not known or is known only up to a multiplicative constant. This is when MCMC become useful. In traditional Markov Chain theory, we are typically interested in determining the steady state distribution, <span class="math inline">\(\pi_j\)</span> from a given transition matrix, <span class="math inline">\(\mathbf{P}\)</span>, assuming that it is irreducible and aperiodic. The key MCMC result, turns this problem around: Given a desired <span class="math inline">\(\pi_j\)</span> what <span class="math inline">\(\mathbf{P}\)</span> should we construct to get the desired <span class="math inline">\(\pi_j\)</span>. The Metropolis-Hastings algorithm prescribes a method to address this problem.</p>
<p>The basic idea behind the Metropolis-Hastings algorithm is to use an arbitrary transition matrix <span class="math inline">\(\mathbf{Q}\)</span> and accept or reject proposed state changes in such a manner that the resulting observations will come from a transition matrix <span class="math inline">\(\mathbf{P}\)</span> that has the desired <span class="math inline">\(\pi_j\)</span>. The steps are as follows:</p>
<ol style="list-style-type: decimal">
<li>When <span class="math inline">\(X_n = i\)</span>, generate random variable <span class="math inline">\(Y \sim P(Y=j) = q_{ij}\)</span>, <span class="math inline">\(j \in S\)</span></li>
<li>If <span class="math inline">\(Y=j\)</span>, let <span class="math inline">\(X_{n+1} = j\)</span> with probability <span class="math inline">\(\alpha_{ij}\)</span> or <span class="math inline">\(i\)</span> with probability <span class="math inline">\(1-\alpha_{ij}\)</span>, where <span class="math inline">\(\alpha_{ij} = min\bigg[\frac{\pi_jq_{ji}}{\pi_iq_{ij}},1\bigg]\)</span></li>
</ol>
<p>The resulting Markov Chain, <span class="math inline">\(X_n\)</span> will have one step transition probabilities:</p>
<p><span class="math display">\[
p_{ij}=
\begin{cases}
q_{ij}\alpha_{ij} &amp; \text{if} \, i \ne j\\
1 - \sum_{k\ne i}q_{ik}\alpha_{ik}   &amp; \text{if} \, i = j
\end{cases}
\]</span>
and the Markov Chain will have the desired stationary probabilities <span class="math inline">\(\pi_j\)</span>. The proof of this result can be found in <span class="citation">(<a href="#ref-ross2023">S. M. Ross 2023</a>)</span>. This seems like a lot of work given that we have to know <span class="math inline">\(\pi_j\)</span>; however, close examination of <span class="math inline">\(\alpha_{ij}\)</span> indicates that we need only know <span class="math inline">\(\pi_j\)</span> up to proportionality constant, e.g.Â <span class="math inline">\(\pi_j = b_i/C\)</span> because of the ratio form of <span class="math inline">\(\alpha_{ij}\)</span>.</p>
<p>The payoff is when we want to generate samples from some arbitrary multi-dimensional pdf, <span class="math inline">\(f(\vec{x})\)</span>. The theory can be generalized to this case by generalizing from a discrete Markov Chain to a continuous Markov Chain. This is done by defining a probability transition function <span class="math inline">\(q(\vec{x},\vec{y})\)</span> which is called the proposal function. The proposal function proposes the next state and is acting as the arbitrary transition matrix <span class="math inline">\(\mathbf{Q}\)</span>. With that in mind, it is really a conditional probability density function <span class="math inline">\(q(\vec{y}|\vec{x})\)</span> which represents the probability of generating <span class="math inline">\(\vec{Y}\)</span> given we are in state <span class="math inline">\(\vec{x}\)</span>. The <span class="math inline">\(\alpha_{ij}\)</span> is generalized to a function, <span class="math inline">\(\alpha(\vec{x},\vec{y})\)</span>, which is called the acceptance probability function. The general Metropolis-Hastings algorithm is:</p>
<p>Let <span class="math inline">\(f(\vec{x})\)</span> be the target distribution.</p>
<p>Let <span class="math inline">\(q(\vec{y}|\vec{x})\)</span> be the proposal distribution.</p>
<p>Let <span class="math inline">\(\rho(\vec{x},\vec{y})\)</span> be the acceptance ratio, where</p>
<p><span class="math display">\[
\rho(\vec{x},\vec{y}) = \frac{ q(\vec{x}|\vec{y})\times f(\vec{y})}{ q(\vec{y}|\vec{x}) \times f(\vec{x})}
\]</span>
Let <span class="math inline">\(\alpha(\vec{x},\vec{y}) = min[\rho(\vec{x},\vec{y}),1 ]\)</span> be the acceptance function.</p>
<ol style="list-style-type: decimal">
<li>Set <span class="math inline">\(t=0\)</span></li>
<li>Set <span class="math inline">\(X_0\)</span></li>
</ol>
<p>for t = 1 to ?;</p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(Y \sim q(\vec{y}|\vec{x})\)</span></li>
<li><span class="math inline">\(U \sim U(0,1)\)</span></li>
<li>if <span class="math inline">\(U \leq \alpha(\vec{x},\vec{y})\)</span> then <span class="math inline">\(X_{t+1} = Y\)</span> else <span class="math inline">\(X_{t+1} = X_t\)</span></li>
</ol>
<p>end for;</p>
<p>When applying the Metropolis-Hastings algorithm, you obviously need the distribution from which you intend to generate random variates, <span class="math inline">\(f(\vec{x})\)</span>. The function <span class="math inline">\(f(\vec{x})\)</span> can be the distribution function specified up to a proportionality constant. The second key function is the proposal distribution (or proposal function), <span class="math inline">\(q(\vec{x},\vec{y}) = q(\vec{y}|\vec{x})\)</span>. There are many possible forms for this function and those forms specify the type of sampler for the MCMC.</p>
<p>Figure <a href="ch9GMVRVs.html#fig:MCMClasses">9.9</a> presents the main classes and interfaces for the Metropolis-Hastings implementation within the KSL. The <code>MetropolisHastingsMV</code> class is supported by two interfaces: 1) <code>FunctionMVIfc</code> and 2) <code>ProposalFunctionMVIfc.</code>. Letâ€™s examine these two classes before reviewing the the Metropolis-Hastings implementation.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:MCMClasses"></span>
<img src="figures2/ch9/MetropolisHastingsMV.png" alt="Key Classes and Interfaces for MCMC" width="80%" height="80%" />
<p class="caption">
Figure 9.9: Key Classes and Interfaces for MCMC
</p>
</div>
<p>The purpose of the <code>FunctionMVIfc</code> interface is to represent the desired multi-variate distribution, <span class="math inline">\(f(\vec{x})\)</span>. This is the probability density of the distribution from which you want the random vectors. This interface requires the dimension of the function and the method to represent the functional transformation.</p>
<div class="sourceCode" id="cb395"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb395-1"><a href="ch9GMVRVs.html#cb395-1" tabindex="-1"></a><span class="kw">interface</span> FunctionMVIfc <span class="op">{</span></span>
<span id="cb395-2"><a href="ch9GMVRVs.html#cb395-2" tabindex="-1"></a></span>
<span id="cb395-3"><a href="ch9GMVRVs.html#cb395-3" tabindex="-1"></a>    <span class="co">/**</span></span>
<span id="cb395-4"><a href="ch9GMVRVs.html#cb395-4" tabindex="-1"></a><span class="co">     *</span></span>
<span id="cb395-5"><a href="ch9GMVRVs.html#cb395-5" tabindex="-1"></a><span class="co">     * the expected size of the array</span></span>
<span id="cb395-6"><a href="ch9GMVRVs.html#cb395-6" tabindex="-1"></a><span class="co">     */</span></span>
<span id="cb395-7"><a href="ch9GMVRVs.html#cb395-7" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">dimension</span><span class="op">:</span> <span class="kw">Int</span></span>
<span id="cb395-8"><a href="ch9GMVRVs.html#cb395-8" tabindex="-1"></a></span>
<span id="cb395-9"><a href="ch9GMVRVs.html#cb395-9" tabindex="-1"></a>    <span class="co">/**</span></span>
<span id="cb395-10"><a href="ch9GMVRVs.html#cb395-10" tabindex="-1"></a><span class="co">     * Returns the value of the function for the specified variable value.</span></span>
<span id="cb395-11"><a href="ch9GMVRVs.html#cb395-11" tabindex="-1"></a><span class="co">     * The implementor of f(x) should check if the array size is the</span></span>
<span id="cb395-12"><a href="ch9GMVRVs.html#cb395-12" tabindex="-1"></a><span class="co">     * same as the dimension of the function</span></span>
<span id="cb395-13"><a href="ch9GMVRVs.html#cb395-13" tabindex="-1"></a><span class="co">     */</span></span>
<span id="cb395-14"><a href="ch9GMVRVs.html#cb395-14" tabindex="-1"></a>    <span class="kw">fun</span> <span class="fu">f</span><span class="op">(</span><span class="va">x</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">):</span> <span class="dt">Double</span></span>
<span id="cb395-15"><a href="ch9GMVRVs.html#cb395-15" tabindex="-1"></a>}</span></code></pre></div>
<p>The second interface is the <code>ProposalFunctionMVIfc</code> interface which represents proposal density function <span class="math inline">\(q(\vec{y}|\vec{x})\)</span> with the <code>generateProposedGivenCurrent()</code> function and the proposal functionâ€™s contribution to the computation of the acceptance ratio function, <span class="math inline">\(\rho(\vec{x},\vec{y})\)</span> via the <code>proposalRatio()</code> function. The examples that follow will illustrate this function. The <code>generateProposedGivenCurrent()</code> function takes in the current state as its parameter and returns a possible next state.</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb396-1"><a href="ch9GMVRVs.html#cb396-1" tabindex="-1"></a><span class="kw">interface</span> ProposalFunctionMVIfc <span class="op">{</span></span>
<span id="cb396-2"><a href="ch9GMVRVs.html#cb396-2" tabindex="-1"></a></span>
<span id="cb396-3"><a href="ch9GMVRVs.html#cb396-3" tabindex="-1"></a>    <span class="co">/**</span></span>
<span id="cb396-4"><a href="ch9GMVRVs.html#cb396-4" tabindex="-1"></a><span class="co">     *</span></span>
<span id="cb396-5"><a href="ch9GMVRVs.html#cb396-5" tabindex="-1"></a><span class="co">     * the expected size of the array</span></span>
<span id="cb396-6"><a href="ch9GMVRVs.html#cb396-6" tabindex="-1"></a><span class="co">     */</span></span>
<span id="cb396-7"><a href="ch9GMVRVs.html#cb396-7" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">dimension</span><span class="op">:</span> <span class="kw">Int</span></span>
<span id="cb396-8"><a href="ch9GMVRVs.html#cb396-8" tabindex="-1"></a></span>
<span id="cb396-9"><a href="ch9GMVRVs.html#cb396-9" tabindex="-1"></a>    <span class="co">/** The ratio of g(y,x)/g(x,y).  The ratio of the proposal function</span></span>
<span id="cb396-10"><a href="ch9GMVRVs.html#cb396-10" tabindex="-1"></a><span class="co">     * evaluated at x = current and y = proposed, where g() is some</span></span>
<span id="cb396-11"><a href="ch9GMVRVs.html#cb396-11" tabindex="-1"></a><span class="co">     * proposal function of x and y. The implementor should ensure</span></span>
<span id="cb396-12"><a href="ch9GMVRVs.html#cb396-12" tabindex="-1"></a><span class="co">     * that the returned ratio is a valid double</span></span>
<span id="cb396-13"><a href="ch9GMVRVs.html#cb396-13" tabindex="-1"></a><span class="co">     *</span></span>
<span id="cb396-14"><a href="ch9GMVRVs.html#cb396-14" tabindex="-1"></a><span class="co">     * @param current the x to evaluate</span></span>
<span id="cb396-15"><a href="ch9GMVRVs.html#cb396-15" tabindex="-1"></a><span class="co">     * @param proposed the y to evaluate</span></span>
<span id="cb396-16"><a href="ch9GMVRVs.html#cb396-16" tabindex="-1"></a><span class="co">     * @return the ratio of the proposal function</span></span>
<span id="cb396-17"><a href="ch9GMVRVs.html#cb396-17" tabindex="-1"></a><span class="co">     */</span></span>
<span id="cb396-18"><a href="ch9GMVRVs.html#cb396-18" tabindex="-1"></a>    <span class="kw">fun</span> <span class="fu">proposalRatio</span><span class="op">(</span><span class="va">current</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">,</span> <span class="va">proposed</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">):</span> <span class="dt">Double</span></span>
<span id="cb396-19"><a href="ch9GMVRVs.html#cb396-19" tabindex="-1"></a></span>
<span id="cb396-20"><a href="ch9GMVRVs.html#cb396-20" tabindex="-1"></a>    <span class="co">/**</span></span>
<span id="cb396-21"><a href="ch9GMVRVs.html#cb396-21" tabindex="-1"></a><span class="co">     *</span></span>
<span id="cb396-22"><a href="ch9GMVRVs.html#cb396-22" tabindex="-1"></a><span class="co">     * @param current the current state value of the chain (i.e. x)</span></span>
<span id="cb396-23"><a href="ch9GMVRVs.html#cb396-23" tabindex="-1"></a><span class="co">     * @return the generated possible state (i.e. y) which may or may not be accepted</span></span>
<span id="cb396-24"><a href="ch9GMVRVs.html#cb396-24" tabindex="-1"></a><span class="co">     */</span></span>
<span id="cb396-25"><a href="ch9GMVRVs.html#cb396-25" tabindex="-1"></a>    <span class="kw">fun</span> <span class="fu">generateProposedGivenCurrent</span><span class="op">(</span><span class="va">current</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">):</span> <span class="dt">DoubleArray</span></span>
<span id="cb396-26"><a href="ch9GMVRVs.html#cb396-26" tabindex="-1"></a>}</span></code></pre></div>
<p>Letâ€™s consider a couple of common samplers. The first to consider is the <em>independence</em> sampler. For the independence sampler, the probability of going to <span class="math inline">\(\vec{y}\)</span> from state <span class="math inline">\(\vec{x}\)</span> is independent of <span class="math inline">\(\vec{x}\)</span>. Thus, the proposal function, <span class="math inline">\(q(\vec{y}|\vec{x})\)</span> is simply a function of <span class="math inline">\(\vec{y}\)</span>. That is, <span class="math inline">\(q(\vec{y}|\vec{x}) = q(\vec{y})\)</span>. This causes the acceptance ratio to be:</p>
<p><span class="math display">\[
\rho(\vec{x},\vec{y}) = \frac{ q(\vec{x}|\vec{y})\times f(\vec{y})}{ q(\vec{y}|\vec{x}) \times f(\vec{x})} =  \frac{ q(\vec{x})\times f(\vec{y})}{ q(\vec{y}) \times f(\vec{x})}
\]</span>
Similar in some respects as the acceptance-rejection method, good proposal functions <span class="math inline">\(q(\vec{y})\)</span> should have similar shape as <span class="math inline">\(f(\vec{x})\)</span>. Even though the name of this sampler suggests independence, this independence is in the proposal function, not in the resulting Markov Chain and its state values. That is, the generated <span class="math inline">\(\vec{X}_i\)</span> will be dependent because they come from the underlying Markov Chain implied by the proposal function.</p>
<p>Another common sampler is the <em>random walk</em> sampler. For a random walk sampler, the proposal function is symmetric. Because of symmetry, <span class="math inline">\(q(\vec{y}|\vec{x}) = q(\vec{x}|\vec{y})\)</span>. This causes the acceptance ratio to be:</p>
<p><span class="math display">\[
\rho(\vec{x},\vec{y}) = \frac{ q(\vec{x}|\vec{y})\times f(\vec{y})}{ q(\vec{y}|\vec{x}) \times f(\vec{x})} =  \frac{f(\vec{y})}{f(\vec{x})}
\]</span>
Typical implementations have, <span class="math inline">\(\vec{Y} = \vec{x} + \vec{W}\)</span>, where <span class="math inline">\(\vec{W} \sim G(\vec{W})\)</span> and the distribution <span class="math inline">\(G(\cdot)\)</span> is symmetric, such as the multi-variate normal distribution, <span class="math inline">\(\textbf{MVN}(\vec{0}, \mathbf{\Sigma})\)</span>. Letâ€™s look at an example to put these ideas into practice.</p>
<hr />
<div class="example">
<p><span id="exm:MCMCExample" class="example"><strong>Example 9.8  (MCMC Sampler Example) </strong></span>Suppose that the random variable <span class="math inline">\(X_1\)</span> is the zinc content of an ore sample with a range of values in <span class="math inline">\([0.5, 1.5]\)</span> and the random variable <span class="math inline">\(X_2\)</span> is the iron content of the ore with values in <span class="math inline">\([20.0, 35.0]\)</span>. The joint distribution density function for the random variables has been modeled as:</p>
<p><span class="math display">\[
f(x_1, x_2) =
\begin{cases}
\frac{39}{400} - \frac{17(x_1 - 1)^2}{50} - \frac{(x_2 - 25)^2}{10000} &amp; \, 0.5 \leq x_1 \leq 1.5; \, 20 \leq x_2 \leq 35\\
0.0   &amp; otherwise
\end{cases}
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Develop a MCMC independent sampler to generate <span class="math inline">\((X_1, X_2)\)</span> from this distribution.</li>
<li>Develop a MCMC random walk sampler to generate <span class="math inline">\((X_1, X_2)\)</span> from this distribution.</li>
</ol>
</div>
<hr />
<p>The key issue is developing a suitable proposal function. Recall that for an independence sampler, we have <span class="math inline">\(q(\vec{y}|\vec{x}) = q(\vec{y})\)</span>. The function, <span class="math inline">\(q(\vec{y})\)</span> is a probability density function and it must be a function of <span class="math inline">\(\vec{y} = (y_1, y_2)^T\)</span>. That is, <span class="math inline">\(q(y_1, y_2)\)</span> is a joint density function for random variables <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span>. Now, it might be more readily apparent as to the reason an independence sampler is common. Notice that the general proposal function <span class="math inline">\(q(\vec{y}|\vec{x})\)</span> would be a conditional distribution of the form <span class="math inline">\(q(y_1,y_2|X_1=x_1,X_2=x_2)\)</span>. Thus, an independence sampler avoids having to develop a function that includes <span class="math inline">\(X_1=x_1,X_2=x_2\)</span> in its functional form. So, we need a joint density function that will generate, <span class="math inline">\((Y_1, Y_2)\)</span>.</p>
<p>The proposed random vector, <span class="math inline">\(\vec{Y}\)</span>, needs to be within the set of possible values for <span class="math inline">\(\vec{X}\)</span>. There is no requirement that the joint density have a correlation structure. Thus, it is acceptable to specify the distributions for <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> as independent marginals. Therefore to keep things simple for illustrative purposes, we will specify <span class="math inline">\(Y_1 \sim beta(\alpha_1 = 2, \alpha_2=5, min = 0.5, max=1.5)\)</span> and <span class="math inline">\(Y_2 \sim beta(\alpha_1 = 2, \alpha_2=5, min = 20.0, max=35.0)\)</span>. Both of these distributions are not symmetric and cover the ranges for <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span>.</p>
<p>We make no claim that these distributions are better than any other distributions for the range of <span class="math inline">\(\vec{X}\)</span> for the purposes of MCMC. They simply meet the requirement. Thus, letting <span class="math inline">\(g_{Y_1}(y_1)\)</span> be the generalized beta PDF for <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(g_{Y_2}(y_2)\)</span> be the generalized beta PDF for <span class="math inline">\(Y_2\)</span>, we have that the joint density <span class="math inline">\(q(y_1, y_2) = g_{Y_1}(y_1) \times g_{Y_2}(y_2)\)</span> because of the assumption of independence between <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span>.</p>
<p>Now we can specify the acceptance ratio function:</p>
<p><span class="math display">\[
\rho(\vec{x},\vec{y}) = \frac{ q(\vec{x}|\vec{y})\times f(\vec{y})}{ q(\vec{y}|\vec{x}) \times f(\vec{x})} =  \frac{ q(\vec{x})\times f(\vec{y})}{ q(\vec{y}) \times f(\vec{x})} =
\frac{ g_{Y_1}(x_1) \times g_{Y_2}(x_2)\times f(y_1, y_2)}{ g_{Y_1}(y_1) \times g_{Y_2}(y_2) \times f(x_1, x_2)}
\]</span>
Notice that <span class="math inline">\(\rho(\vec{x},\vec{y})\)</span> is simply a function of <span class="math inline">\(x_1,x_2,y_1,y_2\)</span>. We are <em>evaluating</em> the probability density functions at the points <span class="math inline">\(x_1,x_2,y_1,y_2\)</span>. Thus, <span class="math inline">\(\rho(\vec{x},\vec{y})\)</span> is essentially a likelihood ratio. In implementing the Metropolis-Hastings algorithm it is useful to define the acceptance ratio, <span class="math inline">\(\rho(\vec{x},\vec{y})\)</span>, in terms of the proposal ratio, <span class="math inline">\(p_r(\vec{x},\vec{y})\)</span>, and the function ratio, <span class="math inline">\(f_r(\vec{x},\vec{y})\)</span>, where:</p>
<p><span class="math display">\[
p_r(\vec{x},\vec{y}) =  \frac{ q(\vec{x}|\vec{y})}{ q(\vec{y}|\vec{x})}
\]</span>
and,</p>
<p><span class="math display">\[
f_r(\vec{x},\vec{y}) = \frac{ f(\vec{y})}{f(\vec{x})}
\]</span>
which yields, <span class="math inline">\(\rho(\vec{x},\vec{y}) = p_r(\vec{x},\vec{y}) \times f_r(\vec{x},\vec{y})\)</span>. The <code>proposalRatio()</code> function of the <code>ProposalFunctionMVIfc</code> interface implements <span class="math inline">\(p_r(\vec{x},\vec{y})\)</span>.</p>
<p>To implement the Metropolis-Hastings algorithm for this sampler we need to implement the <code>FunctionMVIfc</code> interface to implement the distribution of interest. Here is the KSL code for the example problem.</p>
<div class="sourceCode" id="cb397"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb397-1"><a href="ch9GMVRVs.html#cb397-1" tabindex="-1"></a><span class="kw">object</span> Function <span class="op">:</span> <span class="dt">FunctionMVIfc</span> <span class="op">{</span></span>
<span id="cb397-2"><a href="ch9GMVRVs.html#cb397-2" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">val</span> <span class="va">dimension</span><span class="op">:</span> <span class="kw">Int</span></span>
<span id="cb397-3"><a href="ch9GMVRVs.html#cb397-3" tabindex="-1"></a>        <span class="kw">get</span><span class="op">()</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb397-4"><a href="ch9GMVRVs.html#cb397-4" tabindex="-1"></a></span>
<span id="cb397-5"><a href="ch9GMVRVs.html#cb397-5" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">fun</span> <span class="fu">f</span><span class="op">(</span><span class="va">x</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">):</span> <span class="dt">Double</span> <span class="op">{</span></span>
<span id="cb397-6"><a href="ch9GMVRVs.html#cb397-6" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">x0p</span> <span class="op">=</span> <span class="fl">17.0</span> <span class="op">*</span> <span class="op">(</span>x<span class="op">[</span><span class="dv">0</span><span class="op">]</span> <span class="op">-</span> <span class="fl">1.0</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span>x<span class="op">[</span><span class="dv">0</span><span class="op">]</span> <span class="op">-</span> <span class="fl">1.0</span><span class="op">)</span> <span class="op">/</span> <span class="fl">50.0</span></span>
<span id="cb397-7"><a href="ch9GMVRVs.html#cb397-7" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">x1p</span> <span class="op">=</span> <span class="op">(</span>x<span class="op">[</span><span class="dv">1</span><span class="op">]</span> <span class="op">-</span> <span class="fl">25.0</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span>x<span class="op">[</span><span class="dv">1</span><span class="op">]</span> <span class="op">-</span> <span class="fl">25.0</span><span class="op">)</span> <span class="op">/</span> <span class="fl">10000.0</span></span>
<span id="cb397-8"><a href="ch9GMVRVs.html#cb397-8" tabindex="-1"></a>        <span class="kw">return</span> <span class="op">(</span><span class="fl">39.0</span> <span class="op">/</span> <span class="fl">400.0</span><span class="op">)</span> <span class="op">-</span> x0p <span class="op">-</span> x1p</span>
<span id="cb397-9"><a href="ch9GMVRVs.html#cb397-9" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb397-10"><a href="ch9GMVRVs.html#cb397-10" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>In addition, we need to implement the <code>ProposalFunctionMVIfc</code> interface, which requires the proposal ratio, <span class="math inline">\(p_r(\vec{x},\vec{y})\)</span> and the proposal function <span class="math inline">\(q(\vec{x}|\vec{y})\)</span>. The KSL code for the suggested independence sampler is as follows. The code used the <code>GeneralizedBeta</code> class from the <code>ksl.utilities.distributions</code> package because the distributions package contains the implementations for the probability density function.</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb398-1"><a href="ch9GMVRVs.html#cb398-1" tabindex="-1"></a><span class="kw">object</span> ExampleIndependencePF <span class="op">:</span> <span class="dt">ProposalFunctionMVIfc</span> <span class="op">{</span></span>
<span id="cb398-2"><a href="ch9GMVRVs.html#cb398-2" tabindex="-1"></a></span>
<span id="cb398-3"><a href="ch9GMVRVs.html#cb398-3" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">myY1Dist</span> <span class="op">=</span> GeneralizedBeta<span class="op">(</span>alphaShape <span class="op">=</span> <span class="fl">2.0</span><span class="op">,</span> betaShape <span class="op">=</span> <span class="fl">5.0</span><span class="op">,</span> minimum <span class="op">=</span> <span class="fl">0.5</span><span class="op">,</span> maximum <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span></span>
<span id="cb398-4"><a href="ch9GMVRVs.html#cb398-4" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">myY2Dist</span> <span class="op">=</span> GeneralizedBeta<span class="op">(</span>alphaShape <span class="op">=</span> <span class="fl">2.0</span><span class="op">,</span> betaShape <span class="op">=</span> <span class="fl">5.0</span><span class="op">,</span> minimum <span class="op">=</span> <span class="fl">20.0</span><span class="op">,</span> maximum <span class="op">=</span> <span class="fl">35.0</span><span class="op">)</span></span>
<span id="cb398-5"><a href="ch9GMVRVs.html#cb398-5" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">myY1RV</span> <span class="op">=</span> myY1Dist<span class="op">.</span>randomVariable</span>
<span id="cb398-6"><a href="ch9GMVRVs.html#cb398-6" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">myY2RV</span> <span class="op">=</span> myY2Dist<span class="op">.</span>randomVariable</span>
<span id="cb398-7"><a href="ch9GMVRVs.html#cb398-7" tabindex="-1"></a></span>
<span id="cb398-8"><a href="ch9GMVRVs.html#cb398-8" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">val</span> <span class="va">dimension</span><span class="op">:</span> <span class="kw">Int</span></span>
<span id="cb398-9"><a href="ch9GMVRVs.html#cb398-9" tabindex="-1"></a>        <span class="kw">get</span><span class="op">()</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb398-10"><a href="ch9GMVRVs.html#cb398-10" tabindex="-1"></a></span>
<span id="cb398-11"><a href="ch9GMVRVs.html#cb398-11" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">fun</span> <span class="fu">proposalRatio</span><span class="op">(</span><span class="va">currentX</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">,</span> <span class="va">proposedY</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">):</span> <span class="dt">Double</span> <span class="op">{</span></span>
<span id="cb398-12"><a href="ch9GMVRVs.html#cb398-12" tabindex="-1"></a>        <span class="co">//g(y|x) = g(x,y)</span></span>
<span id="cb398-13"><a href="ch9GMVRVs.html#cb398-13" tabindex="-1"></a>        <span class="co">// proposal ratio = g(x|y)/g(y|x) = g(y,x)/g(x,y)</span></span>
<span id="cb398-14"><a href="ch9GMVRVs.html#cb398-14" tabindex="-1"></a>        <span class="co">// for independent sampler the proposal ratio is g(x)/g(y)</span></span>
<span id="cb398-15"><a href="ch9GMVRVs.html#cb398-15" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">gx</span> <span class="op">=</span> myY1Dist<span class="op">.</span>pdf<span class="op">(</span>currentX<span class="op">[</span><span class="dv">0</span><span class="op">])</span> <span class="op">*</span> myY2Dist<span class="op">.</span>pdf<span class="op">(</span>currentX<span class="op">[</span><span class="dv">1</span><span class="op">])</span></span>
<span id="cb398-16"><a href="ch9GMVRVs.html#cb398-16" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">gy</span> <span class="op">=</span> myY1Dist<span class="op">.</span>pdf<span class="op">(</span>proposedY<span class="op">[</span><span class="dv">0</span><span class="op">])</span> <span class="op">*</span> myY2Dist<span class="op">.</span>pdf<span class="op">(</span>proposedY<span class="op">[</span><span class="dv">1</span><span class="op">])</span></span>
<span id="cb398-17"><a href="ch9GMVRVs.html#cb398-17" tabindex="-1"></a>        <span class="kw">return</span> <span class="op">(</span>gx <span class="op">/</span> gy<span class="op">)</span></span>
<span id="cb398-18"><a href="ch9GMVRVs.html#cb398-18" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb398-19"><a href="ch9GMVRVs.html#cb398-19" tabindex="-1"></a></span>
<span id="cb398-20"><a href="ch9GMVRVs.html#cb398-20" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">fun</span> <span class="fu">generateProposedGivenCurrent</span><span class="op">(</span><span class="va">currentX</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">):</span> <span class="dt">DoubleArray</span> <span class="op">{</span></span>
<span id="cb398-21"><a href="ch9GMVRVs.html#cb398-21" tabindex="-1"></a>        <span class="kw">return</span> doubleArrayOf<span class="op">(</span>myY1RV<span class="op">.</span>value<span class="op">,</span> myY2RV<span class="op">.</span>value<span class="op">)</span></span>
<span id="cb398-22"><a href="ch9GMVRVs.html#cb398-22" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb398-23"><a href="ch9GMVRVs.html#cb398-23" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>To run the simulation and generate the random vectors, we use the <code>MetropolisHastingsMV</code> class as illustrated in the following code. Because the function in the example is relatively simple, the expected values of the marginals can be readily computed. In this case, <span class="math inline">\(E[X_1] = 1.0\)</span> and <span class="math inline">\(E[X_2] = 27.5\)</span>, which were used as the initial state of the chain. The initial starting point can be some arbitrary state as long as it is a legal. This code warms the chain up by 10000 steps and attaches an observer to the generation process to capture the generated values to a file.</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb399-1"><a href="ch9GMVRVs.html#cb399-1" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">f</span> <span class="op">=</span> Function</span>
<span id="cb399-2"><a href="ch9GMVRVs.html#cb399-2" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">q</span> <span class="op">=</span> ExampleIndependencePF</span>
<span id="cb399-3"><a href="ch9GMVRVs.html#cb399-3" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">x0</span> <span class="op">=</span> doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">27.5</span><span class="op">)</span></span>
<span id="cb399-4"><a href="ch9GMVRVs.html#cb399-4" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">m</span> <span class="op">=</span> MetropolisHastingsMV<span class="op">(</span>x0<span class="op">,</span> f<span class="op">,</span> q<span class="op">)</span></span>
<span id="cb399-5"><a href="ch9GMVRVs.html#cb399-5" tabindex="-1"></a>    m<span class="op">.</span>runWarmUpPeriod<span class="op">(</span><span class="dv">10000</span><span class="op">)</span></span>
<span id="cb399-6"><a href="ch9GMVRVs.html#cb399-6" tabindex="-1"></a>    m<span class="op">.</span>attachObserver<span class="op">(</span>WriteData<span class="op">(</span><span class="st">&quot;IndData.csv&quot;</span><span class="op">))</span></span>
<span id="cb399-7"><a href="ch9GMVRVs.html#cb399-7" tabindex="-1"></a>    m<span class="op">.</span>runAll<span class="op">(</span><span class="dv">10000</span><span class="op">)</span></span>
<span id="cb399-8"><a href="ch9GMVRVs.html#cb399-8" tabindex="-1"></a>    println<span class="op">(</span>m<span class="op">)</span></span></code></pre></div>
<p>The results are only illustrative of the type of default results that are available.</p>
<pre><code>MetropolisHastings1D
Initialized Flag = true
Burn In Flag = true
Initial X =[0.9594860880833775, 28.12096270621112]
Current X = [0.906954110208565, 26.987110000370624]
Previous X = [1.1256323226794631, 30.436063687178418]
Last Proposed Y= [0.906954110208565, 26.987110000370624]
Last Prob. of Acceptance = 0.04051986694353263
Last f(Y) = 0.09416157659823556
Last f(X) = 0.08917853778826954
Acceptance Statistics
Statistic{name=&#39;Acceptance Statistics&#39;, n=10000.0, avg=0.3430999999999989, sd=0.4747682913728006, ci=[0.3337935942370735, 0.3524064057629243]}
BatchStatistic{name=&#39;X_1&#39;, n=39.0, avg=0.9967017932134693, sd=0.15875667093683876, ci=[0.9452388337522397, 1.0481647526746989], lag-1 corr=0.496713378422824, Total number observed = 10000.0}
BatchStatistic{name=&#39;X_2&#39;, n=39.0, avg=26.081192452184705, sd=1.3778407004302573, ci=[25.63454816510158, 26.52783673926783], lag-1 corr=0.23746016384798618, Total number observed = 10000.0}</code></pre>
<p>The <code>MetropolisHastingsMV</code> class automatically estimates the probability of acceptance for the generation process. Generally, the higher the better for efficiency and other characteristics of the chain. In general, achieving a high probability of acceptance may be quite difficult. Probability of acceptance values in the range from 20-50% are not uncommon. Notice that the statistics collected on the marginal output are close to what is expected. The default results use the <code>BatchStatistic</code> class because of the correlation that is typically present in MCMC output. The correlation reported is for the batch means, not the state observations. The raw observation statistics based on the <code>Statistic</code> class can be obtained via the <code>observedStatistics()</code> method of the <code>MetropolisHastingsMV</code> class. Keep in mind that the confidence intervals reported from the <code>Statistic</code> class assume independent observations. Thus, they will have bias as discussed in Section <a href="simoainfhorizon.html#simoainfhorizonbatchmeans">5.6.3</a>.</p>
<p>We can see from some of the initial data that the state vector can repeat in the sampling. Large lengths of runs for repeated observations indicates that the Markov Chain is not mixing very well. This can be a common occurrence for independence samplers. We leave it as an exercise for the reader to improve the sampling.</p>
<pre><code>0.6351363119853689, 26.352266492202997
0.5982875748975195, 23.90232944372732
0.6190352791846846, 21.02435324965421
0.9193784433785976, 21.682499716304555
0.9193784433785976, 21.682499716304555
0.9193784433785976, 21.682499716304555
0.931177812433096, 24.40013423216797
0.931177812433096, 24.40013423216797
0.931177812433096, 24.40013423216797
0.931177812433096, 24.40013423216797
0.931177812433096, 24.40013423216797
0.5712462807702627, 30.282898990787338</code></pre>
<p>We will reexamine the example, in order to illustrate a random walk sampler. For a random walk sampler, we need to have a symmetric distribution. The random variable <span class="math inline">\(X\)</span> has a symmetric distribution if and only if there is a number <span class="math inline">\(c\)</span> such that <span class="math inline">\(P(X &lt; c âˆ’ k)=P(X &gt; c+k)\)</span>, for all <span class="math inline">\(k\)</span>. A partial list of symmetric distributions can be found on this <a href="https://en.wikipedia.org/wiki/Symmetric_probability_distribution">Wikipedia page</a>. The most commonly used distributions in random walk samplers are the uniform and the normal distributions.</p>
<p>The main challenge that we face in this example is that the proposal distribution, <span class="math inline">\(q(\vec{x}|\vec{y})\)</span> should have the same set of possible values as the multi-variate distribution function <span class="math inline">\(f(\vec{x})\)</span>. In the example <span class="math inline">\(f(\vec{x})\)</span> is bounded within the limits, <span class="math inline">\(0.5 \leq x_1 \leq 1.5\)</span> and <span class="math inline">\(20 \leq x_2 \leq 35\)</span>. We avoided this issue in the independence sampler implementation because of the choice of the beta distributions for the marginals of the sampler.</p>
<p>As previously noted, typical implementations have, <span class="math inline">\(\vec{Y} = \vec{x} + \vec{W}\)</span>, where <span class="math inline">\(\vec{W} \sim G(\vec{W})\)</span> and <span class="math inline">\(G(\cdot)\)</span> is symmetric. Because the proposed value <span class="math inline">\(\vec{x} + \vec{W}\)</span> may â€œwalkâ€ outside the bounds, we need to handle this situation. One possible choice would be to use the truncated normal distribution <span class="math inline">\(N_{[a,b]}(\mu = x, \sigma^2)\)</span>, where <span class="math inline">\([a,b]\)</span> is specified by our limits on <span class="math inline">\(\vec{X}\)</span>. We leave this possibility as an exercise for the reader. In this example, we will use the uniform distribution <span class="math inline">\(U(x-c,x+c)\)</span> where <span class="math inline">\(c &gt; 0\)</span> is some typically small positive constant. We will handle the boundary situation within the implementation.</p>
<p>The implementation for <span class="math inline">\(f(\vec{x})\)</span> remains the same. The proposal ratio and proposal function are implemented in the following code. Here we specify the intervals for each of the dimensions, the small constants, <span class="math inline">\(c_i\)</span> for each dimension, and the random variable, <span class="math inline">\(e_i \sim U(-c_i, c_i)\)</span> for each dimension. In this case the proposal ratio is always 1.0.</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb402-1"><a href="ch9GMVRVs.html#cb402-1" tabindex="-1"></a><span class="kw">object</span> ExampleRandomWalkPF <span class="op">:</span> <span class="dt">ProposalFunctionMVIfc</span> <span class="op">{</span></span>
<span id="cb402-2"><a href="ch9GMVRVs.html#cb402-2" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">y1Interval</span> <span class="op">=</span> Interval<span class="op">(</span><span class="fl">0.5</span><span class="op">,</span> <span class="fl">1.5</span><span class="op">)</span></span>
<span id="cb402-3"><a href="ch9GMVRVs.html#cb402-3" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">y2Interval</span> <span class="op">=</span> Interval<span class="op">(</span><span class="fl">20.0</span><span class="op">,</span> <span class="fl">35.0</span><span class="op">)</span></span>
<span id="cb402-4"><a href="ch9GMVRVs.html#cb402-4" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">y1c</span> <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb402-5"><a href="ch9GMVRVs.html#cb402-5" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">y2c</span> <span class="op">=</span> <span class="fl">5.0</span></span>
<span id="cb402-6"><a href="ch9GMVRVs.html#cb402-6" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">e1rv</span> <span class="op">=</span> UniformRV<span class="op">(-</span>y1c<span class="op">,</span> y1c<span class="op">)</span></span>
<span id="cb402-7"><a href="ch9GMVRVs.html#cb402-7" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">val</span> <span class="va">e2rv</span> <span class="op">=</span> UniformRV<span class="op">(-</span>y2c<span class="op">,</span> y2c<span class="op">)</span></span>
<span id="cb402-8"><a href="ch9GMVRVs.html#cb402-8" tabindex="-1"></a></span>
<span id="cb402-9"><a href="ch9GMVRVs.html#cb402-9" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">val</span> <span class="va">dimension</span><span class="op">:</span> <span class="kw">Int</span></span>
<span id="cb402-10"><a href="ch9GMVRVs.html#cb402-10" tabindex="-1"></a>        <span class="kw">get</span><span class="op">()</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb402-11"><a href="ch9GMVRVs.html#cb402-11" tabindex="-1"></a></span>
<span id="cb402-12"><a href="ch9GMVRVs.html#cb402-12" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">fun</span> <span class="fu">proposalRatio</span><span class="op">(</span><span class="va">currentX</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">,</span> <span class="va">proposedY</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">):</span> <span class="dt">Double</span> <span class="op">{</span></span>
<span id="cb402-13"><a href="ch9GMVRVs.html#cb402-13" tabindex="-1"></a>        <span class="co">//g(y|x) = g(x|y) proposal ratio = g(x|y)/g(y|x) = 1.0</span></span>
<span id="cb402-14"><a href="ch9GMVRVs.html#cb402-14" tabindex="-1"></a>        <span class="kw">return</span> <span class="op">(</span><span class="fl">1.0</span><span class="op">)</span></span>
<span id="cb402-15"><a href="ch9GMVRVs.html#cb402-15" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb402-16"><a href="ch9GMVRVs.html#cb402-16" tabindex="-1"></a></span>
<span id="cb402-17"><a href="ch9GMVRVs.html#cb402-17" tabindex="-1"></a>    <span class="kw">private</span> <span class="kw">fun</span> <span class="fu">genYGivenX</span><span class="op">(</span><span class="va">interval</span><span class="op">:</span> <span class="dt">Interval</span><span class="op">,</span> <span class="va">rv</span><span class="op">:</span> <span class="dt">UniformRV</span><span class="op">,</span> <span class="va">x</span><span class="op">:</span> <span class="dt">Double</span><span class="op">):</span> <span class="dt">Double</span> <span class="op">{</span></span>
<span id="cb402-18"><a href="ch9GMVRVs.html#cb402-18" tabindex="-1"></a>        <span class="kw">var</span> <span class="va">yp</span><span class="op">:</span> <span class="kw">Double</span></span>
<span id="cb402-19"><a href="ch9GMVRVs.html#cb402-19" tabindex="-1"></a>        <span class="cf">do</span> <span class="op">{</span></span>
<span id="cb402-20"><a href="ch9GMVRVs.html#cb402-20" tabindex="-1"></a>            <span class="kw">val</span> <span class="va">e</span> <span class="op">=</span> rv<span class="op">.</span>value</span>
<span id="cb402-21"><a href="ch9GMVRVs.html#cb402-21" tabindex="-1"></a>            yp <span class="op">=</span> x <span class="op">+</span> e</span>
<span id="cb402-22"><a href="ch9GMVRVs.html#cb402-22" tabindex="-1"></a>        <span class="op">}</span> <span class="cf">while</span> <span class="op">(!</span>interval<span class="op">.</span>contains<span class="op">(</span>yp<span class="op">))</span></span>
<span id="cb402-23"><a href="ch9GMVRVs.html#cb402-23" tabindex="-1"></a>        <span class="kw">return</span> yp</span>
<span id="cb402-24"><a href="ch9GMVRVs.html#cb402-24" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb402-25"><a href="ch9GMVRVs.html#cb402-25" tabindex="-1"></a>    </span>
<span id="cb402-26"><a href="ch9GMVRVs.html#cb402-26" tabindex="-1"></a>    <span class="kw">override</span> <span class="kw">fun</span> <span class="fu">generateProposedGivenCurrent</span><span class="op">(</span><span class="va">currentX</span><span class="op">:</span> <span class="dt">DoubleArray</span><span class="op">):</span> <span class="dt">DoubleArray</span> <span class="op">{</span></span>
<span id="cb402-27"><a href="ch9GMVRVs.html#cb402-27" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">y1</span> <span class="op">=</span> genYGivenX<span class="op">(</span>y1Interval<span class="op">,</span> e1rv<span class="op">,</span> currentX<span class="op">[</span><span class="dv">0</span><span class="op">])</span></span>
<span id="cb402-28"><a href="ch9GMVRVs.html#cb402-28" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">y2</span> <span class="op">=</span> genYGivenX<span class="op">(</span>y2Interval<span class="op">,</span> e2rv<span class="op">,</span> currentX<span class="op">[</span><span class="dv">1</span><span class="op">])</span></span>
<span id="cb402-29"><a href="ch9GMVRVs.html#cb402-29" tabindex="-1"></a>        <span class="kw">return</span> doubleArrayOf<span class="op">(</span>y1<span class="op">,</span> y2<span class="op">)</span></span>
<span id="cb402-30"><a href="ch9GMVRVs.html#cb402-30" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb402-31"><a href="ch9GMVRVs.html#cb402-31" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>A small private function <code>genYGivenX()</code> is used to sample a value <span class="math inline">\(x_i + e_i\)</span> until the values are within the desired intervals. To setup and run this case, we have the following code, which is similar to previous run simulation code, except for the use of the random walk sampler.</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb403-1"><a href="ch9GMVRVs.html#cb403-1" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">f</span> <span class="op">=</span> Function</span>
<span id="cb403-2"><a href="ch9GMVRVs.html#cb403-2" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">q</span> <span class="op">=</span> ExampleRandomWalkPF</span>
<span id="cb403-3"><a href="ch9GMVRVs.html#cb403-3" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">x0</span> <span class="op">=</span> doubleArrayOf<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="fl">27.5</span><span class="op">)</span></span>
<span id="cb403-4"><a href="ch9GMVRVs.html#cb403-4" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">m</span> <span class="op">=</span> MetropolisHastingsMV<span class="op">(</span>x0<span class="op">,</span> f<span class="op">,</span> q<span class="op">)</span></span>
<span id="cb403-5"><a href="ch9GMVRVs.html#cb403-5" tabindex="-1"></a>    m<span class="op">.</span>runWarmUpPeriod<span class="op">(</span><span class="dv">10000</span><span class="op">)</span></span>
<span id="cb403-6"><a href="ch9GMVRVs.html#cb403-6" tabindex="-1"></a>    m<span class="op">.</span>attachObserver<span class="op">(</span>WriteData<span class="op">(</span><span class="st">&quot;RWData.csv&quot;</span><span class="op">))</span></span>
<span id="cb403-7"><a href="ch9GMVRVs.html#cb403-7" tabindex="-1"></a>    m<span class="op">.</span>runAll<span class="op">(</span><span class="dv">10000</span><span class="op">)</span></span>
<span id="cb403-8"><a href="ch9GMVRVs.html#cb403-8" tabindex="-1"></a>    println<span class="op">(</span>m<span class="op">)</span></span></code></pre></div>
<p>The results could be considered a bit better than the independence sampler results. Clearly, the acceptance probability is significantly better for this sampler.</p>
<pre><code>MetropolisHastings1D
Initialized Flag = true
Burn In Flag = true
Initial X =[0.773680150259463, 25.06436933842605]
Current X = [1.393917079069964, 20.76389519938342]
Previous X = [1.1538567477857675, 25.59456469111667]
Last Proposed Y= [1.393917079069964, 20.76389519938342]
Last Prob. of Acceptance = 0.48031020870117797
Last f(Y) = 0.04294751544959516
Last f(X) = 0.08941620367747521
Acceptance Statistics
Statistic{name=&#39;Acceptance Statistics&#39;, n=10000.0, avg=0.785899999999997, sd=0.41021703743479404, ci=[0.7778589276061466, 0.7939410723938475]}
BatchStatistic{name=&#39;X_1&#39;, n=39.0, avg=0.999193515968228, sd=0.0159560164316252, ci=[0.9940211737797846, 1.0043658581566715], lag-1 corr=0.10751413994760596, Total number observed = 10000.0}
BatchStatistic{name=&#39;X_2&#39;, n=39.0, avg=27.370099404669936, sd=0.6779873978358747, ci=[27.150321314312187, 27.589877495027686], lag-1 corr=-0.11710134097028374, Total number observed = 10000.0}</code></pre>
<p>As we can see from the sampled vectors, there appears to be more mixing.</p>
<pre><code>0.7114637098246581, 23.334752715575693
1.3918884893683938, 27.582854620937724
1.0234882610125577, 28.761501219684373
1.0234882610125577, 28.761501219684373
1.0234882610125577, 28.761501219684373
1.022818982310043, 28.05859569138944
0.6279823315850492, 30.684331865598743
1.2590803294191133, 25.866338857499585
0.9952174851225053, 21.43482917651085
0.9882686966013114, 24.419256539368444
0.9882686966013114, 24.419256539368444
0.5990339635411173, 20.575702628065457</code></pre>
<p>This section provided an introduction to Markov Chain Monte Carlo methods. The topic of MCMC is vast and the proliferation of research and applications has been enormously active in the past 20 years. This introduction was meant to only illustrate some of the key concepts that you need to understand when applying the technique using the KSL. There are many additional issues that we did not address, including:</p>
<ul>
<li><p>warm up period determination - This has similar characteristics as to that discussed in Section <a href="simoainfhorizon.html#simoainfhorizoninitialbias">5.6.1</a> but because of the structure of Markov Chains, there are some additional theoretical results that could be explored.</p></li>
<li><p>statistical analysis - As noted in the implementation discussion, the KSL automatically use batch statistics when reporting the MCMC results. There are other procedures, such as standardized time series and others that may be of interest for MCMC.</p></li>
<li><p>design of efficient samplers - As the example noted, the design of samplers can be challenging work. We did not discuss the Gibbs sampler and I encourage the interested reader to review the suggested references for more details and other samplers.</p></li>
</ul>
</div>
</div>
<h3><span class="header-section-number">G</span> References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-banks2005discreteevent" class="csl-entry">
Banks, J., J. Carson, B. Nelson, and D. Nicol. 2005. <em>Discrete-Event System Simulation</em>. 4th ed. Prentice Hall.
</div>
<div id="ref-biller2003modeling" class="csl-entry">
Biller, B., and B. L. Nelson. 2003. <span>â€œModeling and Generating Multivarate Time- Series Input Processes Using a Vector Autogressive Technique.â€</span> <em>Assoc. Comput. Mach. Trans. Modeling and Comput. Simul.</em> 13: 211â€“37.
</div>
<div id="ref-brooks1998" class="csl-entry">
Brooks, Stephen. 1998. <span>â€œMarkov Chain Monte Carlo Method and Its Application.â€</span> <em>Journal of the Royal Statistical Society: Series D (The Statistician)</em> 47 (1): 69â€“100.
</div>
<div id="ref-cario1996autoregressive" class="csl-entry">
Cario, M. C., and B. L. Nelson. 1996. <span>â€œAutoregressive to Anything: Time Series Input Processes for Simulation.â€</span> <em>Operations Research Letters</em> 19: 51â€“58.
</div>
<div id="ref-cario1998numerical" class="csl-entry">
â€”â€”â€”. 1998. <span>â€œNumerical Methods for Fitting and Simulating Autoregressive-to-Anything Processes.â€</span> <em>INFORMS Journal of Computing</em> 10: 72â€“81.
</div>
<div id="ref-fishman2006first" class="csl-entry">
Fishman, George. 2006. <em>A First Course in Monte Carlo</em>. Thomson Brooks/Cole.
</div>
<div id="ref-geyer2011" class="csl-entry">
Geyer, Charles. 2011. <span>â€œHandbook of Markov Chain Monte Carlo.â€</span> In, edited by Galin Jones Steve Brooks Andrew Gelman and Xiao-Li Meng. Vol. 20116022. CRC Handbooks of Modern Statistical Methods. Chapman &amp; Hall.
</div>
<div id="ref-livny1993the" class="csl-entry">
Livny, M., B. Melamed, and A. K. Tsiolis. 1993. <span>â€œThe Impact of Autocorrelation on Queueing Systems.â€</span> <em>Management Science</em> 39 (3): 322â€“39.
</div>
<div id="ref-Nadarajah_Afuecheta_Chan_2017" class="csl-entry">
Nadarajah, Saralees, Emmanuel Afuecheta, and Stephen Chan. 2017. <span>â€œA Compendium of Copulas.â€</span> <em>Statistica</em> 77 (4): 279â€“328. <a href="https://doi.org/10.6092/issn.1973-2201/7202">https://doi.org/10.6092/issn.1973-2201/7202</a>.
</div>
<div id="ref-Nelsen2004PropertiesAA" class="csl-entry">
Nelsen, Roger B. 2004. <span>â€œProperties and Applications of Copulas : A Brief Survey.â€</span> In. <a href="https://api.semanticscholar.org/CorpusID:2508363">https://api.semanticscholar.org/CorpusID:2508363</a>.
</div>
<div id="ref-rbNelson1999" class="csl-entry">
Nelson, Roger B. 1999. <em>An Introduction to Copulas</em>. ISBN o-387-98623-5. New York: Springer-Verlag.
</div>
<div id="ref-patuwo1993the" class="csl-entry">
Patuwo, B. E., R. L. Disney, and D. C. Mcnickle. 1993. <span>â€œThe Effect of Correlated Arrivals on Queues.â€</span> <em>IIE Transactions</em> 25 (3): 105â€“10.
</div>
<div id="ref-pishro-nik" class="csl-entry">
Pishro-Nik, H. 2014. <em>Introduction to Probability, Statistics, and Random Processes</em>. Kappa Research LLC.
</div>
<div id="ref-Christian2020" class="csl-entry">
Robert, Christian P., and Wu Changye. n.d. <span>â€œMarkov Chain Monte Carlo Methods, a Survey with Some Frequent Misunderstandings.â€</span> <a href="http://arxiv.org/abs/2001.06249">http://arxiv.org/abs/2001.06249</a>.
</div>
<div id="ref-ross2023" class="csl-entry">
Ross, Sheldon M. 2023. <em>Simulation (6th Edition)</em>. Elsevier.
</div>
<div id="ref-rubenstein-kroese" class="csl-entry">
Rubinstein, R., and D. Kroese. 2017. <em>Simulation and the Monte Carlo Method</em>. John Wiley &amp; Sons Inc.
</div>
<div id="ref-sklar1959" class="csl-entry">
Sklar, A. 1959. <span>â€œFonctions de r ÌEpartition a Ì n Dimensions Et Leurs Marges.â€</span> <em>Publ. Inst. Statist. Univ. Paris</em> 8: 229â€“31.
</div>
<div id="ref-speagle2020" class="csl-entry">
Speagle, Joshua S. 2020. <span>â€œA Conceptual Introduction to Markov Chain Monte Carlo Methods.â€</span> 2020. <a href="http://arxiv.org/abs/1909.12313">http://arxiv.org/abs/1909.12313</a>.
</div>
<div id="ref-Ravenzwaaij2018" class="csl-entry">
Van Ravenzwaaij, Pete Cassey, Don, and Scott D. Brown. 2018. <span>â€œA Simple Introduction to Markov Chain Monteâ€“Carlo Sampling.â€</span> <em>Psychonomic Bulletin &amp; Review</em> 25 (1): 143â€“54.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch9VRTs.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summary-4.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
