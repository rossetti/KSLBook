<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.6 Analysis of Infinite Horizon Simulations | Simulation Modeling using the Kotlin Simulation Library (KSL)</title>
  <meta name="description" content="A book that illustrates the basics of using the KSL. The output format for this book is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="5.6 Analysis of Infinite Horizon Simulations | Simulation Modeling using the Kotlin Simulation Library (KSL)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A book that illustrates the basics of using the KSL. The output format for this book is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.6 Analysis of Infinite Horizon Simulations | Simulation Modeling using the Kotlin Simulation Library (KSL)" />
  
  <meta name="twitter:description" content="A book that illustrates the basics of using the KSL. The output format for this book is bookdown::gitbook." />
  

<meta name="author" content="Manuel D. Rossetti" />


<meta name="date" content="2024-07-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="simoaseqsampling.html"/>
<link rel="next" href="simoacomparingSystems.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Simulation Modeling using the Kotlin Simulation Library (KSL)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="release-history.html"><a href="release-history.html"><i class="fa fa-check"></i>Release History</a></li>
<li class="chapter" data-level="" data-path="ksl-project-page.html"><a href="ksl-project-page.html"><i class="fa fa-check"></i>KSL Project Page</a></li>
<li class="chapter" data-level="" data-path="book-support-files.html"><a href="book-support-files.html"><i class="fa fa-check"></i>Book Support Files</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="intended-audience.html"><a href="intended-audience.html"><i class="fa fa-check"></i>Intended Audience</a></li>
<li class="chapter" data-level="" data-path="organization-of-the-book.html"><a href="organization-of-the-book.html"><i class="fa fa-check"></i>Organization of the Book</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the Author</a></li>
<li class="chapter" data-level="1" data-path="ch1.html"><a href="ch1.html"><i class="fa fa-check"></i><b>1</b> Simulation Modeling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="simulation-modeling.html"><a href="simulation-modeling.html"><i class="fa fa-check"></i><b>1.1</b> Simulation Modeling</a></li>
<li class="chapter" data-level="1.2" data-path="why-simulate.html"><a href="why-simulate.html"><i class="fa fa-check"></i><b>1.2</b> Why Simulate?</a></li>
<li class="chapter" data-level="1.3" data-path="types-of-systems-and-simulation-models.html"><a href="types-of-systems-and-simulation-models.html"><i class="fa fa-check"></i><b>1.3</b> Types of Systems and Simulation Models</a></li>
<li class="chapter" data-level="1.4" data-path="simulation-descriptive-or-prescriptive-modeling.html"><a href="simulation-descriptive-or-prescriptive-modeling.html"><i class="fa fa-check"></i><b>1.4</b> Simulation: Descriptive or Prescriptive Modeling?</a></li>
<li class="chapter" data-level="1.5" data-path="randomness-in-simulation.html"><a href="randomness-in-simulation.html"><i class="fa fa-check"></i><b>1.5</b> Randomness in Simulation</a></li>
<li class="chapter" data-level="1.6" data-path="simulation-languages.html"><a href="simulation-languages.html"><i class="fa fa-check"></i><b>1.6</b> Simulation Languages</a></li>
<li class="chapter" data-level="1.7" data-path="ch1secsimMeth.html"><a href="ch1secsimMeth.html"><i class="fa fa-check"></i><b>1.7</b> Simulation Methodology</a></li>
<li class="chapter" data-level="1.8" data-path="overview-of-the-kotlin-simulation-library.html"><a href="overview-of-the-kotlin-simulation-library.html"><i class="fa fa-check"></i><b>1.8</b> Overview of the Kotlin Simulation Library</a></li>
<li class="chapter" data-level="1.9" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch2rng.html"><a href="ch2rng.html"><i class="fa fa-check"></i><b>2</b> Modeling Randomness</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch2generator.html"><a href="ch2generator.html"><i class="fa fa-check"></i><b>2.1</b> Random Number Generator</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ch2generator.html"><a href="ch2generator.html#ch2randompkg"><i class="fa fa-check"></i><b>2.1.1</b> Random Package</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch2generator.html"><a href="ch2generator.html#ch2creatingStreams"><i class="fa fa-check"></i><b>2.1.2</b> Creating and Using Streams</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch2generator.html"><a href="ch2generator.html#ch2crn"><i class="fa fa-check"></i><b>2.1.3</b> Common Random Numbers</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch2generator.html"><a href="ch2generator.html#ch2antitheticStreams"><i class="fa fa-check"></i><b>2.1.4</b> Creating and Using Antithetic Streams</a></li>
<li class="chapter" data-level="2.1.5" data-path="ch2generator.html"><a href="ch2generator.html#ch2rnFAQ"><i class="fa fa-check"></i><b>2.1.5</b> Frequently Asked Questions about Random Numbers</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="rvg.html"><a href="rvg.html"><i class="fa fa-check"></i><b>2.2</b> Random Variate Generation</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="rvg.html"><a href="rvg.html#basic-random-variate-generation"><i class="fa fa-check"></i><b>2.2.1</b> Basic Random Variate Generation</a></li>
<li class="chapter" data-level="2.2.2" data-path="rvg.html"><a href="rvg.html#rvg_dists"><i class="fa fa-check"></i><b>2.2.2</b> Continuous and Discrete Random Variables</a></li>
<li class="chapter" data-level="2.2.3" data-path="rvg.html"><a href="rvg.html#rvguse"><i class="fa fa-check"></i><b>2.2.3</b> Creating and Using Random Variables</a></li>
<li class="chapter" data-level="2.2.4" data-path="rvg.html"><a href="rvg.html#functions-of-random-variables"><i class="fa fa-check"></i><b>2.2.4</b> Functions of Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="probModels.html"><a href="probModels.html"><i class="fa fa-check"></i><b>2.3</b> Probability Distribution Models</a></li>
<li class="chapter" data-level="2.4" data-path="distFitting.html"><a href="distFitting.html"><i class="fa fa-check"></i><b>2.4</b> Distribution Fitting Using the KSL</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="distFitting.html"><a href="distFitting.html#estimating-distribution-parameters"><i class="fa fa-check"></i><b>2.4.1</b> Estimating Distribution Parameters</a></li>
<li class="chapter" data-level="2.4.2" data-path="distFitting.html"><a href="distFitting.html#continuous-distribution-recommendation-framework"><i class="fa fa-check"></i><b>2.4.2</b> Continuous Distribution Recommendation Framework</a></li>
<li class="chapter" data-level="2.4.3" data-path="distFitting.html"><a href="distFitting.html#discrete-distribution-framework"><i class="fa fa-check"></i><b>2.4.3</b> Discrete Distribution Framework</a></li>
<li class="chapter" data-level="2.4.4" data-path="distFitting.html"><a href="distFitting.html#pdfmexamples"><i class="fa fa-check"></i><b>2.4.4</b> Illustrative Examples from Appendix @ref(appidm)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>2.5</b> Summary</a></li>
<li class="chapter" data-level="2.6" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mcm.html"><a href="mcm.html"><i class="fa fa-check"></i><b>3</b> Monte Carlo Methods</a>
<ul>
<li class="chapter" data-level="3.1" data-path="kslStatistics.html"><a href="kslStatistics.html"><i class="fa fa-check"></i><b>3.1</b> Collecting Statistics</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="kslStatistics.html"><a href="kslStatistics.html#creating-and-using-a-statistic"><i class="fa fa-check"></i><b>3.1.1</b> Creating and Using a Statistic</a></li>
<li class="chapter" data-level="3.1.2" data-path="kslStatistics.html"><a href="kslStatistics.html#histFreq"><i class="fa fa-check"></i><b>3.1.2</b> Histograms and Frequencies</a></li>
<li class="chapter" data-level="3.1.3" data-path="kslStatistics.html"><a href="kslStatistics.html#ch3batchStats"><i class="fa fa-check"></i><b>3.1.3</b> Batch Statistics</a></li>
<li class="chapter" data-level="3.1.4" data-path="kslStatistics.html"><a href="kslStatistics.html#ch3StatSummary"><i class="fa fa-check"></i><b>3.1.4</b> Statistics Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ssMC.html"><a href="ssMC.html"><i class="fa fa-check"></i><b>3.2</b> Simple Monte Carlo Integration</a></li>
<li class="chapter" data-level="3.3" data-path="ch3StatReview.html"><a href="ch3StatReview.html"><i class="fa fa-check"></i><b>3.3</b> Review of Statistical Concepts</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="ch3StatReview.html"><a href="ch3StatReview.html#point-estimates-and-confidence-intervals"><i class="fa fa-check"></i><b>3.3.1</b> Point Estimates and Confidence Intervals</a></li>
<li class="chapter" data-level="3.3.2" data-path="ch3StatReview.html"><a href="ch3StatReview.html#ch3SampleSize"><i class="fa fa-check"></i><b>3.3.2</b> Sample Size Determination</a></li>
<li class="chapter" data-level="3.3.3" data-path="ch3StatReview.html"><a href="ch3StatReview.html#determining-the-sample-size-for-a-monte-carlo-simulation-experiment"><i class="fa fa-check"></i><b>3.3.3</b> Determining the Sample Size for a Monte Carlo Simulation Experiment</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="craps.html"><a href="craps.html"><i class="fa fa-check"></i><b>3.4</b> Simulating the Game of Craps</a></li>
<li class="chapter" data-level="3.5" data-path="the-news-vendor-problem.html"><a href="the-news-vendor-problem.html"><i class="fa fa-check"></i><b>3.5</b> The News Vendor Problem</a></li>
<li class="chapter" data-level="3.6" data-path="ch3InsProcess.html"><a href="ch3InsProcess.html"><i class="fa fa-check"></i><b>3.6</b> A Simple Inspection Process</a></li>
<li class="chapter" data-level="3.7" data-path="ch3SAN.html"><a href="ch3SAN.html"><i class="fa fa-check"></i><b>3.7</b> Stochastic Activity Networks</a></li>
<li class="chapter" data-level="3.8" data-path="mcmExperiments.html"><a href="mcmExperiments.html"><i class="fa fa-check"></i><b>3.8</b> Monte-Carlo Experiments</a></li>
<li class="chapter" data-level="3.9" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>3.9</b> Summary</a></li>
<li class="chapter" data-level="3.10" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>3.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introDEDS.html"><a href="introDEDS.html"><i class="fa fa-check"></i><b>4</b> Introduction to Discrete Event Modeling</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introDEDSdeds.html"><a href="introDEDSdeds.html"><i class="fa fa-check"></i><b>4.1</b> Discrete-Event Dynamic Systems</a></li>
<li class="chapter" data-level="4.2" data-path="HowDEDSClockWorks.html"><a href="HowDEDSClockWorks.html"><i class="fa fa-check"></i><b>4.2</b> How the Discrete-Event Clock Works</a></li>
<li class="chapter" data-level="4.3" data-path="QHandExample.html"><a href="QHandExample.html"><i class="fa fa-check"></i><b>4.3</b> Simulating a Queueing System By Hand</a></li>
<li class="chapter" data-level="4.4" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html"><i class="fa fa-check"></i><b>4.4</b> Modeling DEDS in the KSL</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#event-scheduling"><i class="fa fa-check"></i><b>4.4.1</b> Event Scheduling</a></li>
<li class="chapter" data-level="4.4.2" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#introDEDSschedExamples"><i class="fa fa-check"></i><b>4.4.2</b> Simple Event Scheduling Examples</a></li>
<li class="chapter" data-level="4.4.3" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#introDEDSUpDown"><i class="fa fa-check"></i><b>4.4.3</b> Up and Down Component Example</a></li>
<li class="chapter" data-level="4.4.4" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#introDEDSPharmacy"><i class="fa fa-check"></i><b>4.4.4</b> Modeling a Simple Queueing System</a></li>
<li class="chapter" data-level="4.4.5" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#more-details-about-the-pharmacy-model-implementation"><i class="fa fa-check"></i><b>4.4.5</b> More Details About the Pharmacy Model Implementation</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="enhancing-the-drive-through-pharmacy-model.html"><a href="enhancing-the-drive-through-pharmacy-model.html"><i class="fa fa-check"></i><b>4.5</b> Enhancing the Drive Through Pharmacy Model</a></li>
<li class="chapter" data-level="4.6" data-path="DTPExpanded.html"><a href="DTPExpanded.html"><i class="fa fa-check"></i><b>4.6</b> More Drive Through Fun</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="DTPExpanded.html"><a href="DTPExpanded.html#modeling-a-simple-resource"><i class="fa fa-check"></i><b>4.6.1</b> Modeling a Simple Resource</a></li>
<li class="chapter" data-level="4.6.2" data-path="DTPExpanded.html"><a href="DTPExpanded.html#modeling-a-resource-with-a-waiting-line"><i class="fa fa-check"></i><b>4.6.2</b> Modeling a Resource with a Waiting Line</a></li>
<li class="chapter" data-level="4.6.3" data-path="DTPExpanded.html"><a href="DTPExpanded.html#modeling-the-tandem-queue-of-example-refexmexch4tandemq"><i class="fa fa-check"></i><b>4.6.3</b> Modeling the Tandem Queue of Example @ref(exm:exCh4TandemQ)</a></li>
<li class="chapter" data-level="4.6.4" data-path="DTPExpanded.html"><a href="DTPExpanded.html#modeling-with-the-station-package"><i class="fa fa-check"></i><b>4.6.4</b> Modeling with the Station Package</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="introDEDSSummary.html"><a href="introDEDSSummary.html"><i class="fa fa-check"></i><b>4.7</b> Summary</a></li>
<li class="chapter" data-level="4.8" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>4.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simoa.html"><a href="simoa.html"><i class="fa fa-check"></i><b>5</b> Analyzing and Accessing Simulation Output</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simoadatatypes.html"><a href="simoadatatypes.html"><i class="fa fa-check"></i><b>5.1</b> Types of Statistical Variables</a></li>
<li class="chapter" data-level="5.2" data-path="simoasimtypes.html"><a href="simoasimtypes.html"><i class="fa fa-check"></i><b>5.2</b> Types of Simulation With Respect To Output Analysis</a></li>
<li class="chapter" data-level="5.3" data-path="simoafinhorizon.html"><a href="simoafinhorizon.html"><i class="fa fa-check"></i><b>5.3</b> Analysis of Finite Horizon Simulations</a></li>
<li class="chapter" data-level="5.4" data-path="simoafinhorizonex.html"><a href="simoafinhorizonex.html"><i class="fa fa-check"></i><b>5.4</b> Capturing Output for a Simple Finite Horizon Simulation</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="simoafinhorizonex.html"><a href="simoafinhorizonex.html#simoaCapture"><i class="fa fa-check"></i><b>5.4.1</b> KSL Functionality for Capturing Statistical Results</a></li>
<li class="chapter" data-level="5.4.2" data-path="simoafinhorizonex.html"><a href="simoafinhorizonex.html#additional-remarks"><i class="fa fa-check"></i><b>5.4.2</b> Additional Remarks</a></li>
<li class="chapter" data-level="5.4.3" data-path="simoafinhorizonex.html"><a href="simoafinhorizonex.html#querying-the-ksl-database"><i class="fa fa-check"></i><b>5.4.3</b> Querying the KSL Database</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="simoaseqsampling.html"><a href="simoaseqsampling.html"><i class="fa fa-check"></i><b>5.5</b> Sequential Sampling for Finite Horizon Simulations</a></li>
<li class="chapter" data-level="5.6" data-path="simoainfhorizon.html"><a href="simoainfhorizon.html"><i class="fa fa-check"></i><b>5.6</b> Analysis of Infinite Horizon Simulations</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="simoainfhorizon.html"><a href="simoainfhorizon.html#simoainfhorizoninitialbias"><i class="fa fa-check"></i><b>5.6.1</b> Assessing the Effect of Initial Conditions</a></li>
<li class="chapter" data-level="5.6.2" data-path="simoainfhorizon.html"><a href="simoainfhorizon.html#simoainfhorizonrepDeletion"><i class="fa fa-check"></i><b>5.6.2</b> Performing the Method of Replication-Deletion</a></li>
<li class="chapter" data-level="5.6.3" data-path="simoainfhorizon.html"><a href="simoainfhorizon.html#simoainfhorizonbatchmeans"><i class="fa fa-check"></i><b>5.6.3</b> The Method of Batch Means</a></li>
<li class="chapter" data-level="5.6.4" data-path="simoainfhorizon.html"><a href="simoainfhorizon.html#simoainfhorizonjslbatching"><i class="fa fa-check"></i><b>5.6.4</b> Performing the Method of Batch Means</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="simoacomparingSystems.html"><a href="simoacomparingSystems.html"><i class="fa fa-check"></i><b>5.7</b> Comparing System Configurations</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="simoacomparingSystems.html"><a href="simoacomparingSystems.html#simoacomparingSystems:two"><i class="fa fa-check"></i><b>5.7.1</b> Comparing Two Systems</a></li>
<li class="chapter" data-level="5.7.2" data-path="simoacomparingSystems.html"><a href="simoacomparingSystems.html#simoacomparingSystemsMCB"><i class="fa fa-check"></i><b>5.7.2</b> Concepts for Comparing Systems</a></li>
<li class="chapter" data-level="5.7.3" data-path="simoacomparingSystems.html"><a href="simoacomparingSystems.html#multiple-comparison-with-the-best-procedures-mcb"><i class="fa fa-check"></i><b>5.7.3</b> Multiple Comparison with the Best Procedures (MCB)</a></li>
<li class="chapter" data-level="5.7.4" data-path="simoacomparingSystems.html"><a href="simoacomparingSystems.html#ch5Screening"><i class="fa fa-check"></i><b>5.7.4</b> Screening Procedures</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="ch5Scenarios.html"><a href="ch5Scenarios.html"><i class="fa fa-check"></i><b>5.8</b> Simulating Many Scenarios</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="ch5Scenarios.html"><a href="ch5Scenarios.html#controlAntns"><i class="fa fa-check"></i><b>5.8.1</b> Control Annotations</a></li>
<li class="chapter" data-level="5.8.2" data-path="ch5Scenarios.html"><a href="ch5Scenarios.html#rvParameters"><i class="fa fa-check"></i><b>5.8.2</b> Random Variable Parameters</a></li>
<li class="chapter" data-level="5.8.3" data-path="ch5Scenarios.html"><a href="ch5Scenarios.html#kslScenarios"><i class="fa fa-check"></i><b>5.8.3</b> Setting Up and Running Multiple Scenarios</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="simoasummary.html"><a href="simoasummary.html"><i class="fa fa-check"></i><b>5.9</b> Summary</a></li>
<li class="chapter" data-level="5.10" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>5.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="processview.html"><a href="processview.html"><i class="fa fa-check"></i><b>6</b> Process View Modeling Using the KSL</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ch6Entities.html"><a href="ch6Entities.html"><i class="fa fa-check"></i><b>6.1</b> What are Entities?</a></li>
<li class="chapter" data-level="6.2" data-path="pvIntro.html"><a href="pvIntro.html"><i class="fa fa-check"></i><b>6.2</b> The Process View</a></li>
<li class="chapter" data-level="6.3" data-path="understanding-ksl-processes-and-entities.html"><a href="understanding-ksl-processes-and-entities.html"><i class="fa fa-check"></i><b>6.3</b> Understanding KSL Processes and Entities</a></li>
<li class="chapter" data-level="6.4" data-path="examples-of-process-modeling.html"><a href="examples-of-process-modeling.html"><i class="fa fa-check"></i><b>6.4</b> Examples of Process Modeling</a></li>
<li class="chapter" data-level="6.5" data-path="modeling-a-stem-career-mixer.html"><a href="modeling-a-stem-career-mixer.html"><i class="fa fa-check"></i><b>6.5</b> Modeling a STEM Career Mixer</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="modeling-a-stem-career-mixer.html"><a href="modeling-a-stem-career-mixer.html#conceptualizing-the-system"><i class="fa fa-check"></i><b>6.5.1</b> Conceptualizing the System</a></li>
<li class="chapter" data-level="6.5.2" data-path="modeling-a-stem-career-mixer.html"><a href="modeling-a-stem-career-mixer.html#implementing-the-stem-mixer-model"><i class="fa fa-check"></i><b>6.5.2</b> Implementing the STEM Mixer Model</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="the-tie-dye-t-shirt-model.html"><a href="the-tie-dye-t-shirt-model.html"><i class="fa fa-check"></i><b>6.6</b> The Tie-Dye T-Shirt Model</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="the-tie-dye-t-shirt-model.html"><a href="the-tie-dye-t-shirt-model.html#ch4:TieDyeTShirtsSub1"><i class="fa fa-check"></i><b>6.6.1</b> Implementing the Tie-Dye T-Shirt Model</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="summary-2.html"><a href="summary-2.html"><i class="fa fa-check"></i><b>6.7</b> Summary</a></li>
<li class="chapter" data-level="6.8" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch7AdvModeling.html"><a href="ch7AdvModeling.html"><i class="fa fa-check"></i><b>7</b> Advanced Event and Process View Modeling</a>
<ul>
<li class="chapter" data-level="7.1" data-path="modeling-with-processes-and-resources.html"><a href="modeling-with-processes-and-resources.html"><i class="fa fa-check"></i><b>7.1</b> Modeling with Processes and Resources</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="modeling-with-processes-and-resources.html"><a href="modeling-with-processes-and-resources.html#modeling-space-with-resources"><i class="fa fa-check"></i><b>7.1.1</b> Modeling Space with Resources</a></li>
<li class="chapter" data-level="7.1.2" data-path="modeling-with-processes-and-resources.html"><a href="modeling-with-processes-and-resources.html#resource-pools"><i class="fa fa-check"></i><b>7.1.2</b> Resource Pools</a></li>
<li class="chapter" data-level="7.1.3" data-path="modeling-with-processes-and-resources.html"><a href="modeling-with-processes-and-resources.html#computer-test-and-repair-shop-example"><i class="fa fa-check"></i><b>7.1.3</b> Computer Test and Repair Shop Example</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="modeling-non-stationary-systems.html"><a href="modeling-non-stationary-systems.html"><i class="fa fa-check"></i><b>7.2</b> Modeling Non-Stationary Systems</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="modeling-non-stationary-systems.html"><a href="modeling-non-stationary-systems.html#ch7secNSPP"><i class="fa fa-check"></i><b>7.2.1</b> Non-Stationary Arrival Processes</a></li>
<li class="chapter" data-level="7.2.2" data-path="modeling-non-stationary-systems.html"><a href="modeling-non-stationary-systems.html#modeling-resources-under-non-stationary-conditions"><i class="fa fa-check"></i><b>7.2.2</b> Modeling Resources Under Non-Stationary Conditions</a></li>
<li class="chapter" data-level="7.2.3" data-path="modeling-non-stationary-systems.html"><a href="modeling-non-stationary-systems.html#enhancing-the-stem-career-mixer-model"><i class="fa fa-check"></i><b>7.2.3</b> Enhancing the STEM Career Mixer Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="examples-of-advanced-event-models.html"><a href="examples-of-advanced-event-models.html"><i class="fa fa-check"></i><b>7.3</b> Examples of Advanced Event Models</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="examples-of-advanced-event-models.html"><a href="examples-of-advanced-event-models.html#ch6s1sb4sub3"><i class="fa fa-check"></i><b>7.3.1</b> Modeling Balking and Reneging</a></li>
<li class="chapter" data-level="7.3.2" data-path="examples-of-advanced-event-models.html"><a href="examples-of-advanced-event-models.html#rqModel"><i class="fa fa-check"></i><b>7.3.2</b> Modeling a Reorder Point, Reorder Quantity Inventory Policy</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="summary-3.html"><a href="summary-3.html"><i class="fa fa-check"></i><b>7.4</b> Summary</a></li>
<li class="chapter" data-level="7.5" data-path="exercises-6.html"><a href="exercises-6.html"><i class="fa fa-check"></i><b>7.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch9AdvMC.html"><a href="ch9AdvMC.html"><i class="fa fa-check"></i><b>8</b> Advanced Monte Carlo Methods</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ch9BootStrapping.html"><a href="ch9BootStrapping.html"><i class="fa fa-check"></i><b>8.1</b> Bootstrap Methods</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="ch9BootStrapping.html"><a href="ch9BootStrapping.html#bootstrapping-using-the-ksl"><i class="fa fa-check"></i><b>8.1.1</b> Bootstrapping Using the KSL</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ch9VRTs.html"><a href="ch9VRTs.html"><i class="fa fa-check"></i><b>8.2</b> Variance Reduction Techniques</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ch9VRTs.html"><a href="ch9VRTs.html#common-random-numbers-crn"><i class="fa fa-check"></i><b>8.2.1</b> Common Random Numbers (CRN)</a></li>
<li class="chapter" data-level="8.2.2" data-path="ch9VRTs.html"><a href="ch9VRTs.html#antithetic-variates-av"><i class="fa fa-check"></i><b>8.2.2</b> Antithetic Variates (AV)</a></li>
<li class="chapter" data-level="8.2.3" data-path="ch9VRTs.html"><a href="ch9VRTs.html#indirect-estimation"><i class="fa fa-check"></i><b>8.2.3</b> Indirect Estimation</a></li>
<li class="chapter" data-level="8.2.4" data-path="ch9VRTs.html"><a href="ch9VRTs.html#control-variates-cv"><i class="fa fa-check"></i><b>8.2.4</b> Control Variates (CV)</a></li>
<li class="chapter" data-level="8.2.5" data-path="ch9VRTs.html"><a href="ch9VRTs.html#stratified-and-post-stratified-sampling"><i class="fa fa-check"></i><b>8.2.5</b> Stratified and Post Stratified Sampling</a></li>
<li class="chapter" data-level="8.2.6" data-path="ch9VRTs.html"><a href="ch9VRTs.html#conditional-expectation-ce"><i class="fa fa-check"></i><b>8.2.6</b> Conditional Expectation (CE)</a></li>
<li class="chapter" data-level="8.2.7" data-path="ch9VRTs.html"><a href="ch9VRTs.html#importance-sampling-is"><i class="fa fa-check"></i><b>8.2.7</b> Importance Sampling (IS)</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ch9GMVRVs.html"><a href="ch9GMVRVs.html"><i class="fa fa-check"></i><b>8.3</b> Generating Multi-Variate and Correlated Random Variates</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="ch9GMVRVs.html"><a href="ch9GMVRVs.html#generating-from-a-bivariate-normal-distribution"><i class="fa fa-check"></i><b>8.3.1</b> Generating from a Bivariate Normal Distribution</a></li>
<li class="chapter" data-level="8.3.2" data-path="ch9GMVRVs.html"><a href="ch9GMVRVs.html#copulas-and-multi-variate-generation-methods"><i class="fa fa-check"></i><b>8.3.2</b> Copulas and Multi-variate Generation Methods</a></li>
<li class="chapter" data-level="8.3.3" data-path="ch9GMVRVs.html"><a href="ch9GMVRVs.html#autocorrelated-generation"><i class="fa fa-check"></i><b>8.3.3</b> Autocorrelated Generation</a></li>
<li class="chapter" data-level="8.3.4" data-path="ch9GMVRVs.html"><a href="ch9GMVRVs.html#ch9MCMC"><i class="fa fa-check"></i><b>8.3.4</b> Introduction to Markov Chain Monte Carlo Methods</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="summary-4.html"><a href="summary-4.html"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
<li class="chapter" data-level="8.5" data-path="exercises-7.html"><a href="exercises-7.html"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appRNRV.html"><a href="appRNRV.html"><i class="fa fa-check"></i><b>A</b> Generating Pseudo-Random Numbers and Random Variates</a>
<ul>
<li class="chapter" data-level="A.1" data-path="appRNRVPRN.html"><a href="appRNRVPRN.html"><i class="fa fa-check"></i><b>A.1</b> Pseudo Random Numbers</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="appRNRVPRN.html"><a href="appRNRVPRN.html#appRNRVRNGs"><i class="fa fa-check"></i><b>A.1.1</b> Random Number Generators</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="appRNRVs.html"><a href="appRNRVs.html"><i class="fa fa-check"></i><b>A.2</b> Generating Random Variates from Distributions</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="appRNRVs.html"><a href="appRNRVs.html#inverse-transform-method"><i class="fa fa-check"></i><b>A.2.1</b> Inverse Transform Method</a></li>
<li class="chapter" data-level="A.2.2" data-path="appRNRVs.html"><a href="appRNRVs.html#convolution"><i class="fa fa-check"></i><b>A.2.2</b> Convolution</a></li>
<li class="chapter" data-level="A.2.3" data-path="appRNRVs.html"><a href="appRNRVs.html#acceptancerejection"><i class="fa fa-check"></i><b>A.2.3</b> Acceptance/Rejection</a></li>
<li class="chapter" data-level="A.2.4" data-path="appRNRVs.html"><a href="appRNRVs.html#AppRNRVsubsecMTSRV"><i class="fa fa-check"></i><b>A.2.4</b> Mixture Distributions, Truncated Distributions, and Shifted Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="summary-5.html"><a href="summary-5.html"><i class="fa fa-check"></i><b>A.3</b> Summary</a></li>
<li class="chapter" data-level="A.4" data-path="exercises-8.html"><a href="exercises-8.html"><i class="fa fa-check"></i><b>A.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appidm.html"><a href="appidm.html"><i class="fa fa-check"></i><b>B</b> Probability Distribution Modeling</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appidmsecrvPD.html"><a href="appidmsecrvPD.html"><i class="fa fa-check"></i><b>B.1</b> Random Variables and Probability Distributions</a></li>
<li class="chapter" data-level="B.2" data-path="appidmsecMDD.html"><a href="appidmsecMDD.html"><i class="fa fa-check"></i><b>B.2</b> Modeling with Discrete Distributions</a></li>
<li class="chapter" data-level="B.3" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html"><i class="fa fa-check"></i><b>B.3</b> Fitting Discrete Distributions</a>
<ul>
<li class="chapter" data-level="B.3.1" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#AppDisFitPoissonFit"><i class="fa fa-check"></i><b>B.3.1</b> Fitting a Poisson Distribution</a></li>
<li class="chapter" data-level="B.3.2" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#visualizing-the-data"><i class="fa fa-check"></i><b>B.3.2</b> Visualizing the Data</a></li>
<li class="chapter" data-level="B.3.3" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#estimating-the-rate-parameter-for-the-poisson-distribution"><i class="fa fa-check"></i><b>B.3.3</b> Estimating the Rate Parameter for the Poisson Distribution</a></li>
<li class="chapter" data-level="B.3.4" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#chi-squared-goodness-of-fit-test-for-poisson-distribution"><i class="fa fa-check"></i><b>B.3.4</b> Chi-Squared Goodness of Fit Test for Poisson Distribution</a></li>
<li class="chapter" data-level="B.3.5" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#subsubchisqGOF"><i class="fa fa-check"></i><b>B.3.5</b> Chi-Squared Goodness of Fit Test</a></li>
<li class="chapter" data-level="B.3.6" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#using-the-fitdistrplus-r-package-on-discrete-data"><i class="fa fa-check"></i><b>B.3.6</b> Using the fitdistrplus R Package on Discrete Data</a></li>
<li class="chapter" data-level="B.3.7" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#fitting-a-discrete-empirical-distribution"><i class="fa fa-check"></i><b>B.3.7</b> Fitting a Discrete Empirical Distribution</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="appidmsecMCD.html"><a href="appidmsecMCD.html"><i class="fa fa-check"></i><b>B.4</b> Modeling with Continuous Distributions</a></li>
<li class="chapter" data-level="B.5" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html"><i class="fa fa-check"></i><b>B.5</b> Fitting Continuous Distributions</a>
<ul>
<li class="chapter" data-level="B.5.1" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsecvisualizedata"><i class="fa fa-check"></i><b>B.5.1</b> Visualizing the Data</a></li>
<li class="chapter" data-level="B.5.2" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsecstatsdata"><i class="fa fa-check"></i><b>B.5.2</b> Statistically Summarize the Data</a></li>
<li class="chapter" data-level="B.5.3" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsechypothDist"><i class="fa fa-check"></i><b>B.5.3</b> Hypothesizing and Testing a Distribution</a></li>
<li class="chapter" data-level="B.5.4" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#kolmogorov-smirnov-test"><i class="fa fa-check"></i><b>B.5.4</b> Kolmogorov-Smirnov Test</a></li>
<li class="chapter" data-level="B.5.5" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsecvisFit"><i class="fa fa-check"></i><b>B.5.5</b> Visualizing the Fit</a></li>
<li class="chapter" data-level="B.5.6" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidms2sb3"><i class="fa fa-check"></i><b>B.5.6</b> Using the Input Analyzer</a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html"><i class="fa fa-check"></i><b>B.6</b> Testing Uniform (0,1) Pseudo-Random Numbers</a>
<ul>
<li class="chapter" data-level="B.6.1" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#chi-squared-goodness-of-fit-tests-for-pseudo-random-numbers"><i class="fa fa-check"></i><b>B.6.1</b> Chi-Squared Goodness of Fit Tests for Pseudo-Random Numbers</a></li>
<li class="chapter" data-level="B.6.2" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#higher-dimensional-chi-squared-test"><i class="fa fa-check"></i><b>B.6.2</b> Higher Dimensional Chi-Squared Test</a></li>
<li class="chapter" data-level="B.6.3" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#kolmogorov-smirnov-test-for-pseudo-random-numbers"><i class="fa fa-check"></i><b>B.6.3</b> Kolmogorov-Smirnov Test for Pseudo-Random Numbers</a></li>
<li class="chapter" data-level="B.6.4" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#testing-for-independence-and-patterns-in-pseudo-random-numbers"><i class="fa fa-check"></i><b>B.6.4</b> Testing for Independence and Patterns in Pseudo-Random Numbers</a></li>
</ul></li>
<li class="chapter" data-level="B.7" data-path="appdistfitidms2sb4.html"><a href="appdistfitidms2sb4.html"><i class="fa fa-check"></i><b>B.7</b> Additional Distribution Modeling Concepts</a></li>
<li class="chapter" data-level="B.8" data-path="appidmSummary.html"><a href="appidmSummary.html"><i class="fa fa-check"></i><b>B.8</b> Summary</a></li>
<li class="chapter" data-level="B.9" data-path="exercises-9.html"><a href="exercises-9.html"><i class="fa fa-check"></i><b>B.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="appqtAndInvT.html"><a href="appqtAndInvT.html"><i class="fa fa-check"></i><b>C</b> Queueing Theory</a>
<ul>
<li class="chapter" data-level="C.1" data-path="appqts1.html"><a href="appqts1.html"><i class="fa fa-check"></i><b>C.1</b> Single Line Queueing Stations</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="appqts1.html"><a href="appqts1.html#queueing-notation"><i class="fa fa-check"></i><b>C.1.1</b> Queueing Notation</a></li>
<li class="chapter" data-level="C.1.2" data-path="appqts1.html"><a href="appqts1.html#littles-formula"><i class="fa fa-check"></i><b>C.1.2</b> Little’s Formula</a></li>
<li class="chapter" data-level="C.1.3" data-path="appqts1.html"><a href="appqts1.html#appqts1sb1"><i class="fa fa-check"></i><b>C.1.3</b> Deriving Formulas for Markovian Single Queue Systems</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="appqts1sb2.html"><a href="appqts1sb2.html"><i class="fa fa-check"></i><b>C.2</b> Examples and Applications of Queueing Analysis</a>
<ul>
<li class="chapter" data-level="C.2.1" data-path="appqts1sb2.html"><a href="appqts1sb2.html#infinite-queue-examples"><i class="fa fa-check"></i><b>C.2.1</b> Infinite Queue Examples</a></li>
<li class="chapter" data-level="C.2.2" data-path="appqts1sb2.html"><a href="appqts1sb2.html#finite-queue-examples"><i class="fa fa-check"></i><b>C.2.2</b> Finite Queue Examples</a></li>
</ul></li>
<li class="chapter" data-level="C.3" data-path="appqts1sb3.html"><a href="appqts1sb3.html"><i class="fa fa-check"></i><b>C.3</b> Non-Markovian Queues and Approximations</a></li>
<li class="chapter" data-level="C.4" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html"><i class="fa fa-check"></i><b>C.4</b> Summary of Queueing Formulas</a>
<ul>
<li class="chapter" data-level="C.4.1" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mm1-queue"><i class="fa fa-check"></i><b>C.4.1</b> M/M/1 Queue</a></li>
<li class="chapter" data-level="C.4.2" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmc-queue"><i class="fa fa-check"></i><b>C.4.2</b> M/M/c Queue</a></li>
<li class="chapter" data-level="C.4.3" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmck-queue"><i class="fa fa-check"></i><b>C.4.3</b> M/M/c/k Queue</a></li>
<li class="chapter" data-level="C.4.4" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mgcc-queue"><i class="fa fa-check"></i><b>C.4.4</b> M/G/c/c Queue</a></li>
<li class="chapter" data-level="C.4.5" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mm1k-queue"><i class="fa fa-check"></i><b>C.4.5</b> M/M/1/k Queue</a></li>
<li class="chapter" data-level="C.4.6" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmck-queue-1"><i class="fa fa-check"></i><b>C.4.6</b> M/M/c/k Queue</a></li>
<li class="chapter" data-level="C.4.7" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mm1kk-queue"><i class="fa fa-check"></i><b>C.4.7</b> M/M/1/k/k Queue</a></li>
<li class="chapter" data-level="C.4.8" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmckk-queue"><i class="fa fa-check"></i><b>C.4.8</b> M/M/c/k/k Queue</a></li>
</ul></li>
<li class="chapter" data-level="C.5" data-path="exercises-10.html"><a href="exercises-10.html"><i class="fa fa-check"></i><b>C.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="appUtilities.html"><a href="appUtilities.html"><i class="fa fa-check"></i><b>D</b> KSL Utility Packages</a>
<ul>
<li class="chapter" data-level="D.1" data-path="the-outputdirectory-class-and-ksl-object.html"><a href="the-outputdirectory-class-and-ksl-object.html"><i class="fa fa-check"></i><b>D.1</b> The <code>OutputDirectory</code> Class and <code>KSL</code> Object</a></li>
<li class="chapter" data-level="D.2" data-path="logging-options.html"><a href="logging-options.html"><i class="fa fa-check"></i><b>D.2</b> Logging Options</a></li>
<li class="chapter" data-level="D.3" data-path="the-kslfileutil-object.html"><a href="the-kslfileutil-object.html"><i class="fa fa-check"></i><b>D.3</b> The <code>KSLFileUtil</code> Object</a></li>
<li class="chapter" data-level="D.4" data-path="appDCSVEtc.html"><a href="appDCSVEtc.html"><i class="fa fa-check"></i><b>D.4</b> CSV, Excel, and Tabular Data Files</a></li>
<li class="chapter" data-level="D.5" data-path="dfUtil.html"><a href="dfUtil.html"><i class="fa fa-check"></i><b>D.5</b> The <code>DataFrameUtil</code> Object</a></li>
<li class="chapter" data-level="D.6" data-path="ksl-database-utilities.html"><a href="ksl-database-utilities.html"><i class="fa fa-check"></i><b>D.6</b> KSL Database Utilities</a></li>
<li class="chapter" data-level="D.7" data-path="appUtilitiesArrays.html"><a href="appUtilitiesArrays.html"><i class="fa fa-check"></i><b>D.7</b> Array Utilities</a></li>
<li class="chapter" data-level="D.8" data-path="appPlotting.html"><a href="appPlotting.html"><i class="fa fa-check"></i><b>D.8</b> KSL Plotting Utilities</a></li>
<li class="chapter" data-level="D.9" data-path="appExpDesign.html"><a href="appExpDesign.html"><i class="fa fa-check"></i><b>D.9</b> Experimental Design Utilities</a></li>
<li class="chapter" data-level="D.10" data-path="appUtilitiesMisc.html"><a href="appUtilitiesMisc.html"><i class="fa fa-check"></i><b>D.10</b> Miscellaneous Utilities</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>E</b> Distributions</a>
<ul>
<li class="chapter" data-level="E.1" data-path="appDiscreteDistributions.html"><a href="appDiscreteDistributions.html"><i class="fa fa-check"></i><b>E.1</b> Discrete Distrbutions</a></li>
<li class="chapter" data-level="E.2" data-path="appContinuousDistributions.html"><a href="appContinuousDistributions.html"><i class="fa fa-check"></i><b>E.2</b> Continuous Distrbutions</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="appStatTables.html"><a href="appStatTables.html"><i class="fa fa-check"></i><b>F</b> Statistical Tables</a></li>
<li class="chapter" data-level="G" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>G</b> References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Simulation Modeling using the Kotlin Simulation Library (KSL)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simoainfhorizon" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Analysis of Infinite Horizon Simulations<a href="simoainfhorizon.html#simoainfhorizon" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This section discusses how to plan and analyze infinite horizon
simulations. When analyzing infinite horizon simulations, the primary
difficulty is the nature of within replication data. In the finite
horizon case, the statistical analysis is based on three basic
requirements:</p>
<ol style="list-style-type: decimal">
<li><p>Observations are independent</p></li>
<li><p>Observations are sampled from identical distributions</p></li>
<li><p>Observations are drawn from a normal distribution (or enough
observations are present to invoke the central limit theorem)</p></li>
</ol>
<p>These requirements were met by performing independent replications of
the simulation to generate a random sample. In a direct sense, the
data within a replication do not satisfy any of these requirements;
however, certain procedures can be imposed on the manner in which the
observations are gathered to ensure that these statistical assumptions
may be acceptable. The following will first explain why within
replication data typically violates these assumptions and then will
provide some methods for mitigating the violations within the context of
infinite horizon simulations.</p>
<p>To illustrate the challenges related to infinite horizon simulations, a
simple spreadsheet simulation was developed for a M/M/1 queue.</p>
<div class="figure"><span style="display:block;" id="fig:SingleServer"></span>
<img src="figures/ch7/ch7fig30.png" alt="Single Server Queueing System" width="80%" height="80%" />
<p class="caption">
Figure 5.9: Single Server Queueing System
</p>
</div>
<p>Consider a single server queuing system as illustrated Figure <a href="simoainfhorizon.html#fig:SingleServer">5.9</a>.</p>
<p>For a single server queueing system, there is an equation that allows
the computation of the waiting times of each of the customers based on
knowledge of the arrival and service times. Let <span class="math inline">\(X_1, X_2, \ldots\)</span>
represent the successive service times and <span class="math inline">\(Y_1, Y_2, \ldots\)</span> represent
the successive inter-arrival times for each of the customers that visit
the queue. Let <span class="math inline">\(E[Y_i] = 1/\lambda\)</span> be the mean of the inter-arrival
times so that <span class="math inline">\(\lambda\)</span> is the mean arrival rate. Let <span class="math inline">\(E[Y_i] = 1/\mu\)</span>
be the mean of the service times so that <span class="math inline">\(\mu\)</span> is the mean service rate.
Let <span class="math inline">\(W_i\)</span> be the waiting time in the queue for the <span class="math inline">\(i^{th}\)</span> customer.
That is, the time between when the customer arrives until they enter
service.</p>
<p>Lindley’s equation, see <span class="citation">(<a href="#ref-gross1998fundamentals">Gross and Harris 1998</a>)</span>, relates the waiting
time to the arrivals and services as follows:</p>
<p><span class="math display">\[W_{i+1} = max(0, W_i + X_i - Y_i)\]</span></p>
<p>The relationship says that the time that the <span class="math inline">\((i + 1)^{st}\)</span> customer
must wait is the time the <span class="math inline">\(i^{th}\)</span> waited, plus the <span class="math inline">\(i^{th}\)</span> customer’s
service time, <span class="math inline">\(X_i\)</span> (because that customer is in front of the <span class="math inline">\(i^{th}\)</span>
customer), less the time between arrivals of the <span class="math inline">\(i^{th}\)</span> and
<span class="math inline">\((i + 1)^{st}\)</span> customers, <span class="math inline">\(Y_i\)</span>. If <span class="math inline">\(W_i + X_i - Y_i\)</span> is less than zero,
then the (<span class="math inline">\((i + 1)^{st}\)</span> customer arrived after the <span class="math inline">\(i^{th}\)</span> finished
service, and thus the waiting time for the <span class="math inline">\((i + 1)^{st}\)</span> customer is
zero, because his service starts immediately.</p>
<p>Suppose that <span class="math inline">\(X_i \sim exp(E[X_i] = 0.7)\)</span> and
<span class="math inline">\(Y_i \sim exp(E[Y_i] = 1.0)\)</span>. This is a M/M/1 queue with <span class="math inline">\(\lambda\)</span> = 1
and <span class="math inline">\(\mu\)</span> = 10/7. Thus, based on traditional queuing theory results:</p>
<p><span class="math display">\[\rho = 0.7\]</span></p>
<p><span class="math display">\[L_q = \dfrac{0.7 \times 0.7}{1 - 0.7} = 1.6\bar{33}\]</span></p>
<p><span class="math display">\[W_q = \dfrac{L_q}{\lambda} = 1.6\bar{33} \; \text{minutes}\]</span></p>
<div class="example">
<p><span id="exm:ch5ex3" class="example"><strong>Example 5.3  (Lindley Equation) </strong></span>Lindley’s equation can be readily implemented in using KSL constructs as illustrated in the following code listing.</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode kt"><code class="sourceCode kotlin"><span id="cb174-1"><a href="simoainfhorizon.html#cb174-1" tabindex="-1"></a><span class="kw">class</span> LindleyEquation<span class="op">(</span></span>
<span id="cb174-2"><a href="simoainfhorizon.html#cb174-2" tabindex="-1"></a>    <span class="kw">var</span> <span class="va">tba</span><span class="op">:</span> <span class="dt">RandomIfc</span> <span class="op">=</span> ExponentialRV<span class="op">(</span><span class="fl">1.0</span><span class="op">),</span></span>
<span id="cb174-3"><a href="simoainfhorizon.html#cb174-3" tabindex="-1"></a>    <span class="kw">var</span> <span class="va">st</span><span class="op">:</span> <span class="dt">RandomIfc</span> <span class="op">=</span> ExponentialRV<span class="op">(</span><span class="fl">0.7</span><span class="op">),</span></span>
<span id="cb174-4"><a href="simoainfhorizon.html#cb174-4" tabindex="-1"></a>    <span class="kw">var</span> <span class="va">numReps</span><span class="op">:</span> <span class="dt">Int</span> <span class="op">=</span> <span class="dv">30</span><span class="op">,</span></span>
<span id="cb174-5"><a href="simoainfhorizon.html#cb174-5" tabindex="-1"></a>    <span class="kw">var</span> <span class="va">numObs</span><span class="op">:</span> <span class="dt">Int</span> <span class="op">=</span> <span class="dv">100000</span><span class="op">,</span></span>
<span id="cb174-6"><a href="simoainfhorizon.html#cb174-6" tabindex="-1"></a>    <span class="kw">var</span> <span class="va">warmUp</span><span class="op">:</span> <span class="dt">Int</span> <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb174-7"><a href="simoainfhorizon.html#cb174-7" tabindex="-1"></a><span class="op">)</span> <span class="op">{</span></span>
<span id="cb174-8"><a href="simoainfhorizon.html#cb174-8" tabindex="-1"></a>    init <span class="op">{</span></span>
<span id="cb174-9"><a href="simoainfhorizon.html#cb174-9" tabindex="-1"></a>        require<span class="op">(</span>numReps <span class="op">&gt;</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span> <span class="st">&quot;The number of replications must be &gt; 0&quot;</span> <span class="op">}</span></span>
<span id="cb174-10"><a href="simoainfhorizon.html#cb174-10" tabindex="-1"></a>        require<span class="op">(</span>numObs <span class="op">&gt;</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span> <span class="st">&quot;The number of replications must be &gt; 0&quot;</span> <span class="op">}</span></span>
<span id="cb174-11"><a href="simoainfhorizon.html#cb174-11" tabindex="-1"></a>        require<span class="op">(</span>warmUp <span class="op">&gt;=</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span> <span class="st">&quot;The number of replications must be &gt; 0&quot;</span> <span class="op">}</span></span>
<span id="cb174-12"><a href="simoainfhorizon.html#cb174-12" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb174-13"><a href="simoainfhorizon.html#cb174-13" tabindex="-1"></a></span>
<span id="cb174-14"><a href="simoainfhorizon.html#cb174-14" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">avgw</span> <span class="op">=</span> Statistic<span class="op">(</span><span class="st">&quot;Across rep avg waiting time&quot;</span><span class="op">)</span></span>
<span id="cb174-15"><a href="simoainfhorizon.html#cb174-15" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">avgpw</span> <span class="op">=</span> Statistic<span class="op">(</span><span class="st">&quot;Across rep prob of wait&quot;</span><span class="op">)</span></span>
<span id="cb174-16"><a href="simoainfhorizon.html#cb174-16" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">wbar</span> <span class="op">=</span> Statistic<span class="op">(</span><span class="st">&quot;Within rep avg waiting time&quot;</span><span class="op">)</span></span>
<span id="cb174-17"><a href="simoainfhorizon.html#cb174-17" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">pw</span> <span class="op">=</span> Statistic<span class="op">(</span><span class="st">&quot;Within rep prob of wait&quot;</span><span class="op">)</span></span>
<span id="cb174-18"><a href="simoainfhorizon.html#cb174-18" tabindex="-1"></a></span>
<span id="cb174-19"><a href="simoainfhorizon.html#cb174-19" tabindex="-1"></a>    <span class="kw">fun</span> <span class="fu">simulate</span><span class="op">(</span><span class="va">r</span><span class="op">:</span> <span class="dt">Int</span> <span class="op">=</span> numReps<span class="op">,</span> <span class="va">n</span><span class="op">:</span> <span class="dt">Int</span> <span class="op">=</span> numObs<span class="op">,</span> <span class="va">d</span><span class="op">:</span> <span class="dt">Int</span> <span class="op">=</span> warmUp<span class="op">)</span> <span class="op">{</span></span>
<span id="cb174-20"><a href="simoainfhorizon.html#cb174-20" tabindex="-1"></a>        require<span class="op">(</span>r <span class="op">&gt;</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span> <span class="st">&quot;The number of replications must be &gt; 0&quot;</span> <span class="op">}</span></span>
<span id="cb174-21"><a href="simoainfhorizon.html#cb174-21" tabindex="-1"></a>        require<span class="op">(</span>n <span class="op">&gt;</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span> <span class="st">&quot;The number of replications must be &gt; 0&quot;</span> <span class="op">}</span></span>
<span id="cb174-22"><a href="simoainfhorizon.html#cb174-22" tabindex="-1"></a>        require<span class="op">(</span>d <span class="op">&gt;=</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span> <span class="st">&quot;The number of replications must be &gt; 0&quot;</span> <span class="op">}</span></span>
<span id="cb174-23"><a href="simoainfhorizon.html#cb174-23" tabindex="-1"></a>        <span class="cf">for</span> <span class="op">(</span>i <span class="kw">in</span> <span class="fl">1.</span><span class="op">.</span>r<span class="op">)</span> <span class="op">{</span></span>
<span id="cb174-24"><a href="simoainfhorizon.html#cb174-24" tabindex="-1"></a>            <span class="kw">var</span> <span class="va">w</span> <span class="op">=</span> <span class="fl">0.0</span> <span class="co">// initial waiting time</span></span>
<span id="cb174-25"><a href="simoainfhorizon.html#cb174-25" tabindex="-1"></a>            <span class="cf">for</span> <span class="op">(</span>j <span class="kw">in</span> <span class="fl">1.</span><span class="op">.</span>n<span class="op">)</span> <span class="op">{</span></span>
<span id="cb174-26"><a href="simoainfhorizon.html#cb174-26" tabindex="-1"></a>                w <span class="op">=</span> Math<span class="op">.</span>max<span class="op">(</span><span class="fl">0.0</span><span class="op">,</span> w <span class="op">+</span> st<span class="op">.</span>value <span class="op">-</span> tba<span class="op">.</span>value<span class="op">)</span></span>
<span id="cb174-27"><a href="simoainfhorizon.html#cb174-27" tabindex="-1"></a>                wbar<span class="op">.</span>collect<span class="op">(</span>w<span class="op">)</span> <span class="co">// collect waiting time</span></span>
<span id="cb174-28"><a href="simoainfhorizon.html#cb174-28" tabindex="-1"></a>                pw<span class="op">.</span>collect<span class="op">(</span>w <span class="op">&gt;</span> <span class="fl">0.0</span><span class="op">)</span> <span class="co">// collect P(W&gt;0)</span></span>
<span id="cb174-29"><a href="simoainfhorizon.html#cb174-29" tabindex="-1"></a>                <span class="cf">if</span> <span class="op">(</span>j <span class="op">==</span> d<span class="op">)</span> <span class="op">{</span> <span class="co">// clear stats at warmup</span></span>
<span id="cb174-30"><a href="simoainfhorizon.html#cb174-30" tabindex="-1"></a>                    wbar<span class="op">.</span>reset<span class="op">()</span></span>
<span id="cb174-31"><a href="simoainfhorizon.html#cb174-31" tabindex="-1"></a>                    pw<span class="op">.</span>reset<span class="op">()</span></span>
<span id="cb174-32"><a href="simoainfhorizon.html#cb174-32" tabindex="-1"></a>                <span class="op">}</span></span>
<span id="cb174-33"><a href="simoainfhorizon.html#cb174-33" tabindex="-1"></a>            <span class="op">}</span></span>
<span id="cb174-34"><a href="simoainfhorizon.html#cb174-34" tabindex="-1"></a>            <span class="co">//collect across replication statistics</span></span>
<span id="cb174-35"><a href="simoainfhorizon.html#cb174-35" tabindex="-1"></a>            avgw<span class="op">.</span>collect<span class="op">(</span>wbar<span class="op">.</span>average<span class="op">)</span></span>
<span id="cb174-36"><a href="simoainfhorizon.html#cb174-36" tabindex="-1"></a>            avgpw<span class="op">.</span>collect<span class="op">(</span>pw<span class="op">.</span>average<span class="op">)</span></span>
<span id="cb174-37"><a href="simoainfhorizon.html#cb174-37" tabindex="-1"></a>            <span class="co">// clear within replication statistics for next rep</span></span>
<span id="cb174-38"><a href="simoainfhorizon.html#cb174-38" tabindex="-1"></a>            wbar<span class="op">.</span>reset<span class="op">()</span></span>
<span id="cb174-39"><a href="simoainfhorizon.html#cb174-39" tabindex="-1"></a>            pw<span class="op">.</span>reset<span class="op">()</span></span>
<span id="cb174-40"><a href="simoainfhorizon.html#cb174-40" tabindex="-1"></a>        <span class="op">}</span></span>
<span id="cb174-41"><a href="simoainfhorizon.html#cb174-41" tabindex="-1"></a></span>
<span id="cb174-42"><a href="simoainfhorizon.html#cb174-42" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb174-43"><a href="simoainfhorizon.html#cb174-43" tabindex="-1"></a></span>
<span id="cb174-44"><a href="simoainfhorizon.html#cb174-44" tabindex="-1"></a>    <span class="kw">fun</span> <span class="fu">print</span><span class="op">()</span> <span class="op">{</span></span>
<span id="cb174-45"><a href="simoainfhorizon.html#cb174-45" tabindex="-1"></a>        println<span class="op">(</span><span class="st">&quot;Replication/Deletion Lindley Equation Example&quot;</span><span class="op">)</span></span>
<span id="cb174-46"><a href="simoainfhorizon.html#cb174-46" tabindex="-1"></a>        println<span class="op">(</span>avgw<span class="op">)</span></span>
<span id="cb174-47"><a href="simoainfhorizon.html#cb174-47" tabindex="-1"></a>        println<span class="op">(</span>avgpw<span class="op">)</span></span>
<span id="cb174-48"><a href="simoainfhorizon.html#cb174-48" tabindex="-1"></a>        println<span class="op">()</span></span>
<span id="cb174-49"><a href="simoainfhorizon.html#cb174-49" tabindex="-1"></a>        <span class="kw">val</span> <span class="va">sr</span> <span class="op">=</span> StatisticReporter<span class="op">(</span>mutableListOf<span class="op">(</span>avgw<span class="op">,</span> avgpw<span class="op">))</span></span>
<span id="cb174-50"><a href="simoainfhorizon.html#cb174-50" tabindex="-1"></a>        print<span class="op">(</span>sr<span class="op">.</span>halfWidthSummaryReport<span class="op">())</span></span>
<span id="cb174-51"><a href="simoainfhorizon.html#cb174-51" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb174-52"><a href="simoainfhorizon.html#cb174-52" tabindex="-1"></a></span>
<span id="cb174-53"><a href="simoainfhorizon.html#cb174-53" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
</div>
<p>This implementation can be readily extended to capture the data to files for display in spreadsheets or other plotting software. As part of the plotting process it is useful to display the cumulative sum and cumulative average of the data values.</p>
<p><span class="math display">\[\sum_{i=1}^n W_i \; \text{for} \; n = 1,2,\ldots\]</span></p>
<p><span class="math display">\[\dfrac{1}{n} \sum_{i=1}^n W_i \; \text{for} \; n = 1,2,\ldots\]</span></p>
<div class="figure"><span style="display:block;" id="fig:CumulativeAvg"></span>
<img src="figures2/ch5/ch7fig34.png" alt="Cumulative Average Waiting Time of 1000 Customers" width="80%" height="80%" />
<p class="caption">
Figure 5.10: Cumulative Average Waiting Time of 1000 Customers
</p>
</div>
<p>Figure <a href="simoainfhorizon.html#fig:CumulativeAvg">5.10</a> presents the cumulative average plot
of the first 1000 customers. As seen in the plot, the cumulative average
starts out low and then eventually trends towards 1.2 minutes.</p>
<div class="figure"><span style="display:block;" id="fig:MM1Results1000"></span>
<img src="figures2/ch5/ch7fig33.png" alt="Lindley Equation Results Across 1000 Customers"  />
<p class="caption">
Figure 5.11: Lindley Equation Results Across 1000 Customers
</p>
</div>
<p>The analytical results indicate that the true
long-run expected waiting time in the queue is 1.633 minutes. The
average over the 1000 customers in the simulation is 1.187 minutes. The results in Figure <a href="simoainfhorizon.html#fig:MM1Results1000">5.11</a> indicated that the sample average is
significantly lower than the true expected average. We will explore why this occurs shortly.</p>
<p>The first issue to consider with this data is independence. To do this
you should analyze the 1000 observations in terms of its
autocorrelation.</p>
<div class="figure"><span style="display:block;" id="fig:MM1Autocorelation"></span>
<img src="figures2/ch5/ch7fig35.png" alt="Autocorrelation Plot for Waiting Times"  />
<p class="caption">
Figure 5.12: Autocorrelation Plot for Waiting Times
</p>
</div>
<p>From Figure <a href="simoainfhorizon.html#fig:MM1Autocorelation">5.12</a>, it is readily apparent that the
data has strong positive correlation. The lag-1
correlation for this data is estimated to be about 0.9.
Figure <a href="simoainfhorizon.html#fig:MM1Autocorelation">5.12</a> clearly indicates the strong first
order linear dependence between <span class="math inline">\(W_i\)</span> and <span class="math inline">\(W_{i-1}\)</span>. This positive
dependence implies that if the previous customer waited a long time the
next customer is likely to wait a long time. If the previous customer
had a short wait, then the next customer is likely to have a short wait.
This makes sense with respect to how a queue operates.</p>
<p>Strong positive correlation has serious implications when developing
confidence intervals on the mean customer waiting time because the usual
estimator for the sample variance:</p>
<p><span class="math display">\[S^2(n) = \dfrac{1}{n - 1} \sum_{i=1}^n (X_i - \bar{X})^2\]</span></p>
<p>is a biased estimator for the true population variance when there is
correlation in the observations. This issue will be re-examined when
ways to mitigate these problems are discussed.</p>
<p>The second issue that needs to be discussed is that of the
non-stationary behavior of the data. Non-stationary data indicates some dependence on time. More generally, non-stationary implies that the <span class="math inline">\(W_1, W_2,W_3, \ldots, W_n\)</span> are not
obtained from identical distributions.</p>
<p>Why should the distribution of <span class="math inline">\(W_1\)</span> not be the same as the distribution
of <span class="math inline">\(W_{1000}\)</span>? The first customer is likely to enter the queue with no
previous customers present and thus it is very likely that the first
customer will experience little or no wait (the way <span class="math inline">\(W_0\)</span> was initialize
in this example allows a chance of waiting for the first customer).
However, the <span class="math inline">\(1000^{th}\)</span> customer may face an entirely different
situation. Between the <span class="math inline">\(1^{st}\)</span> and the <span class="math inline">\(1000^{th}\)</span> customer there might
likely be a line formed. In fact from the M/M/1 formula, it is known
that the steady state expected number in the queue is 1.633. Clearly,
the conditions that the <span class="math inline">\(1^{st}\)</span> customer faces are different than the
<span class="math inline">\(1000^{th}\)</span> customer. Thus, the distributions of their waiting times are
likely to be different.</p>
<p>This situation can be better understood by considering a model for the underlying data. A time
series, <span class="math inline">\(X_1,X_2,\ldots,\)</span> is said to be <em>covariance stationary</em> if:</p>
<ul>
<li><p>The mean exists and <span class="math inline">\(\theta = E[X_i]\)</span>, for i = 1,2,<span class="math inline">\(\ldots\)</span>, n</p></li>
<li><p>The variance exists and <span class="math inline">\(Var[X_i] = \sigma^2\)</span> <span class="math inline">\(&gt;\)</span> 0, for i =
1,2,<span class="math inline">\(\ldots\)</span>, n</p></li>
<li><p>The lag-k autocorrelation, <span class="math inline">\(\rho_k = cor(X_i, X_{i+k})\)</span>, is not a
function of <em>i</em>, i.e. the correlation between any two points in the
series does not depend upon where the points are in the series, it
depends only upon the distance between them in the series.</p></li>
</ul>
<p>In the case of the customer waiting times, we can conclude from the
discussion that it is very likely that <span class="math inline">\(\theta \neq E[X_i]\)</span> and
<span class="math inline">\(Var[X_i] \neq \sigma^2\)</span> for <em>each</em> i = 1,2,<span class="math inline">\(\ldots\)</span>, n for the time
series.</p>
<p>Do you think that is it likely that the distributions of <span class="math inline">\(W_{9999}\)</span> and
<span class="math inline">\(W_{10000}\)</span> will be similar? The argument, that the <span class="math inline">\(9999^{th}\)</span> customer
is on average likely to experience similar conditions as the
<span class="math inline">\(10000^{th}\)</span> customer, sure seems reasonable.</p>
<div class="figure"><span style="display:block;" id="fig:MM1MutipleSP"></span>
<img src="figures2/ch5/ch7fig37.png" alt="Multiple Sample Paths of Queueing Simulation" width="70%" height="70%" />
<p class="caption">
Figure 5.13: Multiple Sample Paths of Queueing Simulation
</p>
</div>
<p>Figure <a href="simoainfhorizon.html#fig:MM1MutipleSP">5.13</a> shows 10 different replications of
the cumulative average for a 10000 customer simulation. From the figure, we can see that the cumulative average plots can vary significantly over the 10000 customers with the average tracking above
the true expected value, below the true expected value, and possibly
towards the true expected value. For the case of 10000 customers, you should notice
that the cumulative average starts to approach the expected value of the
steady state mean waiting time in the queue with increasing number of
customers. This is the law of large numbers in action. It appears that
it takes a period of time for the performance measure to <em>warm up</em>
towards the true mean. Determining the warm up time will be the basic
way to mitigate the problem of this non-stationary behavior.</p>
<p>From this discussion, we can conclude that the second basic
statistical assumption of identically distributed data is not valid for
within replication data. From this, we can also conclude that it is
very likely that the data are not normally distributed. In fact, for the
M/M/1 it can be shown that the steady state distribution for the waiting
time in the queue is not a normal distribution. Thus, all three of the
basic statistical assumptions are violated for the within replication
data of this example. This problem needs to be addressed in order to
properly analyze infinite horizon simulations.</p>
<p>There are two basic methods for performing infinite horizon simulations.
The first is to perform multiple replications. This approach addresses
independence and normality in a similar fashion as the finite horizon
case, but special procedures will be needed to address the
non-stationary aspects of the data. The second basic approach is to work
with one very long replication. Both of these methods depend on first
addressing the problem of the non-stationary aspects of the data. The
next section looks at ways to mitigate the non-stationary aspect of
within-replication data for infinite horizon simulations.</p>
<div id="simoainfhorizoninitialbias" class="section level3 hasAnchor" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Assessing the Effect of Initial Conditions<a href="simoainfhorizon.html#simoainfhorizoninitialbias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider the output stochastic process <span class="math inline">\(X_i\)</span> of the simulation. Let
<span class="math inline">\(F_i(x|I)\)</span> be the conditional cumulative distribution function of <span class="math inline">\(X_i\)</span>
where <span class="math inline">\(I\)</span> represents the initial conditions used to start the simulation
at time 0. If <span class="math inline">\(F_i(x|I)  \rightarrow F(x)\)</span> when <span class="math inline">\(i \rightarrow \infty\)</span>,
for all initial conditions <span class="math inline">\(I\)</span>, then <span class="math inline">\(F(x)\)</span> is called the steady state
distribution of the output process. (Law 2007).</p>
<p>In infinite horizon simulations, estimating parameters of the steady
state distribution, <span class="math inline">\(F(x)\)</span>, such as the steady state mean, <span class="math inline">\(\theta\)</span>, is
often the key objective. The fundamental difficulty associated with
estimating steady state performance is that unless the system is
initialized using the steady state distribution (which is not known),
there is no way to directly observe the steady state distribution.</p>
<p>It is true that if the steady state distribution exists and you run the
simulation long enough the estimators will tend to converge to the
desired quantities. Thus, within the infinite horizon simulation
context, you must decide on how long to run the simulations and how to
handle the effect of the <em>initial conditions</em> on the estimates of
performance. The initial conditions of a simulation represent the state
of the system when the simulation is started. For example, in simulating
the pharmacy system, the simulation was started with no customers in
service or in the line. This is referred to as <em>empty and idle</em>. The
initial conditions of the simulation affect the rate of convergence of
estimators of steady state performance.</p>
<p>Because the distributions <span class="math inline">\(F_i(x|I)\)</span> at the start of the replication
tend to depend more heavily upon the initial conditions, estimators of
steady state performance such as the sample average, <span class="math inline">\(\bar{X}\)</span>, will
tend to be <em>biased</em>. A point estimator, <span class="math inline">\(\hat{\theta}\)</span>, is an <em>unbiased</em>
estimator of the parameter of interest, <span class="math inline">\(\theta\)</span>, if
<span class="math inline">\(E[\hat{\theta}] = \theta\)</span>. That is, if the expected value of the
sampling distribution is equal to the parameter of interest then the
estimator is said to be unbiased. If the estimator is biased then the
difference, <span class="math inline">\(E[\hat{\theta}] - \theta\)</span>, is called the bias of,
<span class="math inline">\(\hat{\theta}\)</span>, the estimator.</p>
<p>Note that any individual difference between the true parameter,
<span class="math inline">\(\theta\)</span>, and a particular observation, <span class="math inline">\(X_i\)</span>, is called error,
<span class="math inline">\(\epsilon_i = X_i -\theta\)</span>. If the expected value of the errors is not
zero, then there is bias. A particular observation is not biased. Bias
is a property of the estimator. Bias is analogous to being consistently
off target when shooting at a bulls-eye. It is as if the sights on your
gun are crooked. In order to estimate the bias of an estimator, you must
have multiple observations of the estimator. Suppose that you are
estimating the mean waiting time in the queue as per the previous
example and that the estimator is based on the first 20 customers. That
is, the estimator is:</p>
<p><span class="math display">\[\bar{W}_r = \dfrac{1}{20}\sum_{i=1}^{20} W_{ir}\]</span></p>
<p>and there are <span class="math inline">\(r = 1, 2, \ldots 10\)</span> replications.
The following table shows the sample average waiting time for the
first 20 customers for 10 different replications.</p>
<table>
<caption>Ten Replications of 20 Customers</caption>
<thead>
<tr class="header">
<th align="center">r</th>
<th align="center"><span class="math inline">\(\bar{W}_r\)</span></th>
<th align="center"><span class="math inline">\(B_r = \bar{W}_r - W_q\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">0.194114</td>
<td align="center">-1.43922</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">0.514809</td>
<td align="center">-1.11852</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">1.127332</td>
<td align="center">-0.506</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">0.390004</td>
<td align="center">-1.24333</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">1.05056</td>
<td align="center">-0.58277</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">1.604883</td>
<td align="center">-0.02845</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">0.445822</td>
<td align="center">-1.18751</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">0.610001</td>
<td align="center">-1.02333</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">0.52462</td>
<td align="center">-1.10871</td>
</tr>
<tr class="even">
<td align="center"> 10</td>
<td align="center">0.335311</td>
<td align="center">-1.29802</td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center"><span class="math inline">\(\bar{\bar{W}}\)</span> = 0.6797</td>
<td align="center"><span class="math inline">\(\bar{B}\)</span> = -0.9536</td>
</tr>
</tbody>
</table>
<p>In the table, <span class="math inline">\(B_r\)</span> is an estimate of the bias for the <span class="math inline">\(r^{th}\)</span> replication, where
<span class="math inline">\(W_q = 1.6\bar{33}\)</span>. Upon averaging across the replications, it can be
seen that <span class="math inline">\(\bar{B}= -0.9536\)</span>, which indicates that the estimator based
only on the first 20 customers has significant negative bias, i.e. on
average it is less than the target value.</p>
<p>This is the so called <em>initialization bias problem</em> in steady state
simulation. Unless the initial conditions of the simulation can be
generated according to <span class="math inline">\(F(x)\)</span>, which is not known, you must focus on
methods that detect and/or mitigate the presence of initialization bias.</p>
<p>One strategy for initialization bias mitigation is to find an index,
<span class="math inline">\(d\)</span>, for the output process, <span class="math inline">\({X_i}\)</span>, so that <span class="math inline">\({X_i; i = d + 1, \ldots}\)</span>
will have substantially similar distributional properties as the steady
state distribution <span class="math inline">\(F(x)\)</span>. This is called the simulation warm up
problem, where <span class="math inline">\(d\)</span> is called the warm up point, and <span class="math inline">\({i = 1,\ldots,d}\)</span>
is called the warm up period for the simulation. Then, the estimators of
steady state performance are based only on <span class="math inline">\({X_i; i = d + 1, \ldots}\)</span>,
which represent the data after deleting the warm up period.</p>
<p>For example, when estimating the steady state mean waiting time for each
replication <span class="math inline">\(r\)</span> the estimator would be:</p>
<p><span class="math display">\[\bar{W_r} = \dfrac{1}{n-d}\sum_{i=d+1}^{n} W_{ir}\]</span></p>
<p>For time-based performance measures, such as the average number in
queue, a time <span class="math inline">\(T_w\)</span> can be determined past which the data collection
process can begin. Estimators of time-persistent performance such as the
sample average are computed as:</p>
<p><span class="math display">\[\bar{Y}_r = \dfrac{1}{T_e - T_w}\int_{T_w}^{T_e} Y_r(t) dt\]</span></p>
<div class="figure"><span style="display:block;" id="fig:WarmUpPeriod"></span>
<img src="figures2/ch5/ch7fig38.png" alt="The Concept of the Warm Up Period" width="60%" height="60%" />
<p class="caption">
Figure 5.14: The Concept of the Warm Up Period
</p>
</div>
<p>Figure <a href="simoainfhorizon.html#fig:WarmUpPeriod">5.14</a> shows the concept of a warm up period for a
simulation replication. When you perform a simulation, you can easily
specify a time-based warm up period using the setLengthOfWarmUp() method
of the Simulation class. In fact, even for observation based data, it
will be more convenient to specify the warm up period in terms of time.
A given value of <span class="math inline">\(T_w\)</span> implies a particular value of <span class="math inline">\(d\)</span> and vice a
versa. Specifying a warm up period, causes an event to be scheduled for
time <span class="math inline">\(T_w\)</span>. At that time, all the accumulated statistical counters are
cleared so that the net effect is that statistics are only collected
over the period from <span class="math inline">\(T_w\)</span> to <span class="math inline">\(T_e\)</span>. The problem then becomes that of
finding an appropriate warm up period.</p>
<p>Before proceeding with how to assess the length of the warm up period,
the concept of steady state needs to be further examined. This subtle
concept is often misunderstood or misrepresented. Often you will hear
the phrase: <em>The system has reached steady state</em>. The correct
interpretation of this phrase is that the distribution of the desired
performance measure has reached a point where it is sufficiently similar
to the desired steady state distribution. Steady state is a concept
involving the performance measures generated by the system as time goes
to infinity. However, sometimes this phrase is interpreted incorrectly
to mean that the system <em>itself</em> has reached steady state. Let me state
emphatically that the system <em>never</em> reaches steady state. If the system
itself reached steady state, then by implication it would never change
with respect to time. It should be clear that the system continues to
evolve with respect to time; otherwise, it would be a very boring
system! Thus, it is incorrect to indicate that the system has reached
steady state. Because of this, do not to use the phrase: <em>The system has
reached steady state</em>.</p>
<p>Understanding this subtle issue raises an interesting implication
concerning the notion of deleting data to remove the initialization
bias. Suppose that the state of the system at the end of the warm up
period, <span class="math inline">\(T_w\)</span>, is exactly the same as at <span class="math inline">\(T = 0\)</span>. For example, it is
certainly possible that at time <span class="math inline">\(T_w\)</span> for a particular replication that
the system was empty and idle. Since the state of the system at <span class="math inline">\(T_w\)</span> is
the same as that of the initial conditions, there will be no effect of
deleting the warm up period for this replication. In fact there will be
a negative effect, in the sense that data will have been thrown away for
no reason. Deletion methods are predicated on the likelihood that the
state of the system seen at <span class="math inline">\(T_w\)</span> is more representative of steady state
conditions. At the end of the warm up period, the system can be in <em>any
of the possible</em> states of the system. Some states will be more likely
than others. If multiple replications are made, then at <span class="math inline">\(T_w\)</span> each
replication will experience a different set of conditions at <span class="math inline">\(T_w\)</span>. Let
<span class="math inline">\(I_{T_w}^r\)</span> be the initial conditions (state) at time <span class="math inline">\(T_w\)</span> on
replication <span class="math inline">\(r\)</span>. By setting a warm up period and performing multiple
replications, you are in essence sampling from the distribution
governing the state of the system at time <span class="math inline">\(T_w\)</span>. If <span class="math inline">\(T_w\)</span> is long
enough, then on average across the replications, you are more likely to
start collecting data when the system is in states that are more
representative over the long term (rather than just empty and idle).</p>
<p>Many methods and rules have been proposed to determine the warm up
period. The interested reader is referred to <span class="citation">(<a href="#ref-wilson1978a">Wilson and Pritsker 1978</a>)</span>, <span class="citation">Lada, Wilson, and Steiger (<a href="#ref-lada2003a">2003</a>)</span>,
<span class="citation">(<a href="#ref-Litton:2002aa">Litton and Harmonosky 2002</a>)</span>, <span class="citation">White, Cobb, and Spratt (<a href="#ref-white2000a">2000</a>)</span>, <span class="citation">Cash et al. (<a href="#ref-cash1992">1992</a>)</span>, and <span class="citation">(<a href="#ref-rossetti1995control">Rossetti and Delaney 1995</a>)</span> for
an overview of such methods. This discussion will concentrate on the
visual method proposed in <span class="citation">(<a href="#ref-welch1983a">Welch 1983</a>)</span>.</p>
<p>The basic idea behind Welch’s graphical procedure is simple:</p>
<ul>
<li><p>Make <span class="math inline">\(R\)</span> replications. Typically, <span class="math inline">\(R \geq 5\)</span> is recommended.</p></li>
<li><p>Let <span class="math inline">\(Y_{rj}\)</span> be the <span class="math inline">\(j^{th}\)</span> observation on replication <span class="math inline">\(r\)</span> for
<span class="math inline">\(j = 1,2,\cdots,m_r\)</span> where <span class="math inline">\(m_r\)</span> is the number of observations in
the <span class="math inline">\(r^{th}\)</span> replication, and <span class="math inline">\(r = 1,2,\cdots,n\)</span>,</p></li>
<li><p>Compute the averages across the replications for each
<span class="math inline">\(j = 1, 2, \ldots, m\)</span>, where <span class="math inline">\(m = min(m_r)\)</span> for <span class="math inline">\(r = 1,2,\cdots,n\)</span>.</p>
<p><span class="math display">\[\bar{Y}_{\cdot j} = \dfrac{1}{n}\sum_{r=1}^n Y_{rj}\]</span></p></li>
<li><p>Plot, <span class="math inline">\(\bar{Y}_{\cdot j}\)</span> for each <span class="math inline">\(j = 1, 2, \ldots, m\)</span></p></li>
<li><p>Apply smoothing techniques to <span class="math inline">\(\bar{Y}_{\cdot j}\)</span> for
<span class="math inline">\(j = 1, 2, \ldots, m\)</span></p></li>
<li><p>Visually assess where the plot start to converge</p></li>
</ul>
<p>Let’s apply the Welch’s procedure to the replications generated from the
Lindley equation simulation. Using the 10 replications stored in a spreadsheet
we can compute the average across each replication for each
customer.</p>
<div class="figure"><span style="display:block;" id="fig:WelchPlot"></span>
<img src="figures2/ch5/ch7fig39.png" alt="Computing the Averages for the Welch Plot"  />
<p class="caption">
Figure 5.15: Computing the Averages for the Welch Plot
</p>
</div>
<p>In Figure <a href="simoainfhorizon.html#fig:WelchPlot">5.15</a>, cell B2 represents the average across the
10 replications for the <span class="math inline">\(1^{st}\)</span> customer. Column D represents the
cumulative average associated with column B.</p>
<div class="figure"><span style="display:block;" id="fig:CumAvgline"></span>
<img src="figures2/ch5/ch7fig40.png" alt="Welch Plot with Superimposed Cumulative Average Line"  />
<p class="caption">
Figure 5.16: Welch Plot with Superimposed Cumulative Average Line
</p>
</div>
<p>Figure <a href="simoainfhorizon.html#fig:CumAvgline">5.16</a> is the plot of the cumulative average
(column D) superimposed on the averages across replications (column B).
The cumulative average is one method of smoothing the data. From the
plot, you can infer that after about customer 3000 the cumulative
average has started to converge. Thus, from this analysis you might
infer that <span class="math inline">\(d = 3000\)</span>.</p>
<p>When you perform an infinite horizon simulation by specifying a warm up
period and making multiple replications, you are using the method of
<em>replication-deletion.</em> If the method of replication-deletion with
<span class="math inline">\(d = 3000\)</span> is used for the current example, a slight reduction in the
bias can be achieved as indicated in the following table.</p>
<table>
<caption>Replication-Deletion Results, d = 3000</caption>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(r\)</span></th>
<th align="center"><span class="math inline">\(\bar{W}_r\)</span> <span class="math inline">\((d = 0)\)</span></th>
<th align="center"><span class="math inline">\(\bar{W}_r(d = 3000)\)</span></th>
<th align="center"><span class="math inline">\(B_r(d = 0)\)</span></th>
<th align="center"><span class="math inline">\(B_r(d = 3000)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1.594843</td>
<td align="center">1.592421</td>
<td align="center">-0.03849</td>
<td align="center">-0.04091</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">1.452237</td>
<td align="center">1.447396</td>
<td align="center">-0.1811</td>
<td align="center">-0.18594</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">1.657355</td>
<td align="center">1.768249</td>
<td align="center">0.024022</td>
<td align="center">0.134915</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">1.503747</td>
<td align="center">1.443251</td>
<td align="center">-0.12959</td>
<td align="center">-0.19008</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">1.606765</td>
<td align="center">1.731306</td>
<td align="center">-0.02657</td>
<td align="center">0.097973</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">1.464981</td>
<td align="center">1.559769</td>
<td align="center">-0.16835</td>
<td align="center">-0.07356</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">1.621275</td>
<td align="center">1.75917</td>
<td align="center">-0.01206</td>
<td align="center">0.125837</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">1.600563</td>
<td align="center">1.67868</td>
<td align="center">-0.03277</td>
<td align="center">0.045347</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">1.400995</td>
<td align="center">1.450852</td>
<td align="center">-0.23234</td>
<td align="center">-0.18248</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">1.833414</td>
<td align="center">1.604855</td>
<td align="center">0.20008</td>
<td align="center">-0.02848</td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center"><span class="math inline">\(\bar{\bar{W}}\)</span> = 1.573617</td>
<td align="center"><span class="math inline">\(\bar{\bar{W}}\)</span> = 1.603595</td>
<td align="center"><span class="math inline">\(\bar{B}\)</span> = -0.05972</td>
<td align="center"><span class="math inline">\(\bar{B}\)</span> = -0.02974</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">s = 0.1248</td>
<td align="center">s = 0.1286</td>
<td align="center">s = 0.1248</td>
<td align="center">s = 0.1286</td>
</tr>
<tr class="odd">
<td align="center">95% LL</td>
<td align="center">1.4843</td>
<td align="center">1.5116</td>
<td align="center">-0.149023</td>
<td align="center">-0.121704</td>
</tr>
<tr class="even">
<td align="center">95% UL</td>
<td align="center">1.6629</td>
<td align="center">1.6959</td>
<td align="center">-0.029590</td>
<td align="center">0.062228</td>
</tr>
</tbody>
</table>
<p>While not definitive for this simple example, the results suggest that
deleting the warm up period helps to reduce initialization bias. This
model’s warm up period will be further analyzed using additional tools
available in the next section.</p>
<p>In performing the method of replication-deletion, there is a fundamental
trade-off that occurs. Because data is deleted, the variability of the
estimator will tend to increase while the bias will tend to decrease.
This is a trade-off between a reduction in bias and an increase in
variance. That is, accuracy is being traded off against precision when
deleting the warm up period. In addition to this trade off, data from
each replication is also being thrown away. This takes computational
time that could be expended more effectively on collecting usable data.
Another disadvantage of performing replication-deletion is that the
techniques for assessing the warm up period (especially graphical) may
require significant data storage. The Welch plotting procedure requires
the saving of data points for post processing after the simulation run.
In addition, significant time by the analyst may be required to perform
the technique and the technique is subjective.</p>
<p>When a simulation has many performance measures, you may have to perform
a warm up period analysis for every performance measure. This is
particularly important, since in general, the performance measures of
the same model may converge towards steady state conditions at different
rates. In this case, the length of the warm up period must be
sufficiently long enough to cover all the performance measures. Finally,
replication-deletion may simply compound the bias problem if the warm up
period is insufficient relative to the length of the simulation. If you
have not specified a long enough warm up period, you are potentially
compounding the problem for <span class="math inline">\(n\)</span> replications.</p>
<p>Despite all these disadvantages, replication-deletion is very much used
in practice because of the simplicity of the analysis after the warm up
period has been determined. Once you are satisfied that you have a good
warm up period, the analysis of the results is the same as that of
finite horizon simulations. Replication-deletion also facilitates the
use of experimental design techniques that rely on replicating design
points.</p>
<p>The next section illustrates how to perform the method of
replication-deletion on this simple M/M/1 model.</p>
</div>
<div id="simoainfhorizonrepDeletion" class="section level3 hasAnchor" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Performing the Method of Replication-Deletion<a href="simoainfhorizon.html#simoainfhorizonrepDeletion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The first step in performing the method of replication-deletion is to
determine the length of the warm up period. This example illustrates how
to:</p>
<ul>
<li><p>Save the values from observation and time-based data to files for
post processing</p></li>
<li><p>Make Welch plots based on the saved data</p></li>
<li><p>Setup and run the multiple replications</p></li>
<li><p>Interpret the results</p></li>
</ul>
<p>When performing a warm-up period analysis, the first decision to make is
the length of each replication. In general, there is very little
guidance that can be offered other than to try different run lengths and
check for the sensitivity of your results. Within the context of
queueing simulations, the work by <span class="citation">(<a href="#ref-whitt1989planning">Whitt 1989</a>)</span> offers some ideas
on specifying the run length, but these results are difficult to
translate to general simulations.</p>
<p>Since the purpose here is to determine the length of the warm up period,
then the run length should be bigger than what you suspect the warm up
period to be. In this analysis, it is better to be conservative. You
should make the run length as long as possible given your time and data
storage constraints. <span class="citation">Banks et al. (<a href="#ref-banks2005discreteevent">2005</a>)</span> offer the rule of thumb
that the run length should be at least 10 times the amount of data
deleted. That is, <span class="math inline">\(n \geq 10d\)</span> or in terms of time, <span class="math inline">\(T_e \geq 10T_w\)</span>. Of
course, this is a “catch 22” situation because you need to specify <span class="math inline">\(n\)</span>
or equivalently <span class="math inline">\(T_e\)</span> in order to assess <span class="math inline">\(T_w\)</span>. Setting <span class="math inline">\(T_e\)</span> very large
is recommended when doing a preliminary assessment of <span class="math inline">\(T_w\)</span>. Then, you
can use the rule of thumb of 10 times the amount of data deleted when
doing a more serious assessment of <span class="math inline">\(T_w\)</span> (e.g. using Welch plots etc.)</p>
<p>A preliminary assessment of the current model has already been performed
based on the previously described spreadsheet simulation. That
assessment suggested a deletion point of at least <span class="math inline">\(d = 3000\)</span> customers.
This can be used as a starting point in the current effort. Now, <span class="math inline">\(T_w\)</span>
needs to be determined based on <span class="math inline">\(d\)</span>. The value of <span class="math inline">\(d\)</span> represents the
customer number for the end of the warm up period. To get <span class="math inline">\(T_w\)</span>, you
need to answer the question: How long (on average) will it take for the
simulation to generate <span class="math inline">\(d\)</span> observations. In this model, the mean number
of arrivals is 1 customer per minute. Thus, the initial <span class="math inline">\(T_w\)</span> is</p>
<p><span class="math display">\[3000 \; \text{customers} \times \frac{\text{minute}}{\text{1 customer}} \; = 3000 \; \text{minutes}\]</span></p>
<p>and therefore the initial <span class="math inline">\(T_e\)</span> should be 30,000 minutes. That is, you
should specify 30,000 minutes for the replication length.</p>
<div id="simoainfhorizonwarmup" class="section level4 hasAnchor" number="5.6.2.1">
<h4><span class="header-section-number">5.6.2.1</span> Determining the Warm Up Period<a href="simoainfhorizon.html#simoainfhorizonwarmup" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To perform a more rigorous analysis of the warm up period, we need to
run the simulation for multiple replications and capture the data
necessary to produce Welch plots for the performance measures of
interest. Within the KSL, this can be accomplished by using the classes
within the <code>ksl.observers.welch</code> package. There are two classes
of note:</p>
<dl>
<dt><code>WelchDataFileCollector</code></dt>
<dd>
<p>This class captures data associated with a Response within
the simulation model. Every observation from every replication is
written to a binary data file. In addition, a text based data file
is created that contains the meta data associated with the data
collection process. The meta data file records the number of
replications, the number of observations for each replication, and
the time between observations for each replication.</p>
</dd>
<dt><code>WelchDataFileAnalyzer</code></dt>
<dd>
<p>This class uses the files produced by the <code>WelchDataFileCollector</code> to
produces the Welch data. That is, the average across each row of
observations and the cumulative average over the observations. This
class produces files from which the plots can be made.</p>
</dd>
</dl>
<p>A warm up period analysis is associated with a particular response. The
goal is to determine the number of observations of the response to
delete at the beginning of the simulation. We can collect the relevant
data by attaching an observer to the response variable.</p>
<div class="example">
<p><span id="exm:ch5ex4" class="example"><strong>Example 5.4  (Welch Plot Analysis) </strong></span>This code illustrates how to capture Welch plot data and to show the Welch
plot within a browser window.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode kt"><code class="sourceCode kotlin"><span id="cb175-1"><a href="simoainfhorizon.html#cb175-1" tabindex="-1"></a><span class="kw">fun</span> <span class="fu">main</span><span class="op">(){</span></span>
<span id="cb175-2"><a href="simoainfhorizon.html#cb175-2" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">model</span> <span class="op">=</span> Model<span class="op">(</span><span class="st">&quot;Drive Through Pharmacy&quot;</span><span class="op">)</span></span>
<span id="cb175-3"><a href="simoainfhorizon.html#cb175-3" tabindex="-1"></a>    <span class="co">// add DriveThroughPharmacy to the main model</span></span>
<span id="cb175-4"><a href="simoainfhorizon.html#cb175-4" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">dtp</span> <span class="op">=</span> DriveThroughPharmacyWithQ<span class="op">(</span>model<span class="op">,</span> <span class="dv">1</span><span class="op">)</span></span>
<span id="cb175-5"><a href="simoainfhorizon.html#cb175-5" tabindex="-1"></a>    dtp<span class="op">.</span>arrivalRV<span class="op">.</span>initialRandomSource <span class="op">=</span> ExponentialRV<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="dv">1</span><span class="op">)</span></span>
<span id="cb175-6"><a href="simoainfhorizon.html#cb175-6" tabindex="-1"></a>    dtp<span class="op">.</span>serviceRV<span class="op">.</span>initialRandomSource <span class="op">=</span> ExponentialRV<span class="op">(</span><span class="fl">0.7</span><span class="op">,</span> <span class="dv">2</span><span class="op">)</span></span>
<span id="cb175-7"><a href="simoainfhorizon.html#cb175-7" tabindex="-1"></a></span>
<span id="cb175-8"><a href="simoainfhorizon.html#cb175-8" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">rvWelch</span> <span class="op">=</span> WelchFileObserver<span class="op">(</span>dtp<span class="op">.</span>systemTime<span class="op">,</span> <span class="fl">1.0</span><span class="op">)</span></span>
<span id="cb175-9"><a href="simoainfhorizon.html#cb175-9" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">twWelch</span> <span class="op">=</span> WelchFileObserver<span class="op">(</span>dtp<span class="op">.</span>numInSystem<span class="op">,</span> <span class="fl">10.0</span><span class="op">)</span></span>
<span id="cb175-10"><a href="simoainfhorizon.html#cb175-10" tabindex="-1"></a>    model<span class="op">.</span>numberOfReplications <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb175-11"><a href="simoainfhorizon.html#cb175-11" tabindex="-1"></a>    model<span class="op">.</span>lengthOfReplication <span class="op">=</span> <span class="fl">50000.0</span></span>
<span id="cb175-12"><a href="simoainfhorizon.html#cb175-12" tabindex="-1"></a>    model<span class="op">.</span>simulate<span class="op">()</span></span>
<span id="cb175-13"><a href="simoainfhorizon.html#cb175-13" tabindex="-1"></a>    model<span class="op">.</span>print<span class="op">()</span></span>
<span id="cb175-14"><a href="simoainfhorizon.html#cb175-14" tabindex="-1"></a>    println<span class="op">(</span>rvWelch<span class="op">)</span></span>
<span id="cb175-15"><a href="simoainfhorizon.html#cb175-15" tabindex="-1"></a>    println<span class="op">(</span>twWelch<span class="op">)</span></span>
<span id="cb175-16"><a href="simoainfhorizon.html#cb175-16" tabindex="-1"></a></span>
<span id="cb175-17"><a href="simoainfhorizon.html#cb175-17" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">rvFileAnalyzer</span> <span class="op">=</span> rvWelch<span class="op">.</span>createWelchDataFileAnalyzer<span class="op">()</span></span>
<span id="cb175-18"><a href="simoainfhorizon.html#cb175-18" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">twFileAnalyzer</span> <span class="op">=</span> twWelch<span class="op">.</span>createWelchDataFileAnalyzer<span class="op">()</span></span>
<span id="cb175-19"><a href="simoainfhorizon.html#cb175-19" tabindex="-1"></a></span>
<span id="cb175-20"><a href="simoainfhorizon.html#cb175-20" tabindex="-1"></a>    rvFileAnalyzer<span class="op">.</span>createCSVWelchPlotDataFile<span class="op">()</span></span>
<span id="cb175-21"><a href="simoainfhorizon.html#cb175-21" tabindex="-1"></a>    twFileAnalyzer<span class="op">.</span>createCSVWelchPlotDataFile<span class="op">()</span></span>
<span id="cb175-22"><a href="simoainfhorizon.html#cb175-22" tabindex="-1"></a>    </span>
<span id="cb175-23"><a href="simoainfhorizon.html#cb175-23" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">wp</span> <span class="op">=</span> WelchPlot<span class="op">(</span>analyzer <span class="op">=</span> rvFileAnalyzer<span class="op">)</span></span>
<span id="cb175-24"><a href="simoainfhorizon.html#cb175-24" tabindex="-1"></a>    wp<span class="op">.</span>defaultPlotDir <span class="op">=</span> model<span class="op">.</span>outputDirectory<span class="op">.</span>plotDir</span>
<span id="cb175-25"><a href="simoainfhorizon.html#cb175-25" tabindex="-1"></a>    wp<span class="op">.</span>showInBrowser<span class="op">()</span></span>
<span id="cb175-26"><a href="simoainfhorizon.html#cb175-26" tabindex="-1"></a>    wp<span class="op">.</span>saveToFile<span class="op">(</span><span class="st">&quot;SystemTimeWelchPlot&quot;</span><span class="op">)</span></span>
<span id="cb175-27"><a href="simoainfhorizon.html#cb175-27" tabindex="-1"></a></span>
<span id="cb175-28"><a href="simoainfhorizon.html#cb175-28" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
</div>
<p>In the code, we create two instances of <code>WelchFileObserver</code> one for the system time (<code>systemTime</code>) and one for the number in the system (<code>numInSyste</code>) both referenced from the exposed properties of the drive through pharmacy class. Since the number in the system is a time-persistent variable, it is discretized based on intervals of 10 time units. The concept of discretizing the time-persistent data is illustrated in Figure <a href="simoainfhorizon.html#fig:DiscretizeTBD">5.18</a>. The <code>WelchFileObserver</code> instances are used to create <code>WelchDataFileAnalyzer</code> instances, which are used to make the data for plotting. You can use any plotting program that you want to display the plot.</p>
<div class="figure"><span style="display:block;" id="fig:WelchSysTimePlot"></span>
<img src="05-Chapter5_files/figure-html/WelchSysTimePlot-1.svg" alt="Welch Plot for System Time Analysis" width="672" />
<p class="caption">
Figure 5.17: Welch Plot for System Time Analysis
</p>
</div>
<p>Figure <a href="simoainfhorizon.html#fig:WelchSysTimePlot">5.17</a> illustrates the plot of the
data. From this plot, we can estimate the number of observations
to delete as approximately 20000.</p>
<p>Time-persistent observations are saved within a file from within the
model such that the time of the observation and the value of the state
variable at the time of change are recorded. Thus, the observations are
not equally spaced in time. In order to perform the Welch plot analysis,
we need to cut the data into discrete equally spaced intervals of time.</p>
<div class="figure"><span style="display:block;" id="fig:DiscretizeTBD"></span>
<img src="figures/ch7/ch7fig48.png" alt="Discretizing Time-Persistent Data" width="70%" height="70%" />
<p class="caption">
Figure 5.18: Discretizing Time-Persistent Data
</p>
</div>
<p>Figure <a href="simoainfhorizon.html#fig:DiscretizeTBD">5.18</a> illustrates the concept of discretizing time-persistent data. Suppose that you divide <span class="math inline">\(T_e\)</span> into <span class="math inline">\(k\)</span> intervals of size <span class="math inline">\(\Delta t\)</span>, so that <span class="math inline">\(T_e = k \times \Delta t\)</span>. The
time average over the <span class="math inline">\(j^{th}\)</span> interval is given by:</p>
<p><span class="math display">\[\bar{Y}_{rj} = \dfrac{1}{\Delta t} \int_{j-1) \Delta t}^{j \Delta t} Y_r(t)dt\]</span></p>
<p>Thus, the overall time average can be computed from the time average
associated with each interval:</p>
<p><span class="math display">\[\begin{aligned}
\bar{Y}_{r} &amp; = \dfrac{\int_0^{T_e} Y_r (t)dt}{T_e} =\dfrac{\int_0^{T_e} Y_r (t)dt}{k \Delta t} \\
&amp; = \dfrac{\sum_{j=1}^{k}\int_{(j-1) \Delta t}^{j \Delta t} Y_r (t)dt}{k \Delta t} = \dfrac{\sum_{j=1}^{k} \bar{Y}_{rj}}{k}\end{aligned}\]</span></p>
<p>Each of the <span class="math inline">\(\bar{Y}_{rj}\)</span> are computed over intervals of time that are
equally spaced and can be treated as if they are observation (tally)
based data.</p>
<p>The computation of the <span class="math inline">\(\bar{Y}_{rj}\)</span> for time-persistent data can be
achieved by using the <code>WelchDataFileCollectorclass</code> and specifying a
discretization interval. Since the number in queue data is
time-persistent, time based batches are selected, and the batch size is
specified in terms of time. In this case, the data is being batched
based on a time interval of 10 minutes. This produces a file which contains the <span class="math inline">\(\bar{Y}_{rj}\)</span> as observations. This file can then be analyzed as previously illustrated.</p>
<div class="figure"><span style="display:block;" id="fig:WPDiscretizeTBD"></span>
<img src="05-Chapter5_files/figure-html/WPDiscretizeTBD-1.svg" alt="Welch Plot of Time-Persistent Number in System Data" width="672" />
<p class="caption">
Figure 5.19: Welch Plot of Time-Persistent Number in System Data
</p>
</div>
<p>The resulting plot is show in Figure <a href="simoainfhorizon.html#fig:WPDiscretizeTBD">5.19</a>. This plot is sparser than the previous
plot because each observation represents the average of 10 minutes.
There are 5000 observations. From the plot, we can conclude that after
observation 2000, we see a steady convergence. The 1000th observation
represents 20000 time units (minutes) because every observation represents 10 time units.</p>
<p>Once you have performed the warm up analysis, you still need to use your
simulation model to estimate system performance. Because the process of
analyzing the warm up period involves saving the data you could use the
already saved data to estimate your system performance after truncating
the initial portion of the data from the data sets. If re-running the
simulation is relatively inexpensive, then you can simply set the warm
up period via the Simulation class and re-run the model. Following the
rule of thumb that the length of the run should be at least 10 times the
warm up period, the simulation was re-run with the settings (30
replications, 20000 minute warm up period, 200,000 minute replication
length). The results shown in the following table indicate that there does not appear to be
any significant bias with these replication settings.</p>
<table>
<caption>Across Replication Statistics for Drive Through Pharmacy</caption>
<thead>
<tr class="header">
<th align="center">Name</th>
<th align="center">Count</th>
<th align="center">Average</th>
<th align="center">Half-Width</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">NumBusy</td>
<td align="center">30.0</td>
<td align="center">.7001</td>
<td align="center">.0008</td>
</tr>
<tr class="even">
<td align="center"># in System</td>
<td align="center">30.0</td>
<td align="center">2.3402</td>
<td align="center">.0103</td>
</tr>
<tr class="odd">
<td align="center">System Time</td>
<td align="center">30.0</td>
<td align="center">2.3389</td>
<td align="center">.01</td>
</tr>
<tr class="even">
<td align="center">PharmacyQ:NumInQ</td>
<td align="center">30.0</td>
<td align="center">1.6401</td>
<td align="center">.0098</td>
</tr>
<tr class="odd">
<td align="center">PharmacyQ:TimeInQ</td>
<td align="center">30.0</td>
<td align="center">1.6392</td>
<td align="center">.0097</td>
</tr>
<tr class="even">
<td align="center">SysTime &gt; 4.0 minutes</td>
<td align="center">30.0</td>
<td align="center">.1806</td>
<td align="center">.0013</td>
</tr>
<tr class="odd">
<td align="center">Num Served</td>
<td align="center">30.0</td>
<td align="center">180104.9667</td>
<td align="center">145.7244</td>
</tr>
</tbody>
</table>
<p>The true waiting time in the queue is <span class="math inline">\(1.6\bar{33}\)</span> and it is clear that
the 95% confidence interval contains this value.</p>
<p>The process described here for determining the warm up period for steady
state simulation is tedious and time consuming. Research into automating
this process is an active area of investigation. The work
by <span class="citation">(<a href="#ref-robinson2005automated">Robinson 2005</a>)</span> and <span class="citation">Rossetti and Li (<a href="#ref-Rossetti2005aa">2005</a>)</span> holds some promise in
this regard; however, there remains the need to integrate these methods
into computer simulation software. Even though determining the warm up
period is tedious, some consideration of the warm up period should be
done for infinite horizon simulations.</p>
<p>Once the warm up period has been found, you can set the warm up period
using the <code>Model</code> class. Then, you can use the method of
replication-deletion to perform your simulation experiments. Thus, all
the discussion previously presented on the analysis of finite horizon
simulations can be applied.</p>
<p>When determining the number of replications, you can apply the fixed
sample size procedure after performing a pilot run. If the analysis
indicates that you need to make more runs to meet your confidence
interval half-width you have two alternatives: 1) increase the number of
replications or 2) keep the same number of replications but increase the
length of each replication. If <span class="math inline">\(n_0\)</span> was the initial number of
replications and <span class="math inline">\(n\)</span> is the number of replications recommended by the
sample size determination procedure, then you can instead set <span class="math inline">\(T_e\)</span>
equal to <span class="math inline">\((n/n_0)T_e\)</span> and run <span class="math inline">\(n_0\)</span> replications. Thus, you will still
have approximately the same amount of data collected over your
replications, but the longer run length may reduce the effect of
initialization bias.</p>
<p>As previously mentioned, the method of replication-deletion causes each
replication to delete the initial portion of the run. As an alternative,
you can make one long run and delete the initial portion only once. When
analyzing an infinite horizon simulation based on one long replication,
a method is needed to address the correlation present in the within
replication data. The method of batch means is often used in this case
and has been automated in within the KSL. The next section discusses the
statistical basis for the batch means method and addresses some of the
practical issues of using it within the KSL.</p>
</div>
</div>
<div id="simoainfhorizonbatchmeans" class="section level3 hasAnchor" number="5.6.3">
<h3><span class="header-section-number">5.6.3</span> The Method of Batch Means<a href="simoainfhorizon.html#simoainfhorizonbatchmeans" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the batch means method, only one simulation run is executed. After
deleting the warm up period, the remainder of the run is divided into
<span class="math inline">\(k\)</span> batches, with each batch average representing a single observation.</p>
<div class="figure"><span style="display:block;" id="fig:BatchMeans"></span>
<img src="figures/ch7/ch7fig64.png" alt="Illustration of the Batch Means Method" width="80%" height="80%" />
<p class="caption">
Figure 5.20: Illustration of the Batch Means Method
</p>
</div>
<p>Figure <a href="simoainfhorizon.html#fig:BatchMeans">5.20</a> illustrates the concept of batching observations. The advantages of the batch means method are that it entails a long simulation run, thus dampening the effect of the initial conditions. The disadvantage is that the within replication data are correlated and
unless properly formed the batches may also exhibit a strong degree of correlation.</p>
<p>The following presentation assumes that a warm up analysis has already
been performed and that the data that has been collected occurs after
the warm up period. For simplicity, the presentation assumes observation
based data. The discussion also applies to time-based data that has been
cut into discrete equally spaced intervals of time as previously described.
Therefore, assume that a series of observations,
<span class="math inline">\((X_1, X_2, X_3, \ldots, X_n)\)</span>, is available from within the one long
replication after the warm up period. As shown earlier, the
within replication data can be highly correlated. In that section, it
was mentioned that standard confidence intervals based on</p>
<p><span class="math display">\[S^2(n) = \dfrac{1}{n - 1}\sum_{i=1}^n (X_i - \bar{X})^2\]</span></p>
<p>are not appropriate for this type of data. Suppose you were to ignore
the correlation, what would be the harm? In essence, a confidence
interval implies a certain level of confidence in the decisions based on
the confidence interval. When you use <span class="math inline">\(S^2(n)\)</span> as defined above, you
will not achieve the desired level of confidence because <span class="math inline">\(S^2(n)\)</span> is a
biased estimator for the variance of <span class="math inline">\(\bar{X}\)</span> when the data are
correlated. Under the assumption that the data are covariance
stationary, an assessment of the harm in ignoring the correlation can be
made. For a series that is covariance stationary, one can show that</p>
<p><span class="math display">\[Var(\bar{X}) = \dfrac{\gamma_0}{n} \left[1 + 2 \sum_{k=1}^{n-1} \left(1 - \dfrac{k}{n} \right) \rho_k \right]\]</span></p>
<p>where <span class="math inline">\(\gamma_0 = Var(X_i)\)</span>, <span class="math inline">\(\gamma_k = Cov(X_i, X_{i + k})\)</span>, and
<span class="math inline">\(\rho_k =  \gamma_k/\gamma_0\)</span> for <span class="math inline">\(k = 1, 2, \ldots, n - 1\)</span>.</p>
<p>When the data are correlated, <span class="math inline">\(S^2/n\)</span> is a biased estimator of
<span class="math inline">\(Var(\bar{X})\)</span>. To show this, you need to compute the expected value of
<span class="math inline">\(S^2/n\)</span> as follows:</p>
<p><span class="math display">\[E\left[S^2/n\right] = \dfrac{\gamma_0}{n} \left[1 - \dfrac{2R}{n - 1}\right]\]</span></p>
<p>where</p>
<p><span class="math display">\[R = \sum_{k=1}^{n-1} (1 - \dfrac{k}{n}) \rho_k\]</span></p>
<p>Bias is defined as the difference between the expected value of the
estimator and the quantity being estimated. In this case, the bias can
be computed with some algebra as:</p>
<p><span class="math display">\[\text{Bias} = E\left[S^2/n\right] - Var(\bar{Y}) = \dfrac{-2 \gamma_0 R}{n - 1}\]</span></p>
<p>Since <span class="math inline">\(\gamma_0 &gt; 0\)</span> and <span class="math inline">\(n &gt; 1\)</span> the sign of the bias depends on the
quantity <em>R</em> and thus on the correlation. There are three cases to
consider: zero correlation, negative correlation, and positive
correlation. Since <span class="math inline">\(-1 \leq \rho_k \leq 1\)</span>, examining the limiting
values for the correlation will determine the range of the bias.</p>
<p>For positive correlation, <span class="math inline">\(0 \leq \rho_k \leq 1\)</span>, the bias will be
negative, (<span class="math inline">\(- \gamma_0 \leq Bias \leq 0\)</span>). Thus, the bias is negative if
the correlation is positive, and the bias is positive if the correlation
is negative. In the case of positive correlation, <span class="math inline">\(S^2/n\)</span> underestimates
the <span class="math inline">\(Var(\bar{X})\)</span>. Thus, using <span class="math inline">\(S^2/n\)</span> to form confidence intervals
will make the confidence intervals too short. You will have unjustified
confidence in the point estimate in this case. The true confidence will
not be the desired <span class="math inline">\(1 - \alpha\)</span>. Decisions based on positively
correlated data will have a higher than planned risk of making an error
based on the confidence interval.</p>
<p>One can easily show that for negative correlation,
<span class="math inline">\(-1 \leq \rho_k \leq 0\)</span>, the bias will be positive
(<span class="math inline">\(0 \leq Bias \leq \gamma_0\)</span>). In the case of negatively correlated
data, <span class="math inline">\(S^2/n\)</span> over estimates the <span class="math inline">\(Var(\bar{X})\)</span>. A confidence interval
based on <span class="math inline">\(S^2/n\)</span> will be too wide and the true quality of the estimate
will be better than indicated. The true confidence coefficient will not
be the desired <span class="math inline">\(1 - \alpha\)</span>; it will be greater than <span class="math inline">\(1 - \alpha\)</span>.</p>
<p>Of the two cases, the positively correlated case is the more severe in
terms of its effect on the decision making process; however, both are
problems. Thus, the naive use of <span class="math inline">\(S^2/n\)</span> for dependent data is highly
unwarranted. If you want to build confidence intervals on <span class="math inline">\(\bar{X}\)</span> you
need to find an unbiased estimator of the <span class="math inline">\(Var(\bar{X})\)</span>.</p>
<p>The method of batch means provides a way to develop (at least
approximately) an unbiased estimator for <span class="math inline">\(Var(\bar{X})\)</span>. Assuming that
you have a series of data point, the method of batch means method
divides the data into subsequences of contiguous batches:</p>
<p><span class="math display">\[\begin{gathered}
\underbrace{X_1, X_2, \ldots, X_b}_{batch 1} \cdots
\underbrace{X_{b+1}, X_{b+2}, \ldots, X_{2b}}_{batch 2} \cdots \\
\underbrace{X_{(j-1)b+1}, X_{(j-1)b+2}, \ldots, X_{jb}}_{batch j}  \cdots
\underbrace{X_{(k-1)b+1}, X_{(k-1)b+2}, \ldots, X_{kb}}_{batch k}\end{gathered}\]</span></p>
<p>and computes the sample average of the batches. Let <span class="math inline">\(k\)</span> be the number of
batches each consisting of <span class="math inline">\(b\)</span> observations, so that
<span class="math inline">\(k = \lfloor n/b \rfloor\)</span>. If <span class="math inline">\(b\)</span> is not a divisor of <span class="math inline">\(n\)</span> then the last
<span class="math inline">\((n - kb)\)</span> data points will not be used. Define <span class="math inline">\(\bar{X}_j(b)\)</span> as the
<span class="math inline">\(j^{th}\)</span> batch mean for <span class="math inline">\(j = 1, 2, \ldots, k\)</span>, where,</p>
<p><span class="math display">\[\bar{X}_j(b) = \dfrac{1}{b} \sum_{i=1}^b X_{(j-1)b+i}\]</span></p>
<p>Each of the batch means are treated like observations in the batch means
series. For example, if the batch means are re-labeled as
<span class="math inline">\(Y_j = \bar{X}_j(b)\)</span>, the batching process simply produces another
series of data, (<span class="math inline">\(Y_1, Y_2, Y_3, \ldots, Y_k\)</span>) which may be more like a
random sample. To form a <span class="math inline">\(1 - \alpha\)</span>% confidence interval, you simply
treat this new series like a random sample and compute approximate
confidence intervals using the sample average and sample variance of the
batch means series:</p>
<p><span class="math display">\[\bar{Y}(k) = \dfrac{1}{k} \sum_{j=1}^k Y_j\]</span></p>
<p><span class="math display">\[S_b^2 (k) = \dfrac{1}{k - 1} \sum_{j=1}^k (Y_j - \bar{Y}^2)\]</span></p>
<p><span class="math display">\[\bar{Y}(k) \pm t_{\alpha/2, k-1} \dfrac{S_b (k)}{\sqrt{k}}\]</span></p>
<p>Since the original X’s are covariance stationary, it follows that the
resulting batch means are also covariance stationary. One can show, see
<span class="citation">(<a href="#ref-alexopoulos1998output">Alexopoulos and Seila 1998</a>)</span>, that the correlation in the batch means
reduces as both the size of the batches, <span class="math inline">\(b\)</span> and the number of data
points, <span class="math inline">\(n\)</span> increases. In addition, one can show that <span class="math inline">\(S_b^2 (k)/k\)</span>
approximates <span class="math inline">\(\text{Var}(\bar{X})\)</span> with error that reduces as both <span class="math inline">\(b\)</span>
and <span class="math inline">\(n\)</span> increase towards infinity.</p>
<p>The basic difficulty with the batch means method is determining the
batch size or alternatively the number of batches. Larger batch sizes
are good for independence but reduce the number of batches, resulting in
higher variance for the estimator. <span class="citation">(<a href="#ref-schmeiser1982batch">Schmeiser 1982</a>)</span> performed an
analysis that suggests that there is little benefit if the number of
batches is larger than 30 and recommended that the number of batches
remain in the range from 10 to 30. However, when trying to assess
whether the batches are independent, it is better to have a large
number of batches (<span class="math inline">\(&gt;\)</span> 100) so that tests on the lag-k correlation have
better statistical properties.</p>
<p>There are a variety of procedures that have been developed that will
automatically batch the data as it is collected, see for example
<span class="citation">(<a href="#ref-fishman1997an">G. S. Fishman and Yarberry 1997</a>)</span>, <span class="citation">(<a href="#ref-steiger2002an">Steiger and Wilson 2002</a>)</span>, and <span class="citation">Banks et al. (<a href="#ref-banks2005discreteevent">2005</a>)</span>. has its
own batching algorithm. The batching algorithm is described in
<span class="citation">Kelton, Sadowski, and Sturrock (<a href="#ref-kelton2004simulation">2004</a>)</span> page 311. See also <span class="citation">(<a href="#ref-fishman2001discreteevent">G. S. Fishman 2001</a>)</span>
page 254 for an analysis of the effectiveness of the algorithm.</p>
<p>The discussion here is based on the description in
<span class="citation">Kelton, Sadowski, and Sturrock (<a href="#ref-kelton2004simulation">2004</a>)</span>. When the algorithm has recorded a sufficient
amount of data, it begins by forming k = 20 batches. As more data is
collected, additional batches are formed until k = 40 batches are
collected. When 40 batches are formed, the algorithm collapses the
number of batches back to 20, by averaging each pair of batches. This
has the net effect of doubling the batch size. This process is repeated
as more data is collected, thereby ensuring that the number of batches
is between 20 and 39.</p>
<p>For time-persistent data, the approach requires that the data be
discretized as previously discussed in the section on warm up period
analysis. Then, the same batch method is applied to ensure between 20
and 39 batches. In addition, the process also computes the lag-1
correlation so that a test can be performed to check if the correlation
is significant by testing the hypothesis that the batch means are
uncorrelated using the following test statistic, see
<span class="citation">(<a href="#ref-alexopoulos1998output">Alexopoulos and Seila 1998</a>)</span>:</p>
<p><span class="math display">\[C = \sqrt{\dfrac{k^2 - 1}{k - 2}}\biggl[ \hat{\rho}_1 + \dfrac{[Y_1 - \bar{Y}]^2 + [Y_k - \bar{Y}]^2}{2 \sum_{j=1}^k (Y_j - \bar{Y})^2}\biggr]\]</span></p>
<p><span class="math display">\[\hat{\rho}_1 = \dfrac{\sum_{j=1}^{k-1} (Y_j - \bar{Y})(Y_{j+1} - \bar{Y})}{\sum _{j=1}^k (Y_j - \bar{Y})^2}\]</span></p>
<p>The hypothesis is rejected if <span class="math inline">\(C &gt; z_\alpha\)</span> for a given confidence
level <span class="math inline">\(\alpha\)</span>. If the batch means do not pass the test, then increasing the replication run length should permit more data to be collected and increase the size of the batches. This may permit the correlation test to pass.</p>
</div>
<div id="simoainfhorizonjslbatching" class="section level3 hasAnchor" number="5.6.4">
<h3><span class="header-section-number">5.6.4</span> Performing the Method of Batch Means<a href="simoainfhorizon.html#simoainfhorizonjslbatching" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Performing the method of batch means in the KSL is relatively straight
forward. The following assumes that a warm up period analysis has
already been performed. Batches are formed during the simulation run and
the confidence intervals are based on the batches. In this situation,
the primary concern will be to determine the run length that will ensure
a desired half-width on the confidence intervals. Both fixed sampling
and sequential sampling methods can be applied.</p>
<p>The following code present the process to set up batching
within the KSL for the Drive Through Pharmacy Model. The key class is
the <code>StatisticalBatchingElement</code> class, which must be added to the <code>Model</code>
(see line 9) prior to running the simulation. The
<code>StatisticalBatchingElement</code> has one key parameter which represents the
interval used to discretize the time weighted variables. If no interval
is supplied, then the algorithm ensures that the initial number of
batches collected before applying the previously described batching
algorithm is 512.</p>
<div class="example">
<p><span id="exm:ch5ex5" class="example"><strong>Example 5.5  (Performing a Batch Means Analysis) </strong></span>This code illustrates how to perform a single run, batch means analysis, by
adding a batching element to the model.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode kt"><code class="sourceCode kotlin"><span id="cb176-1"><a href="simoainfhorizon.html#cb176-1" tabindex="-1"></a><span class="kw">fun</span> <span class="fu">main</span><span class="op">(){</span></span>
<span id="cb176-2"><a href="simoainfhorizon.html#cb176-2" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">model</span> <span class="op">=</span> Model<span class="op">(</span><span class="st">&quot;Drive Through Pharmacy&quot;</span><span class="op">)</span></span>
<span id="cb176-3"><a href="simoainfhorizon.html#cb176-3" tabindex="-1"></a>    <span class="co">// add DriveThroughPharmacy to the main model</span></span>
<span id="cb176-4"><a href="simoainfhorizon.html#cb176-4" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">dtp</span> <span class="op">=</span> DriveThroughPharmacyWithQ<span class="op">(</span>model<span class="op">,</span> <span class="dv">1</span><span class="op">)</span></span>
<span id="cb176-5"><a href="simoainfhorizon.html#cb176-5" tabindex="-1"></a>    dtp<span class="op">.</span>arrivalRV<span class="op">.</span>initialRandomSource <span class="op">=</span> ExponentialRV<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span> <span class="dv">1</span><span class="op">)</span></span>
<span id="cb176-6"><a href="simoainfhorizon.html#cb176-6" tabindex="-1"></a>    dtp<span class="op">.</span>serviceRV<span class="op">.</span>initialRandomSource <span class="op">=</span> ExponentialRV<span class="op">(</span><span class="fl">0.7</span><span class="op">,</span> <span class="dv">2</span><span class="op">)</span></span>
<span id="cb176-7"><a href="simoainfhorizon.html#cb176-7" tabindex="-1"></a>    model<span class="op">.</span>numberOfReplications <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb176-8"><a href="simoainfhorizon.html#cb176-8" tabindex="-1"></a>    model<span class="op">.</span>lengthOfReplication <span class="op">=</span> <span class="fl">1000000.0</span></span>
<span id="cb176-9"><a href="simoainfhorizon.html#cb176-9" tabindex="-1"></a>    model<span class="op">.</span>lengthOfReplicationWarmUp <span class="op">=</span> <span class="fl">100000.0</span></span>
<span id="cb176-10"><a href="simoainfhorizon.html#cb176-10" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">batchingElement</span> <span class="op">=</span> model<span class="op">.</span>statisticalBatching<span class="op">()</span></span>
<span id="cb176-11"><a href="simoainfhorizon.html#cb176-11" tabindex="-1"></a>    model<span class="op">.</span>simulate<span class="op">()</span></span>
<span id="cb176-12"><a href="simoainfhorizon.html#cb176-12" tabindex="-1"></a>    <span class="kw">val</span> <span class="va">sr</span> <span class="op">=</span> batchingElement<span class="op">.</span>statisticReporter</span>
<span id="cb176-13"><a href="simoainfhorizon.html#cb176-13" tabindex="-1"></a>    println<span class="op">(</span>sr<span class="op">.</span>halfWidthSummaryReport<span class="op">())</span></span>
<span id="cb176-14"><a href="simoainfhorizon.html#cb176-14" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
</div>
<p>The analysis performed to determine the warm up period should give you
some information concerning how long to make this single run and how
long to set it’s warm up period. Assume that a warm up analysis has been
performed using <span class="math inline">\(n_0\)</span> replications of length <span class="math inline">\(T_e\)</span> and that the analysis
has indicated a warm up period of length <span class="math inline">\(T_w\)</span>. Then, we can use this
information is setting up the run length and warm up period for the
single replication experiment.</p>
<p>As previously discussed, the method of replication deletion spreads the
risk of choosing a bad initial condition across multiple replications.
The method of batch means relies on only one replication. If you were
satisfied with the warm up period analysis based on <span class="math inline">\(n_0\)</span> replications
and you were going to perform replication deletion, then you are willing
to throw away the observations contained in at least <span class="math inline">\(n_0 \times T_w\)</span>
time units and you are willing to use the data collected over
<span class="math inline">\(n_0 \times (T_e - T_w)\)</span> time units. Therefore, the warm up period for
the single replication can be set at <span class="math inline">\(n_0 \times T_w\)</span> and the run length
can be set at <span class="math inline">\(n_0 \times T_e\)</span>. For example, suppose your warm up
analysis was based on the initial results of <span class="math inline">\(n_0\)</span> = 10, <span class="math inline">\(T_e\)</span> = 30000,
<span class="math inline">\(T_w\)</span> = 10000. Thus, your starting run length would be
<span class="math inline">\(n_0 \times T_e = 10 \times 30,000 = 300,000\)</span> and the warm period will
be <span class="math inline">\(n_0 \times T_w = 100,000\)</span>. The following table show the results based on replication deletion</p>
<table>
<caption>Replication-Deletion Half-Width Summary report <span class="math inline">\(n=10\)</span>, <span class="math inline">\(T_e = 30000\)</span>, <span class="math inline">\(T_w = 10000\)</span></caption>
<thead>
<tr class="header">
<th align="left">Response Name</th>
<th align="center"><span class="math inline">\(n\)</span></th>
<th align="center"><span class="math inline">\(\bar{x}\)</span></th>
<th align="center"><span class="math inline">\(hw\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PharmacyQ:Num In Q</td>
<td align="center">10</td>
<td align="center">1.656893</td>
<td align="center">0.084475</td>
</tr>
<tr class="even">
<td align="left">PharmacyQ:Time In Q</td>
<td align="center">10</td>
<td align="center">1.659100</td>
<td align="center">0.082517</td>
</tr>
<tr class="odd">
<td align="left">NumBusy</td>
<td align="center">10</td>
<td align="center">0.699705</td>
<td align="center">0.004851</td>
</tr>
<tr class="even">
<td align="left">Num in System</td>
<td align="center">10</td>
<td align="center">2.356598</td>
<td align="center">0.088234</td>
</tr>
<tr class="odd">
<td align="left">System Time</td>
<td align="center">10</td>
<td align="center">2.359899</td>
<td align="center">0.085361</td>
</tr>
</tbody>
</table>
<p>This table shows the results based on batching one long replication.</p>
<table>
<caption>Batch Means Summary Report <span class="math inline">\(T_e = 300000\)</span>, <span class="math inline">\(T_w = 100000\)</span></caption>
<thead>
<tr class="header">
<th align="left">Response Name</th>
<th align="center"><span class="math inline">\(n\)</span></th>
<th align="center"><span class="math inline">\(\bar{x}\)</span></th>
<th align="center"><span class="math inline">\(hw\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PharmacyQ:Num In Q</td>
<td align="center">32</td>
<td align="center">1.631132</td>
<td align="center">0.047416</td>
</tr>
<tr class="even">
<td align="left">PharmacyQ:Time In Q</td>
<td align="center">24</td>
<td align="center">1.627059</td>
<td align="center">0.055888</td>
</tr>
<tr class="odd">
<td align="left">NumBusy</td>
<td align="center">32</td>
<td align="center">0.699278</td>
<td align="center">0.004185</td>
</tr>
<tr class="even">
<td align="left">Num in System</td>
<td align="center">32</td>
<td align="center">2.330410</td>
<td align="center">0.049853</td>
</tr>
<tr class="odd">
<td align="left">System Time</td>
<td align="center">24</td>
<td align="center">2.324590</td>
<td align="center">0.057446</td>
</tr>
</tbody>
</table>
<p>Suppose now you want to ensure that the half-widths from a single
replication are less than a given error bound. The half-widths reported
by the simulation for a single replication are based on the <em>batch
means</em>. You can get an approximate idea of how much to increase the
length of the replication by using the half-width sample size
determination formula.</p>
<p><span class="math display">\[n \cong n_0 \left(\dfrac{h_0}{h}\right)^2\]</span></p>
<p>In this case, you interpret <span class="math inline">\(n\)</span> and <span class="math inline">\(n_0\)</span> as the number of batches. From
previous results, there were 32 batches for the time-weighted
variables. Based on <span class="math inline">\(T_e = 300000\)</span> and <span class="math inline">\(T_w = 100000\)</span> there was a total
of <span class="math inline">\(T_e - T_w = 200000\)</span> time units of observed data. This means that
each batch represents <span class="math inline">\(200,000\div 32 = 6250\)</span> time units. Using this
information in the half-width based sample size formula with <span class="math inline">\(n_0 = 32\)</span>,
<span class="math inline">\(h_0 = 0.049\)</span>, and <span class="math inline">\(h = 0.02\)</span>, for the number in the system, yields:</p>
<p><span class="math display">\[n \cong n_0 \dfrac{h_0^2}{h^2} = 32 \times \dfrac{(0.049)^2}{(0.02)^2} = 192 \ \ \text{batches}\]</span></p>
<p>Since each batch in the run had 6250 time units, this yields the need
for 1,200,000 time units of observations. Because of the warm up period,
you therefore need to set <span class="math inline">\(T_e\)</span> equal to (1,200,000 + 100,000 =
1,300,000). Re-running the simulation yields the results shown in
the following table. The results show that the half-width meets
the desired criteria. This approach is approximate since you do not know
how the observations will be batched when making the final run.</p>
<table>
<caption>Batch Means Summary Report <span class="math inline">\(T_e = 1,300,000\)</span>, <span class="math inline">\(T_w = 100000\)</span></caption>
<thead>
<tr class="header">
<th align="left">Response Name</th>
<th align="center"><span class="math inline">\(n\)</span></th>
<th align="center"><span class="math inline">\(\bar{x}\)</span></th>
<th align="center"><span class="math inline">\(hw\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">NumBusy</td>
<td align="center">32</td>
<td align="center">0.698973</td>
<td align="center">0.001652</td>
</tr>
<tr class="even">
<td align="left">Num in System</td>
<td align="center">32</td>
<td align="center">2.322050</td>
<td align="center">0.019413</td>
</tr>
<tr class="odd">
<td align="left">PharmacyQ:Num In Q</td>
<td align="center">32</td>
<td align="center">1.623077</td>
<td align="center">0.018586</td>
</tr>
<tr class="even">
<td align="left">PharmacyQ:Time In Q</td>
<td align="center">36</td>
<td align="center">1.625395</td>
<td align="center">0.017383</td>
</tr>
<tr class="odd">
<td align="left">System Time</td>
<td align="center">36</td>
<td align="center">2.324915</td>
<td align="center">0.017815</td>
</tr>
</tbody>
</table>
<p>Rather than trying to fix the amount of sampling, you might instead try
to use a sequential sampling technique that is based on the half-width
computed during the simulation run. In order to do this, we need to
create a specific observer that can stop the simulation when the
half-width criteria is met for the batch means. Currently, the KSL does not facilitate this approach.</p>
<p>Once the warm up period has been analyzed, performing infinite horizon
simulations using the batch means method is relatively straight forward.
A disadvantage of the batch means method is that it will be more
difficult to use classical experimental design methods.
If you are faced with an infinite horizon simulation, then you can use
either the replication-deletion approach or the batch means method
readily within the KSL. In either case, you should investigate if there
may be any problems related to initialization bias. If you use the
replication-deletion approach, you should play it safe when specifying
the warm up period. Making the warm up period longer than you think it
should be is better than replicating a poor choice. When performing an
infinite horizon simulation based on one long run, you should make sure
that your run length is long enough. A long run length can help to “wash
out” the effects of initial condition bias.</p>
<p>Ideally, in the situation where you have to make many simulation
experiments using different parameter settings of the same model, you
should perform a warm up analysis for <strong>each design configuration</strong>. In
practice, this is not readily feasible when there are a large number of
experiments. In this situation, you should use your common sense to pick
the design configurations (and performance measures) that you feel will
most likely suffer from initialization bias. If you can determine long
enough warm up periods for these configurations, the other
configurations should be relatively safe from the problem by using the
longest warm up period found.</p>
<p>There are a number of other techniques that have been developed for the
analysis of infinite horizon simulations including the standardized time
series method, the regenerative method, and spectral methods. An
overview of these methods and others can be found in
<span class="citation">(<a href="#ref-alexopoulos1998output">Alexopoulos and Seila 1998</a>)</span> and in <span class="citation">(<a href="#ref-law2007simulation">Law 2007</a>)</span>.</p>
<p>So far you have learned how to analyze the data from one design
configuration. A key use of simulation is to be able to compare
alternative system configurations and to assist in choosing which
configurations are best according to the decision criteria. The next
section discusses how to compare different system configurations.</p>
</div>
</div>
<h3><span class="header-section-number">G</span> References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-alexopoulos1998output" class="csl-entry">
Alexopoulos, C., and A. F. Seila. 1998. <span>“Output Data Analysis.”</span> In <em>Handbook of Simulation</em>, edited by J. Banks. John Wiley &amp; Sons, New York.
</div>
<div id="ref-banks2005discreteevent" class="csl-entry">
Banks, J., J. Carson, B. Nelson, and D. Nicol. 2005. <em>Discrete-Event System Simulation</em>. 4th ed. Prentice Hall.
</div>
<div id="ref-cash1992" class="csl-entry">
Cash, C. R., D. G. Dippold, J. M. Long, B. L. Nelson, and W. P. Pollard. 1992. <span>“Evaluation of Tests for Initial Conditions Bias.”</span> In <em>Proceedings of the 1992 Winter Simulation Conference</em>, edited by J. J. Swain, D. Goldsman, R. C. Crain, and J. R. Wilson, 577–85.
</div>
<div id="ref-fishman2001discreteevent" class="csl-entry">
Fishman, G. S. 2001. <em>Discrete-Event Simulation: Modeling, Programming, and Analysis</em>. New York: Springer.
</div>
<div id="ref-fishman1997an" class="csl-entry">
Fishman, G. S., and L. S. Yarberry. 1997. <span>“An Implementation of the Batch Means Method.”</span> <em>INFORMS Journal on Computing</em> 9.
</div>
<div id="ref-gross1998fundamentals" class="csl-entry">
Gross, D., and C. M. Harris. 1998. <em>Fundamentals of Queueing Theory</em>. 3rd ed. New York: John Wiley &amp; Sons.
</div>
<div id="ref-kelton2004simulation" class="csl-entry">
Kelton, W. D., R. P. Sadowski, and D. T. Sturrock. 2004. <em>Simulation with Arena</em>. 3rd ed. McGraw-Hill.
</div>
<div id="ref-lada2003a" class="csl-entry">
Lada, E. K., J. R. Wilson, and N. M. Steiger. 2003. <em>A Wavelet-Based Spectral Method for Steady-State Simulation Analysis</em>. Proceedings of the 2003 Winter Simulation Conference.
</div>
<div id="ref-law2007simulation" class="csl-entry">
Law, A. 2007. <em>Simulation Modeling and Analysis</em>. 4th ed. McGraw-Hill.
</div>
<div id="ref-Litton:2002aa" class="csl-entry">
Litton, J. R., and C. H. Harmonosky. 2002. <em>A Comparison of Selective Initialization Bias Elimination Methods</em>. Proceeding of the 2002 Winter Simulation Conference.
</div>
<div id="ref-robinson2005automated" class="csl-entry">
Robinson, S. 2005. <span>“Automated Analysis of Simulation Output Data.”</span> Edited by M. E. Kuhl, N. M. Steiger, F. B. Armstrong, and J. A. Joines. <em>Proceedings of the 2005 Winter Simulation Conference</em> 763-770.
</div>
<div id="ref-rossetti1995control" class="csl-entry">
Rossetti, M. D., and P. J. Delaney. 1995. <em>Control of Initialization Bias in Queueing Simulations Using Queueing Approximations</em>. Piscataway, New Jersey: Institute of Electrical; Electronics Engineers.
</div>
<div id="ref-Rossetti2005aa" class="csl-entry">
Rossetti, M. D., and Z. Li. 2005. <span>“Exploring Exponentially Weighted Moving Average Control Charts to Determine the Warm-up Period.”</span> In <em>Proceedings of the 2005 Winter Simulation Conference</em>, edited by M. E. Kuhl, N. M. Steiger, F. B. Armstrong, and J. A. Joines, 771–80. Piscataway, New Jersey: Institute of Electrical; Electronics Engineers.
</div>
<div id="ref-schmeiser1982batch" class="csl-entry">
Schmeiser, B. W. 1982. <span>“Batch Size Effects in the Analysis of Simulation Output.”</span> <em>Operations Research</em> 30: 556–68.
</div>
<div id="ref-steiger2002an" class="csl-entry">
Steiger, N. M., and J. R. Wilson. 2002. <span>“An Improved Batch Means Procedure for Simulation Output Analysis.”</span> <em>Management Science</em> 48.
</div>
<div id="ref-welch1983a" class="csl-entry">
Welch, P. D. 1983. <span>“A Graphical Approach to the Initial Transient Problem in Steady State Simulation.”</span> In <em>10th <span>IMACS</span> World Congress on System Simulation and Scientific Computation</em>, 219–21.
</div>
<div id="ref-white2000a" class="csl-entry">
White, K. P., M. J. Cobb, and S. C. Spratt. 2000. <em>A Comparison of Five Steady-State Truncation Heuristics for Simulation</em>. Proceeding of the 2000 Winter Simulation Conference.
</div>
<div id="ref-whitt1989planning" class="csl-entry">
———. 1989. <span>“Planning Queueing Simulations.”</span> <em>Management Science</em> 35 (11): 1341–66.
</div>
<div id="ref-wilson1978a" class="csl-entry">
Wilson, J. R., and A. A. B. Pritsker. 1978. <span>“A Survey of Re-Search on the Simulation Startup Problem.”</span> <em>Simulation</em>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simoaseqsampling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="simoacomparingSystems.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
