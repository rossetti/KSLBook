<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.6 Comparing System Configurations | Simulation Modeling using the Kotlin Simulation Library</title>
  <meta name="description" content="A book that illustrates the basics of using the KSL. The output format for this book is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="6.6 Comparing System Configurations | Simulation Modeling using the Kotlin Simulation Library" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A book that illustrates the basics of using the KSL. The output format for this book is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.6 Comparing System Configurations | Simulation Modeling using the Kotlin Simulation Library" />
  
  <meta name="twitter:description" content="A book that illustrates the basics of using the KSL. The output format for this book is bookdown::gitbook." />
  

<meta name="author" content="Manuel D. Rossetti" />


<meta name="date" content="2022-11-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="simoa:infhorizon.html"/>
<link rel="next" href="simoa:summary.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Simulation Modeling using the Kotlin Simulation Library</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the Author</a></li>
<li class="chapter" data-level="1" data-path="ch1.html"><a href="ch1.html"><i class="fa fa-check"></i><b>1</b> Simulation Modeling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="simulation-modeling.html"><a href="simulation-modeling.html"><i class="fa fa-check"></i><b>1.1</b> Simulation Modeling</a></li>
<li class="chapter" data-level="1.2" data-path="why-simulate.html"><a href="why-simulate.html"><i class="fa fa-check"></i><b>1.2</b> Why Simulate?</a></li>
<li class="chapter" data-level="1.3" data-path="types-of-systems-and-simulation-models.html"><a href="types-of-systems-and-simulation-models.html"><i class="fa fa-check"></i><b>1.3</b> Types of Systems and Simulation Models</a></li>
<li class="chapter" data-level="1.4" data-path="simulation-descriptive-or-prescriptive-modeling.html"><a href="simulation-descriptive-or-prescriptive-modeling.html"><i class="fa fa-check"></i><b>1.4</b> Simulation: Descriptive or Prescriptive Modeling?</a></li>
<li class="chapter" data-level="1.5" data-path="randomness-in-simulation.html"><a href="randomness-in-simulation.html"><i class="fa fa-check"></i><b>1.5</b> Randomness in Simulation</a></li>
<li class="chapter" data-level="1.6" data-path="simulation-languages.html"><a href="simulation-languages.html"><i class="fa fa-check"></i><b>1.6</b> Simulation Languages</a></li>
<li class="chapter" data-level="1.7" data-path="ch1:sec:simMeth.html"><a href="ch1:sec:simMeth.html"><i class="fa fa-check"></i><b>1.7</b> Simulation Methodology</a></li>
<li class="chapter" data-level="1.8" data-path="overview-of-the-kotline-simulation-library.html"><a href="overview-of-the-kotline-simulation-library.html"><i class="fa fa-check"></i><b>1.8</b> Overview of the Kotline Simulation Library</a></li>
<li class="chapter" data-level="1.9" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch2rng.html"><a href="ch2rng.html"><i class="fa fa-check"></i><b>2</b> Modeling Randomness</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch2generator.html"><a href="ch2generator.html"><i class="fa fa-check"></i><b>2.1</b> Random Number Generator</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ch2generator.html"><a href="ch2generator.html#ch2randompkg"><i class="fa fa-check"></i><b>2.1.1</b> Random Package</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch2generator.html"><a href="ch2generator.html#ch2creatingStreams"><i class="fa fa-check"></i><b>2.1.2</b> Creating and Using Streams</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch2generator.html"><a href="ch2generator.html#ch2crn"><i class="fa fa-check"></i><b>2.1.3</b> Common Random Numbers</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch2generator.html"><a href="ch2generator.html#ch2antitheticStreams"><i class="fa fa-check"></i><b>2.1.4</b> Creating and Using Antithetic Streams</a></li>
<li class="chapter" data-level="2.1.5" data-path="ch2generator.html"><a href="ch2generator.html#ch2rnFAQ"><i class="fa fa-check"></i><b>2.1.5</b> Frequently Asked Questions about Random Numbers</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="rvg.html"><a href="rvg.html"><i class="fa fa-check"></i><b>2.2</b> Random Variate Generation</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="rvg.html"><a href="rvg.html#rvg_dists"><i class="fa fa-check"></i><b>2.2.1</b> Continuous and Discrete Random Variables</a></li>
<li class="chapter" data-level="2.2.2" data-path="rvg.html"><a href="rvg.html#rvg_algo"><i class="fa fa-check"></i><b>2.2.2</b> Overview of Generation Algorithms</a></li>
<li class="chapter" data-level="2.2.3" data-path="rvg.html"><a href="rvg.html#rvg_use"><i class="fa fa-check"></i><b>2.2.3</b> Creating and Using Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="probability-distribution-models.html"><a href="probability-distribution-models.html"><i class="fa fa-check"></i><b>2.3</b> Probability Distribution Models</a></li>
<li class="chapter" data-level="2.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>2.4</b> Summary</a></li>
<li class="chapter" data-level="2.5" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mcm.html"><a href="mcm.html"><i class="fa fa-check"></i><b>3</b> Monte Carlo Methods</a>
<ul>
<li class="chapter" data-level="3.1" data-path="kslStatistics.html"><a href="kslStatistics.html"><i class="fa fa-check"></i><b>3.1</b> Collecting Statistics</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="kslStatistics.html"><a href="kslStatistics.html#creating-and-using-a-statistic"><i class="fa fa-check"></i><b>3.1.1</b> Creating and Using a Statistic</a></li>
<li class="chapter" data-level="3.1.2" data-path="kslStatistics.html"><a href="kslStatistics.html#histograms-and-frequencies"><i class="fa fa-check"></i><b>3.1.2</b> Histograms and Frequencies</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ch3batchStats.html"><a href="ch3batchStats.html"><i class="fa fa-check"></i><b>3.2</b> Batch Statistics</a></li>
<li class="chapter" data-level="3.3" data-path="ssMC.html"><a href="ssMC.html"><i class="fa fa-check"></i><b>3.3</b> Simple Monte Carlo Integration</a></li>
<li class="chapter" data-level="3.4" data-path="ch3StatReview.html"><a href="ch3StatReview.html"><i class="fa fa-check"></i><b>3.4</b> Review of Statistical Concepts</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ch3StatReview.html"><a href="ch3StatReview.html#point-estimates-and-confidence-intervals"><i class="fa fa-check"></i><b>3.4.1</b> Point Estimates and Confidence Intervals</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch3StatReview.html"><a href="ch3StatReview.html#ch3SampleSize"><i class="fa fa-check"></i><b>3.4.2</b> Sample Size Determination</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch3StatReview.html"><a href="ch3StatReview.html#determining-the-sample-size-for-a-monte-carlo-simulation-experiment"><i class="fa fa-check"></i><b>3.4.3</b> Determining the Sample Size for a Monte Carlo Simulation Experiment</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="craps.html"><a href="craps.html"><i class="fa fa-check"></i><b>3.5</b> Simulating the Game of Craps</a></li>
<li class="chapter" data-level="3.6" data-path="the-news-vendor-problem.html"><a href="the-news-vendor-problem.html"><i class="fa fa-check"></i><b>3.6</b> The News Vendor Problem</a></li>
<li class="chapter" data-level="3.7" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>3.7</b> Summary</a></li>
<li class="chapter" data-level="3.8" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introDEDS.html"><a href="introDEDS.html"><i class="fa fa-check"></i><b>4</b> Introduction to Discrete Event Modeling</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introDEDSIntro.html"><a href="introDEDSIntro.html"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="introDEDSdeds.html"><a href="introDEDSdeds.html"><i class="fa fa-check"></i><b>4.2</b> Discrete-Event Dynamic Systems</a></li>
<li class="chapter" data-level="4.3" data-path="HowDEDSClockWorks.html"><a href="HowDEDSClockWorks.html"><i class="fa fa-check"></i><b>4.3</b> How the Discrete-Event Clock Works</a></li>
<li class="chapter" data-level="4.4" data-path="QHandExample.html"><a href="QHandExample.html"><i class="fa fa-check"></i><b>4.4</b> Simulating a Queueing System By Hand</a></li>
<li class="chapter" data-level="4.5" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html"><i class="fa fa-check"></i><b>4.5</b> Modeling DEDS in the KSL</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#event-scheduling"><i class="fa fa-check"></i><b>4.5.1</b> Event Scheduling</a></li>
<li class="chapter" data-level="4.5.2" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#introDEDSschedExamples"><i class="fa fa-check"></i><b>4.5.2</b> Simple Event Scheduling Examples</a></li>
<li class="chapter" data-level="4.5.3" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#introDEDSUpDown"><i class="fa fa-check"></i><b>4.5.3</b> Up and Down Component Example</a></li>
<li class="chapter" data-level="4.5.4" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#introDEDSPharmacy"><i class="fa fa-check"></i><b>4.5.4</b> Modeling a Simple Queueing System</a></li>
<li class="chapter" data-level="4.5.5" data-path="introDEDSdedsKSL.html"><a href="introDEDSdedsKSL.html#more-details-about-the-pharmacy-model-implementation"><i class="fa fa-check"></i><b>4.5.5</b> More Details About the Pharmacy Model Implementation</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="introDEDSSummary.html"><a href="introDEDSSummary.html"><i class="fa fa-check"></i><b>4.6</b> Summary</a></li>
<li class="chapter" data-level="4.7" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dem.html"><a href="dem.html"><i class="fa fa-check"></i><b>5</b> Modeling with Queues, Resources, and Stations</a>
<ul>
<li class="chapter" data-level="5.1" data-path="terminology-of-simulation-modeling.html"><a href="terminology-of-simulation-modeling.html"><i class="fa fa-check"></i><b>5.1</b> Terminology of Simulation Modeling</a></li>
<li class="chapter" data-level="5.2" data-path="dem:entities.html"><a href="dem:entities.html"><i class="fa fa-check"></i><b>5.2</b> Entities and Attributes</a></li>
<li class="chapter" data-level="5.3" data-path="dem:eg.html"><a href="dem:eg.html"><i class="fa fa-check"></i><b>5.3</b> Event Generators</a></li>
<li class="chapter" data-level="5.4" data-path="dem:station.html"><a href="dem:station.html"><i class="fa fa-check"></i><b>5.4</b> The Station Package</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="dem:station.html"><a href="dem:station.html#modeling-simple-queueing-stations"><i class="fa fa-check"></i><b>5.4.1</b> Modeling Simple Queueing Stations</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="dem:sharedResources.html"><a href="dem:sharedResources.html"><i class="fa fa-check"></i><b>5.5</b> Sharing a Resource</a></li>
<li class="chapter" data-level="5.6" data-path="dem:tiedyeShirts.html"><a href="dem:tiedyeShirts.html"><i class="fa fa-check"></i><b>5.6</b> Complex System Example</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="dem:tiedyeShirts.html"><a href="dem:tiedyeShirts.html#dem:tiedyeShirts:cm"><i class="fa fa-check"></i><b>5.6.1</b> Conceptualizing the Model</a></li>
<li class="chapter" data-level="5.6.2" data-path="dem:tiedyeShirts.html"><a href="dem:tiedyeShirts.html#dem:tiedyeShirts:im"><i class="fa fa-check"></i><b>5.6.2</b> Implementing the Model</a></li>
<li class="chapter" data-level="5.6.3" data-path="dem:tiedyeShirts.html"><a href="dem:tiedyeShirts.html#dem:tiedyeShirts:results"><i class="fa fa-check"></i><b>5.6.3</b> Model Results</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="dem:summary.html"><a href="dem:summary.html"><i class="fa fa-check"></i><b>5.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simoa.html"><a href="simoa.html"><i class="fa fa-check"></i><b>6</b> Analyzing Simulation Output</a>
<ul>
<li class="chapter" data-level="6.1" data-path="simoa:datatypes.html"><a href="simoa:datatypes.html"><i class="fa fa-check"></i><b>6.1</b> Types of Statistical Variables</a></li>
<li class="chapter" data-level="6.2" data-path="simoa:simtypes.html"><a href="simoa:simtypes.html"><i class="fa fa-check"></i><b>6.2</b> Types of Simulation With Respect To Output Analysis</a></li>
<li class="chapter" data-level="6.3" data-path="simoa:finhorizon.html"><a href="simoa:finhorizon.html"><i class="fa fa-check"></i><b>6.3</b> Analysis of Finite Horizon Simulations</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="simoa:finhorizon.html"><a href="simoa:finhorizon.html#simoa:finhorizon:samplesize"><i class="fa fa-check"></i><b>6.3.1</b> Determining the Number of Replications</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="simoa:finhorizonex.html"><a href="simoa:finhorizonex.html"><i class="fa fa-check"></i><b>6.4</b> Finite Horizon Example</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="simoa:finhorizonex.html"><a href="simoa:finhorizonex.html#conceptualizing-the-model"><i class="fa fa-check"></i><b>6.4.1</b> Conceptualizing the Model</a></li>
<li class="chapter" data-level="6.4.2" data-path="simoa:finhorizonex.html"><a href="simoa:finhorizonex.html#simoa:seqsampling"><i class="fa fa-check"></i><b>6.4.2</b> Sequential Sampling for Finite Horizon Simulations</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="simoa:infhorizon.html"><a href="simoa:infhorizon.html"><i class="fa fa-check"></i><b>6.5</b> Analysis of Infinite Horizon Simulations</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="simoa:infhorizon.html"><a href="simoa:infhorizon.html#simoa:infhorizon:initialbias"><i class="fa fa-check"></i><b>6.5.1</b> Assessing the Effect of Initial Conditions</a></li>
<li class="chapter" data-level="6.5.2" data-path="simoa:infhorizon.html"><a href="simoa:infhorizon.html#simoa:infhorizon:repDeletion"><i class="fa fa-check"></i><b>6.5.2</b> Performing the Method of Replication-Deletion</a></li>
<li class="chapter" data-level="6.5.3" data-path="simoa:infhorizon.html"><a href="simoa:infhorizon.html#simoa:infhorizon:batchmeans"><i class="fa fa-check"></i><b>6.5.3</b> The Method of Batch Means</a></li>
<li class="chapter" data-level="6.5.4" data-path="simoa:infhorizon.html"><a href="simoa:infhorizon.html#simoa:infhorizon:jslbatching"><i class="fa fa-check"></i><b>6.5.4</b> Performing the Method of Batch Means</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="simoa:comparingSystems.html"><a href="simoa:comparingSystems.html"><i class="fa fa-check"></i><b>6.6</b> Comparing System Configurations</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="simoa:comparingSystems.html"><a href="simoa:comparingSystems.html#simoa:comparingSystems:two"><i class="fa fa-check"></i><b>6.6.1</b> Comparing Two Systems</a></li>
<li class="chapter" data-level="6.6.2" data-path="simoa:comparingSystems.html"><a href="simoa:comparingSystems.html#simoa:comparingSystems:MCB"><i class="fa fa-check"></i><b>6.6.2</b> Multiple Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="simoa:summary.html"><a href="simoa:summary.html"><i class="fa fa-check"></i><b>6.7</b> Summary</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="miscellaneous-utility-classes.html"><a href="miscellaneous-utility-classes.html"><i class="fa fa-check"></i><b>A</b> Miscellaneous Utility Classes</a>
<ul>
<li class="chapter" data-level="A.1" data-path="reporting.html"><a href="reporting.html"><i class="fa fa-check"></i><b>A.1</b> Reporting</a></li>
<li class="chapter" data-level="A.2" data-path="jslmath-class.html"><a href="jslmath-class.html"><i class="fa fa-check"></i><b>A.2</b> <code>JSLMath</code> Class</a></li>
<li class="chapter" data-level="A.3" data-path="the-jsl-database.html"><a href="the-jsl-database.html"><i class="fa fa-check"></i><b>A.3</b> The JSL Database</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="the-jsl-database.html"><a href="the-jsl-database.html#the-jsl-database-structure"><i class="fa fa-check"></i><b>A.3.1</b> The JSL Database Structure</a></li>
<li class="chapter" data-level="A.3.2" data-path="the-jsl-database.html"><a href="the-jsl-database.html#creating-and-using-a-default-jsl-database"><i class="fa fa-check"></i><b>A.3.2</b> Creating and Using a Default JSL Database</a></li>
<li class="chapter" data-level="A.3.3" data-path="the-jsl-database.html"><a href="the-jsl-database.html#creating-and-using-jsl-databases"><i class="fa fa-check"></i><b>A.3.3</b> Creating and Using JSL Databases</a></li>
<li class="chapter" data-level="A.3.4" data-path="the-jsl-database.html"><a href="the-jsl-database.html#querying-the-jsl-database"><i class="fa fa-check"></i><b>A.3.4</b> Querying the JSL Database</a></li>
<li class="chapter" data-level="A.3.5" data-path="the-jsl-database.html"><a href="the-jsl-database.html#additional-functionality"><i class="fa fa-check"></i><b>A.3.5</b> Additional Functionality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appRNRV.html"><a href="appRNRV.html"><i class="fa fa-check"></i><b>B</b> Generating Pseudo-Random Numbers and Random Variates</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appRNRVPRN.html"><a href="appRNRVPRN.html"><i class="fa fa-check"></i><b>B.1</b> Pseudo Random Numbers</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="appRNRVPRN.html"><a href="appRNRVPRN.html#appRNRVRNGs"><i class="fa fa-check"></i><b>B.1.1</b> Random Number Generators</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="appRNRVs.html"><a href="appRNRVs.html"><i class="fa fa-check"></i><b>B.2</b> Generating Random Variates from Distributions</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="appRNRVs.html"><a href="appRNRVs.html#inverse-transform-method"><i class="fa fa-check"></i><b>B.2.1</b> Inverse Transform Method</a></li>
<li class="chapter" data-level="B.2.2" data-path="appRNRVs.html"><a href="appRNRVs.html#convolution"><i class="fa fa-check"></i><b>B.2.2</b> Convolution</a></li>
<li class="chapter" data-level="B.2.3" data-path="appRNRVs.html"><a href="appRNRVs.html#acceptancerejection"><i class="fa fa-check"></i><b>B.2.3</b> Acceptance/Rejection</a></li>
<li class="chapter" data-level="B.2.4" data-path="appRNRVs.html"><a href="appRNRVs.html#appRNRVsubsecMTSRV"><i class="fa fa-check"></i><b>B.2.4</b> Mixture Distributions, Truncated Distributions, and Shifted Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="summary-2.html"><a href="summary-2.html"><i class="fa fa-check"></i><b>B.3</b> Summary</a></li>
<li class="chapter" data-level="B.4" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>B.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="appidm.html"><a href="appidm.html"><i class="fa fa-check"></i><b>C</b> Probability Distribution Modeling</a>
<ul>
<li class="chapter" data-level="C.1" data-path="appidmsecrvPD.html"><a href="appidmsecrvPD.html"><i class="fa fa-check"></i><b>C.1</b> Random Variables and Probability Distributions</a></li>
<li class="chapter" data-level="C.2" data-path="appidmsecMDD.html"><a href="appidmsecMDD.html"><i class="fa fa-check"></i><b>C.2</b> Modeling with Discrete Distributions</a></li>
<li class="chapter" data-level="C.3" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html"><i class="fa fa-check"></i><b>C.3</b> Fitting Discrete Distributions</a>
<ul>
<li class="chapter" data-level="C.3.1" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#AppDisFitPoissonFit"><i class="fa fa-check"></i><b>C.3.1</b> Fitting a Poisson Distribution</a></li>
<li class="chapter" data-level="C.3.2" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#visualizing-the-data"><i class="fa fa-check"></i><b>C.3.2</b> Visualizing the Data</a></li>
<li class="chapter" data-level="C.3.3" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#estimating-the-rate-parameter-for-the-poisson-distribution"><i class="fa fa-check"></i><b>C.3.3</b> Estimating the Rate Parameter for the Poisson Distribution</a></li>
<li class="chapter" data-level="C.3.4" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#chi-squared-goodness-of-fit-test-for-poisson-distribution"><i class="fa fa-check"></i><b>C.3.4</b> Chi-Squared Goodness of Fit Test for Poisson Distribution</a></li>
<li class="chapter" data-level="C.3.5" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#subsubchisqGOF"><i class="fa fa-check"></i><b>C.3.5</b> Chi-Squared Goodness of Fit Test</a></li>
<li class="chapter" data-level="C.3.6" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#using-the-fitdistrplus-r-package-on-discrete-data"><i class="fa fa-check"></i><b>C.3.6</b> Using the fitdistrplus R Package on Discrete Data</a></li>
<li class="chapter" data-level="C.3.7" data-path="appidmsecfitDiscrete.html"><a href="appidmsecfitDiscrete.html#fitting-a-discrete-empirical-distribution"><i class="fa fa-check"></i><b>C.3.7</b> Fitting a Discrete Empirical Distribution</a></li>
</ul></li>
<li class="chapter" data-level="C.4" data-path="appidmsecMCD.html"><a href="appidmsecMCD.html"><i class="fa fa-check"></i><b>C.4</b> Modeling with Continuous Distributions</a></li>
<li class="chapter" data-level="C.5" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html"><i class="fa fa-check"></i><b>C.5</b> Fitting Continuous Distributions</a>
<ul>
<li class="chapter" data-level="C.5.1" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsecvisualizedata"><i class="fa fa-check"></i><b>C.5.1</b> Visualizing the Data</a></li>
<li class="chapter" data-level="C.5.2" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsecstatsdata"><i class="fa fa-check"></i><b>C.5.2</b> Statistically Summarize the Data</a></li>
<li class="chapter" data-level="C.5.3" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsechypothDist"><i class="fa fa-check"></i><b>C.5.3</b> Hypothesizing and Testing a Distribution</a></li>
<li class="chapter" data-level="C.5.4" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#kolmogorov-smirnov-test"><i class="fa fa-check"></i><b>C.5.4</b> Kolmogorov-Smirnov Test</a></li>
<li class="chapter" data-level="C.5.5" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidmsubsecvisFit"><i class="fa fa-check"></i><b>C.5.5</b> Visualizing the Fit</a></li>
<li class="chapter" data-level="C.5.6" data-path="appidmsecfitContinuous.html"><a href="appidmsecfitContinuous.html#appidms2sb3"><i class="fa fa-check"></i><b>C.5.6</b> Using the Input Analyzer</a></li>
</ul></li>
<li class="chapter" data-level="C.6" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html"><i class="fa fa-check"></i><b>C.6</b> Testing Uniform (0,1) Pseudo-Random Numbers</a>
<ul>
<li class="chapter" data-level="C.6.1" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#chi-squared-goodness-of-fit-tests-for-pseudo-random-numbers"><i class="fa fa-check"></i><b>C.6.1</b> Chi-Squared Goodness of Fit Tests for Pseudo-Random Numbers</a></li>
<li class="chapter" data-level="C.6.2" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#higher-dimensional-chi-squared-test"><i class="fa fa-check"></i><b>C.6.2</b> Higher Dimensional Chi-Squared Test</a></li>
<li class="chapter" data-level="C.6.3" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#kolmogorov-smirnov-test-for-pseudo-random-numbers"><i class="fa fa-check"></i><b>C.6.3</b> Kolmogorov-Smirnov Test for Pseudo-Random Numbers</a></li>
<li class="chapter" data-level="C.6.4" data-path="appdistfittestU01.html"><a href="appdistfittestU01.html#testing-for-independence-and-patterns-in-pseudo-random-numbers"><i class="fa fa-check"></i><b>C.6.4</b> Testing for Independence and Patterns in Pseudo-Random Numbers</a></li>
</ul></li>
<li class="chapter" data-level="C.7" data-path="appdistfitidms2sb4.html"><a href="appdistfitidms2sb4.html"><i class="fa fa-check"></i><b>C.7</b> Additional Distribution Modeling Concepts</a></li>
<li class="chapter" data-level="C.8" data-path="appidmSummary.html"><a href="appidmSummary.html"><i class="fa fa-check"></i><b>C.8</b> Summary</a></li>
<li class="chapter" data-level="C.9" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>C.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="appqtAndInvT.html"><a href="appqtAndInvT.html"><i class="fa fa-check"></i><b>D</b> Queueing Theory</a>
<ul>
<li class="chapter" data-level="D.1" data-path="appqts1.html"><a href="appqts1.html"><i class="fa fa-check"></i><b>D.1</b> Single Line Queueing Stations</a>
<ul>
<li class="chapter" data-level="D.1.1" data-path="appqts1.html"><a href="appqts1.html#queueing-notation"><i class="fa fa-check"></i><b>D.1.1</b> Queueing Notation</a></li>
<li class="chapter" data-level="D.1.2" data-path="appqts1.html"><a href="appqts1.html#littles-formula"><i class="fa fa-check"></i><b>D.1.2</b> Little’s Formula</a></li>
<li class="chapter" data-level="D.1.3" data-path="appqts1.html"><a href="appqts1.html#appqts1sb1"><i class="fa fa-check"></i><b>D.1.3</b> Deriving Formulas for Markovian Single Queue Systems</a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="appqts1sb2.html"><a href="appqts1sb2.html"><i class="fa fa-check"></i><b>D.2</b> Examples and Applications of Queueing Analysis</a>
<ul>
<li class="chapter" data-level="D.2.1" data-path="appqts1sb2.html"><a href="appqts1sb2.html#infinite-queue-examples"><i class="fa fa-check"></i><b>D.2.1</b> Infinite Queue Examples</a></li>
<li class="chapter" data-level="D.2.2" data-path="appqts1sb2.html"><a href="appqts1sb2.html#finite-queue-examples"><i class="fa fa-check"></i><b>D.2.2</b> Finite Queue Examples</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="appqts1sb3.html"><a href="appqts1sb3.html"><i class="fa fa-check"></i><b>D.3</b> Non-Markovian Queues and Approximations</a></li>
<li class="chapter" data-level="D.4" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html"><i class="fa fa-check"></i><b>D.4</b> Summary of Queueing Formulas</a>
<ul>
<li class="chapter" data-level="D.4.1" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mm1-queue"><i class="fa fa-check"></i><b>D.4.1</b> M/M/1 Queue</a></li>
<li class="chapter" data-level="D.4.2" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmc-queue"><i class="fa fa-check"></i><b>D.4.2</b> M/M/c Queue</a></li>
<li class="chapter" data-level="D.4.3" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmck-queue"><i class="fa fa-check"></i><b>D.4.3</b> M/M/c/k Queue</a></li>
<li class="chapter" data-level="D.4.4" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mgcc-queue"><i class="fa fa-check"></i><b>D.4.4</b> M/G/c/c Queue</a></li>
<li class="chapter" data-level="D.4.5" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mm1k-queue"><i class="fa fa-check"></i><b>D.4.5</b> M/M/1/k Queue</a></li>
<li class="chapter" data-level="D.4.6" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmck-queue-1"><i class="fa fa-check"></i><b>D.4.6</b> M/M/c/k Queue</a></li>
<li class="chapter" data-level="D.4.7" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mm1kk-queue"><i class="fa fa-check"></i><b>D.4.7</b> M/M/1/k/k Queue</a></li>
<li class="chapter" data-level="D.4.8" data-path="appqtsecformulas.html"><a href="appqtsecformulas.html#mmckk-queue"><i class="fa fa-check"></i><b>D.4.8</b> M/M/c/k/k Queue</a></li>
</ul></li>
<li class="chapter" data-level="D.5" data-path="exercises-6.html"><a href="exercises-6.html"><i class="fa fa-check"></i><b>D.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>E</b> Distributions</a>
<ul>
<li class="chapter" data-level="E.1" data-path="appDiscreteDistributions.html"><a href="appDiscreteDistributions.html"><i class="fa fa-check"></i><b>E.1</b> Discrete Distrbutions</a></li>
<li class="chapter" data-level="E.2" data-path="appContinuousDistributions.html"><a href="appContinuousDistributions.html"><i class="fa fa-check"></i><b>E.2</b> Continuous Distrbutions</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="appStatTables.html"><a href="appStatTables.html"><i class="fa fa-check"></i><b>F</b> Statistical Tables</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Simulation Modeling using the Kotlin Simulation Library</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simoa:comparingSystems" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Comparing System Configurations<a href="simoa:comparingSystems.html#simoa:comparingSystems" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The previous sections have concentrated on estimating the performance of
a system through the execution of a single simulation model. The running
of the model requires the specification of the input variables (e.g.
mean time between arrivals, service distribution, etc.) and the
structure of the model (e.g. FIFO queue, process flow, etc.) The
specification of a set of inputs (variables and/or structure) represents
a particular system configuration, which is then simulated to estimate
performance. To be able to simulate design configurations, you may have
to build different models or you may be able to use the same model
supplied with different values of the program inputs. In either
situation, you now have different design configurations that can be
compared. This allows the performance of the system to be estimated
under a wide-variety of controlled conditions. It is this ability to
easily perform these what-if simulations that make simulation such a
useful analysis tool.</p>
<!-- Figure [1.21]{reference-type="ref" -->
<!-- reference="fig:ch7MultipleInputs"} represents the notion of using -->
<!-- different inputs to get different outputs. -->
<!-- ![Multiple Inputs on Models Represent Different System -->
<!-- Configurations[]{label="fig:ch7MultipleInputs"}](./figures/ch7/ch7fig71.png){#fig:ch7MultipleInputs} -->
<p>Naturally, when you have different design configurations, you would like
to know which configurations are better than the others. Since the
simulations are driven by random variables, the outputs from each
configuration (e.g. <span class="math inline">\(Y^1, Y^2\)</span>) are also random variables. The estimate
of the performance of each system must be analyzed using statistical
methods to ensure that the differences in performance are not simply due
to sampling error. In other words, you want to be confident that one
system is statistically better (or worse) than the other system.</p>
<div id="simoa:comparingSystems:two" class="section level3 hasAnchor" number="6.6.1">
<h3><span class="header-section-number">6.6.1</span> Comparing Two Systems<a href="simoa:comparingSystems.html#simoa:comparingSystems:two" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The techniques for comparing two systems via simulation are essentially
the same as that found in books that cover the statistical analysis of
two samples (e.g. <span class="citation">(<a href="#ref-montgomery2006applied" role="doc-biblioref">Montgomery and Runger 2006</a>)</span>). This section begins with a
review of these methods. Assume that samples from two different
populations (system configurations) are available:</p>
<p><span class="math display">\[X_{11}, X_{12},\ldots, X_{1 n_1} \ \ \text{a sample of size $n_1$ from system configuration 1}\]</span></p>
<p><span class="math display">\[X_{21}, X_{22},\ldots, X_{2 n_2} \ \ \text{a sample of size $n_2$ from system configuration 2}\]</span></p>
<p>The samples represent a performance measure of the system that will be
used in a decision regarding which system configuration is preferred.
For example, the performance measure may be the average system
throughput per day, and you want to pick the design configuration that
has highest throughput.</p>
<p>Assume that each system configuration has an unknown population mean for
the performance measure of interest, <span class="math inline">\(E[X_1] = \theta_1\)</span> and
<span class="math inline">\(E[X_2] = \theta_2\)</span>. Thus, the problem is to determine, with some
statistical confidence, whether <span class="math inline">\(\theta_1 &lt; \theta_2\)</span> or alternatively
<span class="math inline">\(\theta_1 &gt; \theta_2\)</span>. Since the system configurations are different, an
analysis of the situation of whether <span class="math inline">\(\theta_1 = \theta_2\)</span> is of less
relevance in this context.</p>
<p>Define <span class="math inline">\(\theta = \theta_1 - \theta_2\)</span> as the mean difference in
performance between the two systems. Clearly, if you can determine
whether <span class="math inline">\(\theta &gt;\)</span> 0 or <span class="math inline">\(\theta &lt;\)</span> 0 you can determine whether
<span class="math inline">\(\theta_1 &lt; \theta_2\)</span> or <span class="math inline">\(\theta_1 &gt; \theta_2\)</span>. Thus, it is sufficient
to concentrate on the difference in performance between the two systems.</p>
<p>Given samples from two different populations, there are a number of ways
in which the analysis can proceed based on different assumptions
concerning the samples. The first common assumption is that the
observations within each sample for each configuration form a random
sample. That is, the samples represent independent and identically
distributed random variables. Within the context of simulation, this can
be easily achieved for a given system configuration by performing
replications. For example, this means that
<span class="math inline">\(X_{11}, X_{12},\ldots, X_{1 n_1}\)</span> are the observations from <span class="math inline">\(n_1\)</span>
replications of the first system configuration. A second common
assumption is that both populations are normally distributed or that the
central limit theorem can be used so that sample averages are at least
approximately normal.</p>
<p>To proceed with further analysis, assumptions concerning the population
variances must be made. Many statistics textbooks present results for
the case of the population variance being known. In general, this is not
the case within simulation contexts, so the assumption here will be that
the variances associated with the two populations are unknown. Textbooks
also present cases where it is assumed that the population variances are
equal. Rather than making that assumption it is better to test a
hypothesis regarding equality of population variances.</p>
<p>The last assumption concerns whether or not the two samples can be
considered independent of each other. This last assumption is very
important within the context of simulation. Unless you take specific
actions to ensure that the samples will be independent, they will, in
fact, be dependent because of how simulations use (re-use) the same
random number streams. The possible dependence between the two samples
is not necessarily a bad thing. In fact, under certain circumstance it
can be a good thing.</p>
<p>The following sections first presents the methods for analyzing the case
of unknown variance with independent samples. Then, we focus on the case
of dependence between the samples. Finally, how to use the JSL to do the
work of the analysis will be illustrated.</p>
<div id="simoa:comparingSystems:twoIND" class="section level4 hasAnchor" number="6.6.1.1">
<h4><span class="header-section-number">6.6.1.1</span> Analyzing Two Independent Samples<a href="simoa:comparingSystems.html#simoa:comparingSystems:twoIND" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Although the variances are unknown, the unknown variances are either
equal or not equal. In the situation where the variances are equal, the
observations can be pooled when developing an estimate for the variance.
In fact, rather than just assuming equal or not equal variances, you can
(and should) use an F-test to test for the equality of variance. The
F-test can be found in most elementary probability and statistics books
(see <span class="citation">(<a href="#ref-montgomery2006applied" role="doc-biblioref">Montgomery and Runger 2006</a>)</span>).</p>
<p>The decision regarding whether <span class="math inline">\(\theta_1 &lt; \theta_2\)</span> can be addressed by
forming confidence intervals on <span class="math inline">\(\theta = \theta_1 - \theta_2\)</span>. Let
<span class="math inline">\(\bar{X}_1\)</span>, <span class="math inline">\(\bar{X}_2\)</span>, <span class="math inline">\(S_1^2\)</span>, and <span class="math inline">\(S_2^2\)</span> be the sample averages
and sample variances based on the two samples (k = 1,2):</p>
<p><span class="math display">\[\bar{X}_k = \dfrac{1}{n_k} \sum_{j=1}^{n_k} X_{kj}\]</span></p>
<p><span class="math display">\[S_k^2 = \dfrac{1}{n_k - 1} \sum_{j=1}^{n_k} (X_{kj} - \bar{X}_k)^2\]</span></p>
<p>An estimate of <span class="math inline">\(\theta = \theta_1 - \theta_2\)</span> is desired. This can be
achieved by estimating the difference with
<span class="math inline">\(\hat{D} = \bar{X}_1 - \bar{X}_2\)</span>. To form confidence intervals on
<span class="math inline">\(\hat{D} = \bar{X}_1 - \bar{X}_2\)</span> an estimator for the variance of
<span class="math inline">\(\hat{D} = \bar{X}_1 - \bar{X}_2\)</span> is required. Because the samples are
independent, the computation of the variance of the difference is:</p>
<p><span class="math display">\[Var(\hat{D}) = Var(\bar{X}_1 - \bar{X}_2) = \dfrac{\sigma_1^2}{n_1} + \dfrac{\sigma_2^2}{n_2}\]</span></p>
<p>where <span class="math inline">\(\sigma_1^2\)</span> and <span class="math inline">\(\sigma_2^2\)</span> are the unknown population
variances. Under the assumption of equal variance,
<span class="math inline">\(\sigma_1^2 = \sigma_2^2 =\sigma^2\)</span>, this can be written as:</p>
<p><span class="math display">\[Var(\hat{D}) = Var(\bar{X}_1 - \bar{X}_2) = \dfrac{\sigma_1^2}{n_1} + \dfrac{\sigma_2^2}{n_2} = \sigma^2 (\dfrac{1}{n_1} + \dfrac{1}{n_2})\]</span></p>
<p>where <span class="math inline">\(\sigma^2\)</span> is the common unknown variance. A pooled estimator of
<span class="math inline">\(\sigma^2\)</span> can be defined as:</p>
<p><span class="math display">\[S_p^2 = \dfrac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{n_1 + n_2 - 2}\]</span></p>
<p>Thus, a (<span class="math inline">\(1 - \alpha\)</span>)% confidence interval on
<span class="math inline">\(\theta = \theta_1 - \theta_2\)</span> is:</p>
<p><span class="math display">\[\hat{D} \pm t_{\alpha/2 , v} s_p \sqrt{\dfrac{1}{n_1} + \dfrac{1}{n_2}}\]</span></p>
<p>where <span class="math inline">\(v = n_1 + n_2 - 2\)</span>. For the case of unequal variances, an
approximate (<span class="math inline">\(1 - \alpha\)</span>)% confidence interval on
<span class="math inline">\(\theta = \theta_1 - \theta_2\)</span> is given by:</p>
<p><span class="math display">\[\hat{D} \pm t_{\alpha/2 , v} \sqrt{S_1^2/n_1 + S_2^2/n_2}\]</span></p>
<p>where
<span class="math display">\[v = \Biggl\lfloor \frac{(S_1^2/n_1 + S_2^2/n_2)^2}{\frac{(S_1^2/n_1)^2}{n_1 +1} + \frac{(S_2^2/n_2)^2}{n_2 + 1}} - 2 \Biggr\rfloor\]</span></p>
<p>Let <span class="math inline">\([l, u]\)</span> be the resulting confidence interval where <span class="math inline">\(l\)</span> and <span class="math inline">\(u\)</span>
represent the lower and upper limits of the interval with by
construction <span class="math inline">\(l &lt; u\)</span>. Thus, if <span class="math inline">\(u &lt; 0\)</span>, you can conclude with
(<span class="math inline">\(1 - \alpha\)</span>)% confidence that <span class="math inline">\(\theta = \theta_1 - \theta_2 &lt; 0\)</span> (i.e.
that <span class="math inline">\(\theta_1 &lt; \theta_2\)</span>). If <span class="math inline">\(l &gt; 0\)</span>, you can conclude with
(<span class="math inline">\(1 - \alpha\)</span>)% that <span class="math inline">\(\theta = \theta_1 - \theta_2 &gt; 0\)</span> (i.e. that
<span class="math inline">\(\theta_1 &gt; \theta_2\)</span>). If <span class="math inline">\([l, u]\)</span> contains 0, then no conclusion can
be made at the given sample sizes about which system is better. This
does not indicate that the system performance is the same for the two
systems. You <em>know</em> that the systems are different. Thus, their
performance will be different. This only indicates that you have not
taken enough samples to detect the true difference. If sampling is
relatively cheap, then you may want to take additional samples in order
to discern an ordering between the systems.</p>
<p>Two configurations are under consideration for the design of an airport
security checkpoint. A simulation model of each design was made. The
replication values of the throughput per minute for the security station
for each design are provided in the following table.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">Design 1</th>
<th align="center">Design 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td align="center">10.98</td>
<td align="center">8.93</td>
</tr>
<tr class="even">
<td>2</td>
<td align="center">8.87</td>
<td align="center">9.82</td>
</tr>
<tr class="odd">
<td>3</td>
<td align="center">10.53</td>
<td align="center">9.27</td>
</tr>
<tr class="even">
<td>4</td>
<td align="center">9.40</td>
<td align="center">8.50</td>
</tr>
<tr class="odd">
<td>5</td>
<td align="center">10.10</td>
<td align="center">9.63</td>
</tr>
<tr class="even">
<td>6</td>
<td align="center">10.28</td>
<td align="center">9.55</td>
</tr>
<tr class="odd">
<td>7</td>
<td align="center">8.86</td>
<td align="center">9.30</td>
</tr>
<tr class="even">
<td>8</td>
<td align="center">9.00</td>
<td align="center">9.31</td>
</tr>
<tr class="odd">
<td>9</td>
<td align="center">9.99</td>
<td align="center">9.23</td>
</tr>
<tr class="even">
<td>10</td>
<td align="center">9.57</td>
<td align="center">8.88</td>
</tr>
<tr class="odd">
<td>11</td>
<td align="center"></td>
<td align="center">8.05</td>
</tr>
<tr class="even">
<td>12</td>
<td align="center"></td>
<td align="center">8.74</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\bar{x}\)</span></td>
<td align="center">9.76</td>
<td align="center">9.10</td>
</tr>
<tr class="even">
<td><span class="math inline">\(s\)</span></td>
<td align="center">0.74</td>
<td align="center">0.50</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(n\)</span></td>
<td align="center">10</td>
<td align="center">12</td>
</tr>
</tbody>
</table>
<p>Assume that the two simulations were run independently of each other,
using different random numbers. Recommend the better design with 95%
confidence.</p>
<p>According to the results:</p>
<p><span class="math display">\[\hat{D} = \bar{X}_1 - \bar{X}_2 = 9.76 - 9.1 = 0.66\]</span></p>
<p>In addition, we should test if the variances of the samples are equal.
This requires an <span class="math inline">\(F\)</span> test, with <span class="math inline">\(H_0: \sigma_{1}^{2} = \sigma_{2}^{2}\)</span>
versus <span class="math inline">\(H_1: \sigma_{1}^{2} \neq \sigma_{2}^{2}\)</span>. Based on elementary
statistics, the test statistic is: <span class="math inline">\(F_0 = S_{1}^{2}/S_{1}^{2}\)</span>. The
rejection criterion is to reject <span class="math inline">\(H_0\)</span> if
<span class="math inline">\(F_0 &gt; f_{\alpha/2, n_1-1, n_2 -1}\)</span> or
<span class="math inline">\(F_0 &lt; f_{1-\alpha/2, n_1-1, n_2 -1}\)</span>, where <span class="math inline">\(f_{p, u, v}\)</span> is the upper
percentage point of the <span class="math inline">\(F\)</span> distribution. Assuming a 0.01 significance
level for the <span class="math inline">\(F\)</span> test, we have <span class="math inline">\(F_0 = (0.74)^{2}/(0.50)^{2} = 2.12\)</span>.
Since <span class="math inline">\(f_{0.005, 9, 11} = 5.54\)</span> and <span class="math inline">\(f_{0.995, 9, 11} = 0.168\)</span>, there is
not enough evidence to conclude that the variances are different at the
0.01 significance level. The value of <span class="math inline">\(f_{p, u, v}\)</span> can be determined in
as F.INV.RT(p, u, v). Note also that <span class="math inline">\(f_{1-p, u, v} = 1/f_{p, v, u}\)</span>. In
<span class="math inline">\(R\)</span>, the formula is <span class="math inline">\(f_{p, u, v} = qt(1-p, u,v)\)</span>, since <span class="math inline">\(R\)</span> provides the
quantile function, not the upper right tail function.</p>
<p>Since the variances can be assumed equal, we can use the pooled
variance, which is:</p>
<p><span class="math display">\[\begin{aligned}
S_p^2 &amp; = \dfrac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{n_1 + n_2 - 2}\\
  &amp; = \dfrac{(10 - 1)(0.74)^2 + (12 - 1)(0.5)^2}{12 + 10 - 2} \\
  &amp; = 0.384\end{aligned}\]</span></p>
<p>Thus, a (<span class="math inline">\(1 -0.05\)</span>)% confidence interval on
<span class="math inline">\(\theta = \theta_1 - \theta_2\)</span> is:</p>
<p><span class="math display">\[\begin{aligned}
\hat{D} &amp; \pm t_{\alpha/2 , v} s_p \sqrt{\dfrac{1}{n_1} + \dfrac{1}{n_2}} \\
0.66 &amp;  \pm t_{0.025 , 20} (\sqrt{0.384}) \sqrt{\dfrac{1}{10} + \dfrac{1}{12}} \\
0.66 &amp; \pm (2.086)(0.6196)(0.428) \\
0.66 &amp; \pm 0.553\end{aligned}\]</span></p>
<p>where <span class="math inline">\(v = n_1 + n_2 - 2 = 10 + 12 - 2 = 20\)</span>. Since this results in an
interval <span class="math inline">\([0.10, 1.21]\)</span> that does not contain zero, we can conclude that
design 1 has the higher throughput with 95% confidence.</p>
<p>The confidence interval can assist in making decisions regarding
relative performance of the systems from a <em>statistically significant</em>
standpoint. However, if you make a conclusion about the ordering of the
system, it still may not be practically significant. That is, the
difference in the system performance is statistically significant but
the actual difference is of no practical use. For example, suppose you
compare two systems in terms of throughput with resulting output
<span class="math inline">\(\bar{X}_1\)</span> = 5.2 and <span class="math inline">\(\bar{X}_2\)</span> = 5.0 with the difference
statistically significant. While the difference of 0.2 may be
statistically significant, you might not be able to achieve this in the
actual system. After all, you are making a decision based on a <em>model of
the system</em> not on the real system. If the costs of the two systems are
significantly different, you should prefer the cheaper of the two
systems since there is no practical difference between the two systems.
The fidelity of the difference is dependent on your modeling
assumptions. Other modeling assumptions may overshadow such a small
difference.</p>
<p>The notion of practical significance is model and performance measure
dependent. One way to characterize the notion of practical significance
is to conceptualize a zone of performance for which you are indifferent
between the two systems.</p>
<div class="figure"><span style="display:block;" id="fig:IndifZone"></span>
<img src="figures/ch7/ch7fig72.png" alt="Indifference Zone Concept" width="80%" height="80%" />
<p class="caption">
Figure 6.17: Indifference Zone Concept
</p>
</div>
<p>Figure <a href="simoa:comparingSystems.html#fig:IndifZone">6.17</a> illustrates the concept of an indifference zone
around the difference between the two systems. If the difference between
the two systems falls in this zone, you are indifferent between the two
systems (i.e. there is no practical difference).</p>
<p>Using the indifference zone to model the notion of practical
significance, if <span class="math inline">\(u &lt; -\Delta\)</span>, you can conclude confidence that
<span class="math inline">\(\theta_1 &lt; \theta_2\)</span>, and if <span class="math inline">\(l &gt; \Delta\)</span>, you can conclude with
confidence that <span class="math inline">\(\theta_1 &gt; \theta_2\)</span>. If <span class="math inline">\(l\)</span> falls within the
indifference zone and <span class="math inline">\(u\)</span> does not (or vice versa), then there is not
enough evidence to make a confident conclusion. If <span class="math inline">\([l,u]\)</span> is totally
contained within the indifference zone, then you can conclude with
confidence that there is no practical difference between the two
systems.</p>
</div>
<div id="simoa:comparingSystems:twoDep" class="section level4 hasAnchor" number="6.6.1.2">
<h4><span class="header-section-number">6.6.1.2</span> Analyzing Two Dependent Samples<a href="simoa:comparingSystems.html#simoa:comparingSystems:twoDep" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In this situation, continue to assume that the observations within a
sample are independent and identically distributed random variables;
however, the samples themselves are not independent. That is, assume
that the <span class="math inline">\((X_{11}, X_{12},\ldots, X_{1n_1})\)</span> and <span class="math inline">\((X_{21}, X_{22}, \ldots, X_{2n_2})\)</span> from the
two systems are dependent.</p>
<p>For simplicity, suppose that the difference in the configurations can be
implemented using a simple parameter change within the model. For
example, the mean processing time is different for the two
configurations. First, run the model to produce
<span class="math inline">\((X_{11}, X_{12}, \ldots, X_{1n_1})\)</span> for configuration 1. Then, change
the parameter and re-executed the model to produce
<span class="math inline">\((X_{21}, X_{22}, \ldots, X_{2n_2})\)</span> for configuration 2.</p>
<p>Assuming that you did nothing with respect to the random number streams,
the second configuration used the same random numbers that the first
configuration used. Thus, the generated responses will be correlated
(dependent). In this situation, it is convenient to assume that each
system is run for the same number of replications, i.e. <span class="math inline">\(n_1\)</span> = <span class="math inline">\(n_2\)</span> =
n. Since each replication for the two systems uses the same random
number streams, the correlation between <span class="math inline">\((X_{1,j}, X_{2,j})\)</span> will not be
zero; however, each pair will still be independent <em>across</em> the
replications. The basic approach to analyzing this situation is to
compute the difference for each pair:</p>
<p><span class="math display">\[D_j = X_{1j} - X_{2j} \ \ \text{for} \; j = 1,2,\ldots,n\]</span></p>
<p>The <span class="math inline">\((D_1, D_2, \ldots, D_n)\)</span> will form a random sample, which can be
analyzed via traditional methods. Thus, a (<span class="math inline">\(1 - \alpha\)</span>)% confidence
interval on <span class="math inline">\(\theta = \theta_1 - \theta_2\)</span> is:</p>
<p><span class="math display">\[\bar{D} = \dfrac{1}{n} \sum_{j=1}^n D_j\]</span></p>
<p><span class="math display">\[S_D^2 = \dfrac{1}{n-1} \sum_{j=1}^n (D_j - \bar{D})^2\]</span></p>
<p><span class="math display">\[\bar{D} \pm t_{\alpha/2, n-1} \dfrac{S_D}{\sqrt{n}}\]</span></p>
<p>The interpretation of the resulting confidence interval <span class="math inline">\([l, u]\)</span> is the
same as in the independent sample approach. This is the paired-t
confidence interval presented in statistics textbooks.</p>
<p>Assume that the two simulations were run dependently using common random
numbers. Recommend the better design with 95% confidence.</p>
<p>According to the results:</p>
<p><span class="math display">\[\bar{D} = \bar{X}_1 - \bar{X}_2 = 50.88 - 48.66 = 2.22\]</span></p>
<p>Also, we have that <span class="math inline">\(S_D^2 = (0.55)^2\)</span>. Thus, a (<span class="math inline">\(1 -0.05\)</span>)% confidence
interval on <span class="math inline">\(\theta = \theta_1 - \theta_2\)</span> is:</p>
<p><span class="math display">\[\begin{aligned}
\hat{D} &amp; \pm t_{\alpha/2, n-1} \dfrac{S_D}{\sqrt{n}}\\
2.22 &amp;  \pm t_{0.025 , 9}  \dfrac{0.55}{\sqrt{10}}\\
2.22 &amp; \pm (2.261)(0.1739)\\
2.22 &amp; \pm 0.0.393\end{aligned}\]</span></p>
<p>Since this results in an interval <span class="math inline">\([1.827, 2.613]\)</span> that does not contain
zero, we can conclude that design 1 has the higher cost with 95%
confidence.</p>
<p>Of the two approaches (independent versus dependent) samples, the latter
is much more prevalent in simulation contexts. The approach is called
the method of <em>common random numbers (CRN)</em> and is a natural by product
of how most simulation languages handle their assignment of random
number streams.</p>
<p>To understand why this method is the preferred method for comparing two
systems, you need to understand the method’s affect on the variance of
the estimator. In the case of independent samples, the estimator of
performance was <span class="math inline">\(\hat{D} = \bar{X}_1 - \bar{X}_2\)</span>. Since</p>
<p><span class="math display">\[\begin{aligned}
\bar{D} &amp; = \dfrac{1}{n} \sum_{j=1}^n D_j \\
&amp; =  \dfrac{1}{n} \sum_{j=1}^n (X_{1j} - X_{2j}) \\
&amp; = \dfrac{1}{n} \sum_{j=1}^n X_{1j} - \dfrac{1}{n} \sum_{j=1}^n X_{2j} \\
&amp; = \bar{X}_1 - \bar{X}_2 \\
&amp; = \hat{D}\end{aligned}\]</span></p>
<p>The two estimators are the same, when <span class="math inline">\(n_1 = n_2 = n\)</span>; however, their
variances are not the same. Under the assumption of independence,
computing the variance of the estimator yields:</p>
<p><span class="math display">\[V_{\text{IND}} = Var(\bar{X}_1 - \bar{X}_2) = \dfrac{\sigma_1^2}{n} + \dfrac{\sigma_2^2}{n}\]</span></p>
<p>Under the assumption that the samples are not independent, the variance
of the estimator is:</p>
<p><span class="math display">\[V_{\text{CRN}} = Var(\bar{X}_1 - \bar{X}_2) = \dfrac{\sigma_1^2}{n} + \dfrac{\sigma_2^2}{n} - 2\text{cov}(\bar{X}_1, \bar{X}_2)\]</span></p>
<p>If you define <span class="math inline">\(\rho_{12} = corr(\bar{X}_1, \bar{X}_2)\)</span>, the variance for
the common random number situation is:</p>
<p><span class="math display">\[V_{\text{CRN}} = V_{\text{IND}} - 2\sigma_1 \sigma_2 \rho_{12}\]</span></p>
<p>Therefore, whenever there is positive correlation <span class="math inline">\(\rho_{12} &gt; 0\)</span> within
the pairs we have that, <span class="math inline">\(V_{\text{CRN}} &lt; V_{\text{IND}}\)</span>.</p>
<p>If the variance of the estimator in the case of common random numbers is
smaller than the variance of the estimator under independent sampling,
then a <em>variance reduction</em> has been achieved. The method of common
random numbers is called a variance reduction technique. If the variance
reduction results in a confidence interval for <span class="math inline">\(\theta\)</span> that is tighter
than the independent case, the use of common random numbers should be
preferred. The variance reduction needs to be big enough to overcome any
loss in the number of degrees of freedom caused by the pairing. When the
number of replications is relatively large (<span class="math inline">\(n &gt; 30\)</span>) this will
generally be the case since the student-t value does not vary
appreciatively for large degrees of freedom. Notice that the method of
common random numbers might backfire and cause a variance increase if
there is negative correlation between the pairs. An overview of the
conditions under which common random numbers may work is given in
<span class="citation">(<a href="#ref-law2007simulation" role="doc-biblioref">Law 2007</a>)</span>.</p>
<p>This notion of pairing the outputs from each replication for the two
system configurations makes common sense. When trying to discern a
difference, you want the two systems to experience the same randomness
so that you can more readily infer that any difference in performance is
due to the inherent difference between the systems and not caused by the
random numbers.</p>
<p>In experimental design settings, this is called blocking on a factor.
For example, if you wanted to perform and experiment to determine
whether a change in a work method was better than the old method, you
should use the same worker to execute both methods. If instead, you had
different workers execute the methods, you would not be sure if any
difference was due to the workers or to the proposed change in the
method. In this context, the worker is the factor that should be
blocked. In the simulation context, the random numbers are being blocked
when using common random numbers.</p>
</div>
<div id="simoa:comparingSystems:CRN" class="section level4 hasAnchor" number="6.6.1.3">
<h4><span class="header-section-number">6.6.1.3</span> Using Common Random Numbers<a href="simoa:comparingSystems.html#simoa:comparingSystems:CRN" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The following explores how independent sampling and common random
numbers can be implemented.</p>
<p>IN PROGRESS</p>
</div>
</div>
<div id="simoa:comparingSystems:MCB" class="section level3 hasAnchor" number="6.6.2">
<h3><span class="header-section-number">6.6.2</span> Multiple Comparisons<a href="simoa:comparingSystems.html#simoa:comparingSystems:MCB" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>IN PROGRESS</p>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-law2007simulation" class="csl-entry">
Law, A. 2007. <em>Simulation Modeling and Analysis</em>. 4th ed. McGraw-Hill.
</div>
<div id="ref-montgomery2006applied" class="csl-entry">
Montgomery, D. C., and G. C. Runger. 2006. <em>Applied Statistics and Probability for Engineers</em>. 4th ed. John Wiley &amp; Sons.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simoa:infhorizon.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="simoa:summary.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["KSLBook.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
